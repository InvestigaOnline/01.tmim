[["index.html", "TMIM Compendio R Parte 1 Presentación 1.1 La asignatura 1.2 Objetivos", " TMIM Compendio R Roberto Gil-Saura 2021-12-07 Parte 1 Presentación 1.1 La asignatura Esta documentación ha sido preparada como guía de alumno en la asignatura Técnicas Estadísticas Multivariantes en Investigación de Mercados del Máster Oficial en Marketing e Investigación de Mercados de la Universitat de València. 1.2 Objetivos El objetivo de esta guía es ilustrar al alumno, a la vez que comenzar el camino de sustitución del software SPSS por R y RStudio, reproduciendo todos los análisis realizados en la asignatura en este entorno. Del mismo modo, las sesiones R1 y R2 permiten al estudiante, acercarse al trabajo con scripting con el objetivo final de la reproducibilidad de la investigación. Para seguir este documento, se asume que ya se han recibido las sesiones teóricas 1 a 6 con SPSS y se han explicado en clase presencial los conceptos teóricos. Aún así, se integra en la medida de lo posible la teoría también con los script correspondientes de la práctica. Del mismo modo, y por coherencia con los contenidos, las sesiones 7 y 8 se han incluido en esta documentación por delante de las sesiones de SPSS, como sesión R1 y sesión R2 respectivamente. Esperamos que al alumno que utilice esta documentación, le sea de ayuda y le aporte un inicial conocimiento a desarrollar con su exploración en el futuro. "],["intro.html", "Parte 2 Introducción", " Parte 2 Introducción El siguiente documento respalda los contenidos impartidos en la asignatura Técnicas Multivariantes en Investigación de Mercados y reproduce los cálculos estadísticos de las sesiones de SPSS organizadas dentro del máster oficial en Marketing e Investigación de mercados tal y como se trabajarían en R. Por ello, se aportan los script de R de todos los análisis realizados en las sesiones 1, 2, 3, 4, 5 y 6 de la asignatura replicando el trabajo con R y además se incluyen las dos sesiones complementarias realizadas con R al final del módulo. Así, este material ayuda a  introducir los conceptos básicos de R; ayudar a la carga de archivos; fija el horizonte en la reproducibilidad de la investigación (uso de rmarkdown); ayuda a la obtención de tablas marginales y cruzadas (uso de expss); ayuda a la obtención de gráficos (uso de highcharter). Este es un documento escrito en lenguaje markdown y compilado utilizando el paquete rbookdown de Xie (2021). El lenguaje markdown combina texto con script que ejecutan procesos. Estos script se localizan dentro de unidades de código de ejecución que se llaman chunk y que si el autor lo desea, se publican con un fondo gris para que el usuario los reconozca como tales. Un chunk se inicia con ```{r} al principio de la línea y se finaliza con ``` al principio de la línea también. Las líneas que quedan en medio de ambos marcadores (denominados token), forman el script de R. Los token (símbolos) de inicio y final del script, no se publican. References "],["r1.html", "Parte 3 Sesión R1 3.1 Introducción 3.2 Preguntas y respuestas antes de comenzar  3.3 Instalar y cargar paquetes básicos 3.4 Practicando el scripting 3.5 Conclusión", " Parte 3 Sesión R1 3.1 Introducción En esta primera sesión, particularmente acometeremos el trabajo básico de: instalar el software R; instalar el software RStudio; instalar los paquetes de trabajo; cargar los bancos de datos necesarios para comenzar nuestro trabajo; acercarnos al proceso de datos real, por medio de la tabulación. 3.1.1 Instalar R Software R Acceder a la web del proyecto R y descargar e instalar la versión indicada. 3.1.2 Instalar RStudio Software RStudio Acceder a la web de RStudio y descargar e instalar la versión indicada. 3.2 Preguntas y respuestas antes de comenzar  ¿Qué es R? R es un entorno y lenguaje de programación con un enfoque al análisis estadístico. R nació como una reimplementación de software libre del lenguaje S, adicionado con soporte para ámbito estático. Se trata de uno de los lenguajes de programación más utilizados en investigación científica, siendo además muy popular en los campos de aprendizaje automático (machine learning), minería de datos, investigación biomédica, bioinformática y matemáticas financieras. A esto contribuye la posibilidad de cargar diferentes bibliotecas o paquetes con funcionalidades de cálculo y de realización de gráficos. ¿Qué es RStudio? RStudio es un entorno de desarrollo integrado (IDE) para el lenguaje de programación R, dedicado a la computación estadística y gráficos. Incluye una consola, editor de sintaxis que apoya la ejecución de código, así como herramientas para el trazado, la depuración y la gestión del espacio de trabajo. RStudio está disponible para Windows, Mac y Linux o para navegadores conectados a RStudio Server o RStudio Server Pro (Debian / Ubuntu, RedHat / CentOS, y SUSE Linux). RStudio tiene la misión de proporcionar el entorno informático estadístico R. Permite un análisis y desarrollo para que cualquiera pueda analizar los datos con R. ¿Qué es un script de R base (.R)? Los script son documentos de texto con la extensión de archivo . R, por ejemplo mi script. R . Estos archivos son iguales a cualquier documentos de texto, pero R los puede leer y ejecutar el código que contienen. ¿Qué es Markdown? Markdown es un lenguaje de marcado ligero creado por John Gruber que trata de conseguir la máxima legibilidad y facilidad de publicación tanto en su forma de entrada como de salida, inspirándose en muchas convenciones existentes para marcar mensajes de correo electrónico usando texto plano. Markdown convierte el texto marcado en documentos XHTML utilizando html2text creado por Aaron Swartz. Te aconsejamos el siguiente enlace para conocer los rudimentos del lenguaje. ¿Qué es un script de rMarkdown (.Rmd)? R Markdown es un formato que permite una fácil creación de documentos, presentaciones dinámicas y informes de R. Markdown es un formato de sintaxis simple en documento de texto para crear documentos en HTML, PDF, y Word. ¿Qué es un archivo HTML self-contained? Los ficheros HTML self contained son ficheros autónomos que residen en un solo archivo HTML. No puede incluir ningún otro archivo y deben funcionar sin una conexión de red. Un usuario debería poder guardar el archivo, abrirlo localmente y tener todo listo para trabajar. ¿Qué es un vector? Los vectores en R son objetos de una única dimensión que puede contener datos numéricos, cadena de caracteres o datos lógicos, entre otros. Esencialmente son uno de los elementos básicos en la estructura de los datos en R. Se crean con la estructura c(). ¿Qué es una matriz? Una matriz en R es un conjunto de elementos del mismo tipo (numérico, carácter, lógico, etc) organizado en filas y columnas. Las matrices en R se construyen con la función matrix(). Aunque con un ejemplo siempre es mucho más fácil comprender cómo funcionan las matrices. ¿Qué es un dataframe? Un dataframe es lo que conocemos como un fichero de datos. Son estructuras para trabajar con datos de diferentes tipos (cadena, lógicos, aritméticos). Utilizar una estructura de datos tabular (como una matriz) pero que permite manipular distintos tipos de datos por lo que podemos tener una columna con caracteres, otra con números y otra con variables lógicas. Son importante para hacer tablas, cuadros, gráficas, análisis y modelos que tienen muchas variables estadísticas. Se crean con la estructura data.frame(). ¿Qué es un paquete / librería? Un paquete (package) es una colección de funciones, datos y código R que se almacenan en una carpeta conforme a una estructura bien definida, fácilmente accesible para R. En la web de R se puede consultar la lista de paquetes disponibles. ¿Qué es un objeto? La información que manipulamos en R se estructura en forma de objetos. Para trabajar con R resulta importante conocer los principales tipos de objetos y sus propiedades básicas. En general, cada tipo de objeto viene definido por una serie de atributos. Las funciones genéricas (como por ejemplo summary o plot) reconocen estos atributos y llevan a cabo distintos tipos de acciones en función del tipo de objeto. ¿Qué es un chunk? Los trozos de código R o que se insertan en archivos markdown se denominan chunk y permiten hacer análisis estadísticos y mostrar los resultados en el documento final. Los chunk tienen diversas opciones que permiten una mayor flexibilidad en como se muestra el código y los resultados en el documento final. print(&#39;_aquí iría el código_&#39;) [1] &quot;_aquí iría el código_&quot; ¿Qué es inline code? A diferencia de los chunk, el inline code se inserta en el texto del archivo, es de este modo como insertamos aquí la fecha: 2021-12-07. 3.3 Instalar y cargar paquetes básicos Los paquetes necesarios son cargados seguidamente. Si alguno no estuviera disponible debería ser instalado con install.packages(). El paquete fontawesome, tiene una forma especial de instalación. Es por ello que se cita al final de forma específica. #install.packages(c(&#39;readr&#39;, &#39;readxl&#39;,&#39;tidyverse&#39;, &#39;kableExtra&#39;, &#39;igraph&#39;, &#39;plotly&#39;, &#39;highcharter&#39;, &#39;sparkline&#39;, &#39;expss&#39;)) #devtools::install_github(&quot;rstudio/fontawesome&quot;) suppressMessages(library(&#39;readr&#39;, quietly = TRUE)) suppressMessages(library(&#39;readxl&#39;, quietly = TRUE)) suppressMessages(library(&#39;tidyverse&#39;, quietly = TRUE)) suppressMessages(library(&#39;kableExtra&#39;, quietly = TRUE)) suppressMessages(library(&#39;igraph&#39;, quietly = TRUE)) suppressMessages(library(&#39;plotly&#39;, quietly = TRUE)) suppressMessages(library(&#39;highcharter&#39;, quietly = TRUE)) suppressMessages(library(&#39;sparkline&#39;, quietly = TRUE)) suppressMessages(library(&#39;expss&#39;, quietly = TRUE)) suppressMessages(library(&#39;fontawesome&#39;, quietly = TRUE)) options(highcharter.theme = hc_theme_hcrt(tooltip = list(valueDecimals = 2))) MIM 2020 - 2021 - TECNICAS MULTIVARIANTES EN INVESTIGACION DE MERCADOS 3.4 Practicando el scripting 3.4.1 Ejercicio: script 01 Un primer ejemplo para iniciarnos en R es crear el siguiente script donde: se crean dos vectores, se publica su contenido, se unen esos dos vectores creando un dataframe se publica el dataframe se muestra la estructura del dataframe calcularemos la media aritmética del vector calcularemos la media aritmética del campo en el dataframe # Primero creamos dos vectores x &lt;- c(1,2,3,1,3,1,3,3,3) y &lt;- c(2,1,3,4,1,2,4,1,1) # Publicamos su contenido x [1] 1 2 3 1 3 1 3 3 3 y [1] 2 1 3 4 1 2 4 1 1 # A continuación creamos un _dataframe_ con los dos vectores df1 &lt;- data.frame(V1=x,V2=y) # Publicamos su contenido df1 V1 V2 1 1 2 2 2 1 3 3 3 4 1 4 5 3 1 6 1 2 7 3 4 8 3 1 9 3 1 # Validamos su estructura str(df1) &#39;data.frame&#39;: 9 obs. of 2 variables: $ V1: num 1 2 3 1 3 1 3 3 3 $ V2: num 2 1 3 4 1 2 4 1 1 # Obtengamos un estadístico, por ejemplo la media mean(x) # obtenida del vector [1] 2.222222 mean(df1$V1) # obtenida del _dataframe_; nótese la nomenclatura y el uso de $ [1] 2.222222 3.4.2 Ejercicio: script 02 En este segundo caso, vamos a acercarnos a conocer la influencia de los valores perdidos (ausencias de valor en la información) y su efecto ante el cálculo de estimaciones estadísticas. En este caso  crearemos los vectores de nuevo, añadiendo un valor perdido (NA), se publica su contenido, se unen esos dos vectores creando un dataframe, se publica el dataframe, realizaremos de nuevo los cálculos estadísticos anteriores con una leve modificación # Modificamos los dos vectores x &lt;- c(1,2,3,1,3,1,3,3,3, NA) #alternativamente podríamos haber hecho x &lt;- c(x,NA) y &lt;- c(2,1,3,4,1,2,4,1,1, NA) #alternativamente podríamos haber hecho y &lt;- c(y,NA) # Publicamos su contenido x [1] 1 2 3 1 3 1 3 3 3 NA y [1] 2 1 3 4 1 2 4 1 1 NA # A continuación creamos un dataframe con los dos vectores df1 &lt;- data.frame(V1=x,V2=y) # Publicamos su contenido df1 V1 V2 1 1 2 2 2 1 3 3 3 4 1 4 5 3 1 6 1 2 7 3 4 8 3 1 9 3 1 10 NA NA # Obtengamos un estadístico, por ejemplo la media mean(x) #obtenida del vector [1] NA mean(df1$V1) #obtenida del dataframe [1] NA mean(df1$V1, na.rm=TRUE) #obtenida del dataframe [1] 2.222222 3.4.3 Ejercicio: script 03 En este tercer caso, vamos a anticipar un gráfico muy simple hecho con la base de R y el mismo gráfico utilizando la librería highcharter, que será nuestra librería gráfica de referencia. El gráfico es obtenido usando el dataframe denominado df que fue cargado inicialmente. # Nuestro primer gráfico plot(df1) # Nuestro primer gráfico actual library(highcharter) # no haría falta si ya está cargado. hchart(df1, type=&#39;scatter&#39;, hcaes(x=V1, y=V2)) 3.4.4 Ejercicio: script 04 En este cuarto ejercicio, añadiremos a nuestro dataframe un identificador de los casos, y para ello usaremos una función LETTERS[] de R que asigna letras a los valores. Como hay 10 casos, así lo indicamos a la función. Posteriormente, representamos el gráfico como un diagrama de barras para la variable V2 del dataframe llamado df1, e ir completando. # Vamos a hacer otros gráficos de la forma completa # Añadimos un campo a df con el nombre de una letra(alumno, ciudad, ...) denominado name df1$name &lt;- LETTERS[1:10] df1 V1 V2 name 1 1 2 A 2 2 1 B 3 3 3 C 4 1 4 D 5 3 1 E 6 1 2 F 7 3 4 G 8 3 1 H 9 3 1 I 10 NA NA J # hacemos el gráfico de barras (1) highchart() %&gt;% hc_chart(type = &#39;bar&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1$V2) # hacemos el gráfico de barras (2) highchart() %&gt;% hc_chart(type = &#39;bar&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1$V2, color=&#39;green&#39;) # hacemos el gráfico de barras (3) highchart() %&gt;% hc_chart(type = &#39;bar&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1$V2, color=&#39;green&#39;, name=&#39;Ingresos&#39;) %&gt;% hc_add_series(df1$V1, color=&#39;red&#39;, name=&#39;Gastos&#39;) 3.4.5 Ejercicio: script 05 Por último, practiquemos la carga de datos. Aunque RStudio proporciona herramientas en su IDE para poder cargar datos desde archivos de texto, Excel © o SPSS © preferimos que la carga del archivo se haga desde el mismo script de trabajo. Por ello, usaremos los paquetes readr para ficheros de texto, readxl para archivos xls o xlsx y expss para archivos SPSS. Las instrucciones serán muy simples. Para evitar repetir la carga en las diferentes secciones de este capítulo, cargamos inicialmente todos los archivos. Los paquetes mencionados deberán haber sido cargados previamente. 3.4.5.1 Carga desde CSV El script que permitiría la lectura de un archivo denominado df.csv (texto separado por comas) require(&#39;readr&#39;) df &lt;- suppressMessages(read_csv(&quot;https://drive.google.com/uc?export=download&amp;id=1OStFMmg5fzIpfTZnzX9Ql8sefN7se5SW&quot;, col_names=TRUE)) #df.csv, archivo con su ruta en el disco df # A tibble: 6 x 11 x y z low high value name color from to weight &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; 1 0 1.6 -34 -6 9.2 1 lemon #d35400 lemon olive 1 2 1 11 -23 6.7 15.3 10 nut #2980b9 lemon guava 1 3 2 20.4 6.8 2.8 38 19 olive #2ecc71 lemon fig 1 4 3 22.1 32.3 19.4 24.8 21 guava #f1c40f nut olive 1 5 4 15.4 27.7 12.1 18.7 14 fig #2c3e50 olive pear 2 6 5 7.4 3.2 -11.8 26.6 6 pear #7f8c8d guava pear 2 3.4.5.2 Carga desde XLS, XLSX El script que permitiría la lectura de un archivo denominado df.xlsx (archivo Excel ©) #require(&#39;readxl&#39;)# se necesita el paquete readxl; si no está cargado, cárgalo #dfxls &lt;- suppressMessages(read_excel(&quot;https://drive.google.com/uc?export=download&amp;id=1JAm972XZeCHT2fQ2Sz_Sl_97o_Pa110U&quot;)) # df.xlsx, archivo con su ruta en el disco 3.4.5.3 Carga desde SPSS El script que permitiría la lectura de un archivo denominado 3192.sav (archivo SPSS © etiquetado) require(&#39;expss&#39;)# se necesita el paquete expss; si no está cargado, cárgalo data &lt;- suppressMessages(read_spss(&quot;https://drive.google.com/uc?export=download&amp;id=11q4pg2iWwWdV9mk5P44ejoAcj5CJEfJM&quot;)) # 3192.sav, archivo con su ruta en el disco head(data, 5) ESTU CUES CCAA PROV MUN TAMUNI CAPITAL DISTR SECCION ENTREV OLA P1 P2 P3 P401 P402 P403 P404 P501 P502 P503 P504 P6 P6A01 P6A02 P6B P6C P6D P7 P7A P801 P802 P803 P8A01 P8A02 P8A03 P8B01 P8B02 P8B03 P901 P902 P903 P904 P905 P906 P907 P908 P1001 P1002 P1003 P11 P11A01 P11A02 P11B P11C P11D P12 P12A01 P12A02 P12B P12C P12D01 P12D02 P12D P1301 P1302 P1303 P1304 P1305 P14 P14A01 P14A02 P14B P14C P1501 P1502 P1503 P1504 P1505 P1506 P16 P17 P18 P18A P18B P18C01 P18C02 P18C03 P18C04 P18C05 P18C06 P18C07 P18C08 P19 P20 P21 P21A01 P21A02 P21A03 P21A04 P21B P22 P23 P24 P2501 P2502 P2503 P2601 P2602 P2603 P2604 P27 P28 P29 P30 P30A P30AR P31 P32 P33 P34 P35 P35A P36 P37 P38 P39 P40 P41 P42 P42A P43 P44 P45 P46 P46A P46B P46C P46D P47 P47A P47B P48 P4901 P4902 P4903 P4904 P5001 P5002 P5003 P5004 P5005 P5101 P5102 P5103 P5104 P5105 P52 P53 P54 P55 I1 I2 I3 I4 I5 I6 I7 I8 I9 E101 E102 E103 E2 E3 E4 C1 C1A C2 C2A C2B C3 C4 RECUERDO ESTUDIOS OCUMAR11 RAMA09 CONDICION11 ESTATUS PESO 1 3192 1 16 1 59 5 1 0 0 0 3 9 3 6 1 1 1 1 7 7 8 8 1 2 0 1 2 3 3 1 1 2 1 2 0 1 96 96 8 7 7 7 7 6 6 6 7 3 2 3 2 96 96 0 0 0 2 96 96 0 0 NA NA NA 6 7 7 6 3 2 96 96 0 0 7 7 5 5 6 2 3 2 1 8 1 NA NA NA 1 NA NA NA NA 2 2 2 0 0 0 0 0 3 1 2 10 10 8 1 2 2 1 2 3 99 1 99 99 2 51 1 1 3 5 2 1 1 2 1 561 2 1 87 99 99 1 1 0 0 0 1 16 0 1 NA NA NA NA - - - - - - - - - - 2 2 2 2 7 NA 30 2 2 NA 12 NA 1 20 10 17 5 17 3 1 0 2 1 0 1 0 99 5 5 4 7 2 0.925 2 3192 2 16 1 59 5 1 0 0 0 3 2 2 7 1 1 1 1 7 7 7 7 1 1 0 0 2 3 1 NA 1 1 1 2 2 1 96 96 7 7 7 7 7 7 7 7 1 3 2 3 2 96 96 0 0 0 1 2 0 2 3 97 97 9997 7 7 7 7 1 2 96 96 0 0 7 7 9 7 7 1 4 8 2 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 1 1 1 10 6 4 2 9 9 2 1 3 2 1 3 3 1 37 1 1 3 13 1 2 1 1 1 215 4 0 86 7 6 1 1 0 0 0 1 16 0 3 NA NA NA NA - - - - - - - - - - 2 2 2 2 1 NA 11 NA 2 2 2 NA NA 20 10 17 5 17 1 1 0 1 0 0 1 0 3 6 2 4 1 1 0.925 3 3192 3 16 1 59 5 1 0 0 0 3 2 2 8 1 1 1 1 8 8 8 8 1 2 0 2 2 2 3 1 1 1 1 1 2 1 10 96 10 8 8 8 8 6 8 8 2 2 3 3 2 96 96 0 0 0 1 1 0 2 3 25 0 25 7 7 7 7 2 2 96 96 0 0 7 7 7 7 7 2 2 3 2 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 1 8 2 10 10 10 1 2 2 1 1 2 4 1 99 99 2 60 1 2 3 7 2 2 4 3 2 351 1 3 35 10 7 1 1 0 0 0 1 16 0 1 NA NA NA NA - - - - - - - - - - 2 2 1 1 2 NA 10 NA NA 1 NA NA NA 20 10 17 5 30 2 1 0 1 0 0 1 0 99 5 3 2 8 2 0.925 4 3192 4 16 1 59 5 1 0 0 0 3 9 2 8 1 1 1 1 9 9 9 1 1 1 0 0 1 3 2 NA 1 2 1 1 0 2 9 96 96 10 98 10 98 5 7 7 3 2 3 2 2 96 96 0 0 0 1 1 0 1 3 0 1 30 9 9 10 10 3 2 96 96 0 0 8 10 4 8 9 3 2 8 1 10 2 0 0 0 0 0 0 0 0 3 2 2 0 0 0 0 0 3 2 2 10 10 10 1 2 2 1 1 1 2 1 98 98 1 53 1 1 3 11 1 1 4 1 1 223 1 1 85 9 7 1 1 0 0 0 1 16 0 1 NA NA NA NA - - - - - - - - - - 2 2 2 1 3 NA 31 NA 2 2 10 1 NA 20 10 17 5 18 2 1 0 1 0 0 1 0 98 6 2 4 2 1 0.925 5 3192 5 16 1 59 5 1 0 0 0 3 3 2 7 1 1 1 1 9 5 8 8 1 2 0 1 2 3 4 1 1 1 1 2 2 2 96 96 96 8 8 9 9 6 8 8 4 2 3 2 2 96 96 0 0 0 1 1 0 2 3 0 4 120 5 6 8 8 4 2 96 96 0 0 5 10 7 5 98 4 8 2 1 10 2 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 1 1 2 10 8 10 2 2 2 1 2 3 1 1 3 3 2 69 3 2 3 4 2 2 4 1 2 921 1 3 81 5 5 1 1 0 0 0 1 14 0 1 NA NA NA NA - - - - - - - - - - 2 2 2 2 4 NA 13 NA NA 1 9 NA NA 20 10 17 5 19 2 1 0 1 0 0 1 0 3 3 9 4 8 5 0.925 tail(data,5) ESTU CUES CCAA PROV MUN TAMUNI CAPITAL DISTR SECCION ENTREV OLA P1 P2 P3 P401 P402 P403 P404 P501 P502 P503 P504 P6 P6A01 P6A02 P6B P6C P6D P7 P7A P801 P802 P803 P8A01 P8A02 P8A03 P8B01 P8B02 P8B03 P901 P902 P903 P904 P905 P906 P907 P908 P1001 P1002 P1003 P11 P11A01 P11A02 P11B P11C P11D P12 P12A01 P12A02 P12B P12C P12D01 P12D02 P12D P1301 P1302 P1303 P1304 P1305 P14 P14A01 P14A02 P14B P14C P1501 P1502 P1503 P1504 P1505 P1506 P16 P17 P18 P18A P18B P18C01 P18C02 P18C03 P18C04 P18C05 P18C06 P18C07 P18C08 P19 P20 P21 P21A01 P21A02 P21A03 P21A04 P21B P22 P23 P24 P2501 P2502 P2503 P2601 P2602 P2603 P2604 P27 P28 P29 P30 P30A P30AR P31 P32 P33 P34 P35 P35A P36 P37 P38 P39 P40 P41 P42 P42A P43 P44 P45 P46 P46A P46B P46C P46D P47 P47A P47B P48 P4901 P4902 P4903 P4904 P5001 P5002 P5003 P5004 P5005 P5101 P5102 P5103 P5104 P5105 P52 P53 P54 P55 I1 I2 I3 I4 I5 I6 I7 I8 I9 E101 E102 E103 E2 E3 E4 C1 C1A C2 C2A C2B C3 C4 RECUERDO ESTUDIOS OCUMAR11 RAMA09 CONDICION11 ESTATUS PESO 2553 3192 2596 19 52 1 4 1 0 0 0 3 3 2 6 1 1 1 1 8 7 6 7 1 10 0 2 1 2 4 7 1 2 2 1 0 0 4 96 96 7 7 8 8 8 8 8 5 1 3 1 2 96 96 0 0 0 2 96 96 0 0 NA NA NA 7 8 8 8 4 2 96 96 0 0 7 7 7 6 7 4 3 8 1 4 1 NA NA NA NA NA 1 NA NA 8 2 2 0 0 0 0 0 3 1 3 10 8 8 2 2 2 8 1 1 5 5 0 0 1 32 2 2 3 12 3 1 4 2 4 271 2 3 62 98 1 1 1 0 0 0 1 19 0 1 1 NA NA NA - - - - - - - - - - 2 3 2 2 5 NA NA NA NA NA 1 NA NA 22 10 17 7 17 2 1 0 1 0 0 1 0 97 6 2 4 9 1 0.049 2554 3192 2597 19 52 1 4 1 0 0 0 3 2 2 7 3 2 1 2 6 9 5 6 2 96 96 0 0 0 0 NA 0 0 0 0 0 0 96 96 96 7 7 7 7 1 7 7 1 2 8 2 2 96 96 0 0 0 2 96 96 0 0 NA NA NA 7 10 7 10 1 2 96 96 0 0 7 8 1 5 8 1 3 8 2 0 0 0 0 0 0 0 0 0 0 8 3 2 0 0 0 0 0 3 8 1 10 1 98 2 2 2 2 1 3 7 1 1 1 1 19 2 2 3 6 2 2 4 2 6 592 1 1 84 98 1 1 1 0 0 0 1 19 0 3 1 NA NA NA - - - - - - - - - - 2 1 2 1 6 NA 5 2 1 1 14 NA NA 22 10 17 7 19 2 1 0 1 0 0 1 0 1 4 5 4 10 2 0.049 2555 3192 2598 19 52 1 4 1 0 0 0 3 2 4 3 2 2 2 2 5 3 7 7 1 0 2 0 0 0 0 NA 0 0 0 0 0 0 96 96 96 5 5 5 5 2 5 5 1 2 3 2 1 1 0 1 0 0 2 96 96 0 0 NA NA NA 5 6 5 6 1 2 96 96 0 0 4 6 1 1 3 1 3 8 2 0 0 0 0 0 0 0 0 0 0 1 2 2 0 0 0 0 0 1 8 3 10 1 1 2 2 2 2 1 3 7 1 1 1 2 38 1 1 3 9 2 2 4 2 1 224 1 1 85 99 99 1 1 0 0 0 1 5 0 1 1 NA NA NA - - - - - - - - - - 2 1 1 1 7 NA 1 NA NA NA 3 NA NA 22 10 17 7 17 2 1 0 1 0 0 1 0 1 6 2 4 2 1 0.049 2556 3192 2599 19 52 1 4 1 0 0 0 3 2 3 5 2 2 2 2 4 6 2 3 2 96 96 0 0 0 0 NA 0 0 0 0 0 0 96 96 96 5 5 5 5 2 5 5 6 3 3 3 2 96 96 0 0 0 2 96 96 0 0 NA NA NA 5 7 5 5 4 2 96 96 0 0 6 7 1 1 3 4 3 8 2 0 0 0 0 0 0 0 0 0 0 2 3 2 0 0 0 0 0 1 1 3 10 1 1 1 1 1 1 2 4 5 5 0 0 2 20 2 2 3 6 1 2 4 2 6 740 1 3 45 98 1 1 1 0 0 0 1 19 0 1 NA NA NA 1 - - - - - - - - - - 2 1 2 1 3 NA 1 NA 1 NA 2 NA 1 22 10 17 7 17 1 1 0 1 0 0 1 0 97 4 7 4 10 4 0.049 2557 3192 2600 19 52 1 4 1 0 0 0 3 7 2 7 2 2 2 2 3 4 3 6 1 0 2 0 0 0 0 NA 0 0 0 0 0 0 96 96 96 98 98 98 98 2 98 98 1 2 3 2 2 96 96 0 0 0 2 96 96 0 0 NA NA NA 7 7 7 7 1 2 96 96 0 0 5 7 6 4 7 1 3 1 2 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 3 2 2 10 5 98 2 2 2 2 1 1 8 1 1 1 1 44 1 1 3 5 1 2 4 1 1 2 1 1 84 99 7 1 1 0 0 0 1 19 0 1 NA NA NA NA - - - - - - - - - - 2 1 1 1 8 NA NA NA NA NA 1 NA NA 22 10 17 7 17 2 2 1 1 0 0 1 0 1 5 10 4 12 2 0.049 Nuestros dataframe df y data están cargados y listos para ser utilizados a lo largo de las sesiones. 3.4.6 Ejercicio: Creación de un script rmarkdown El ejercicio consistirá en utilizar las opciones de ejemplo para que el estudiante vea la diferencia entre trabajar con archivo .R y archivos .Rmd, con la particularidad de su salida a HTML, Diapositivas (ioslides) o PDF si se dispone de la utilidad adecuada instalada. File &gt; New &gt; New RMarkdown &gt; Documentation &gt; HTML File &gt; New &gt; New RMarkdown &gt; Presentation &gt; ioslides 3.4.7 Ejercicio: script 05a y 05b Obtención de una tabla de frecuencias estilo SPSS (Script 05a). Nótese que la tabla sale igual con las dos formas, pero mientras que en el primer caso se usa la nomenclatura estándar de R, y el campo se llama data$P31, es decir nombre del marco de datos en R (data) el símbolo del $ que separa y nombre del campo en el marco de datos P31 en la segunda al definir de inicio que se utilizará dataya se usa el nombre P31directamente, aunque debamos dar la orden de cálculo con el comando calculate(). library(expss) data &lt;- suppressMessages(read_spss( &quot;https://drive.google.com/uc?export=download&amp;id=11q4pg2iWwWdV9mk5P44ejoAcj5CJEfJM&quot;)) fre(data$P31) Sexo de la persona entrevistada  Count   Valid percent   Percent   Responses, %   Cumulative responses, %   Hombre  1256 49.1 49.1 49.1 49.1  Mujer  1301 50.9 50.9 50.9 100.0  #Total  2557 100 100 100  &lt;NA&gt;  0 0.0 data %&gt;% calculate(fre(P31)) Sexo de la persona entrevistada  Count   Valid percent   Percent   Responses, %   Cumulative responses, %   Hombre  1256 49.1 49.1 49.1 49.1  Mujer  1301 50.9 50.9 50.9 100.0  #Total  2557 100 100 100  &lt;NA&gt;  0 0.0 3.4.8 Ejercicio: script 06 Para este script, indicaremos que usamos la fuente de datos cargado anteriormente. Redactamos pues nuestro script, donde identificamos el dataframe, el campo P31 del cual vamos a calcular el número de casos. # Script 6 data %&gt;% tab_cells(P31) %&gt;% tab_stat_cases() %&gt;% tab_pivot()  #Total   Sexo de la persona entrevistada     Hombre  1256    Mujer  1301    #Total cases  2557 3.4.9 Ejercicio: script 07a Realicemos ahora una pequeña pero importante variación en el cálculo del estadístico casos -frecuencias- y utilicemos la posibilidad de ubicar donde queramos el total de casos, así como su etiqueta. Ello lo hacemos con total_row_position = above, label = Casos aplicado a la función tab_stat_cases(). data %&gt;% tab_cells(P31) %&gt;% tab_stat_cases(total_row_position = &quot;above&quot;, label = &quot;Casos&quot;) %&gt;% tab_pivot()  #Total   Sexo de la persona entrevistada     #Total cases   Casos  2557    Hombre   Casos  1256    Mujer   Casos  1301 3.4.10 Ejercicio: script 07b Si en lugar de obtener casos (valores absolutos) queremos sacar valores porcentuales, el cambio es mínimo. Usaremos el comando tab_stat_cpct()para indicarlo. # Script 7b data %&gt;% tab_cells(P31) %&gt;% tab_stat_cpct(total_row_position = &quot;above&quot;, label = &quot;% casos&quot;) %&gt;% tab_pivot()  #Total   Sexo de la persona entrevistada     #Total cases   % casos  2557    Hombre   % casos  49.1    Mujer   % casos  50.9 3.4.11 Ejercicio: script 08 Cuando deseamos hacer combinaciones de frecuencias y porcentajes, la filosofía de trabajo es muy parecida. En nuestro caso vamos a hacer algo muy típico. Aunque creo que resulta más sencillo leer cada estadístico en su tabla, hay ocasiones en las que la comparativa es muy necesaria y por tanto es necesario unir los estadísticos en la misma tabla. Nótese la diferencia con el siguiente cuadro # Script 8 data %&gt;% tab_cells(P31) %&gt;% tab_stat_cases(total_row_position = &quot;above&quot;, label = &quot;Casos&quot;) %&gt;% tab_stat_cpct(label = &quot;% casos&quot;) %&gt;% tab_pivot(stat_position = &quot;inside_columns&quot;)  #Total   Casos   % casos   Sexo de la persona entrevistada     #Total cases  2557 2557    Hombre  1256 49.1    Mujer  1301 50.9 3.4.12 Ejercicio: script 09 Diferentes modalidades de cálculo de los porcentajes. # Script 9 data %&gt;% tab_cells(P31) %&gt;% tab_stat_cases() %&gt;% tab_stat_cpct() %&gt;% tab_stat_rpct() %&gt;% tab_stat_tpct() %&gt;% tab_pivot()  #Total   Sexo de la persona entrevistada     Hombre  1256.0    Mujer  1301.0    #Total cases  2557    Hombre  49.1    Mujer  50.9    #Total cases  2557    Hombre  100.0    Mujer  100.0    #Total cases  2557    Hombre  49.1    Mujer  50.9    #Total cases  2557 3.4.13 Ejercicio: script 10 Efecto de los modificadores. # Script 10 data %&gt;% tab_cells(P31) %&gt;% tab_stat_cases(total_row_position = &quot;below&quot;, label = &quot;N&quot;) %&gt;% tab_stat_cpct(label = &quot;V% casos&quot;) %&gt;% tab_stat_rpct(label = &quot;H% casos&quot;) %&gt;% tab_stat_tpct(label = &quot;T% casos&quot;) %&gt;% tab_pivot(stat_position = &quot;inside_columns&quot;)  #Total   N   V% casos   H% casos   T% casos   Sexo de la persona entrevistada     Hombre  1256 49.1 100 49.1    Mujer  1301 50.9 100 50.9    #Total cases  2557 2557 2557 2557 3.4.14 Ejercicio: script 11 La función var_lab() nos permite manipular la etiqueta de una variable, un texto descriptivo de su significado. Prueba en tu consola a escribir ?expss::var_lab() # Script 11 var_lab(data$P31) [1] &quot;Sexo de la persona entrevistada&quot; var_lab(data$P31) &lt;- &#39;Género del entrevistado&#39; 3.4.15 Ejercicio: script 12 La función val_lab() nos permite manipular las etiquetas de una variable, definir las etiquetas de los códigos, factores o niveles. Prueba en tu consola a escribir ?expss::val_lab() # Script 12 val_lab(data$P31) Hombre Mujer 1 2 val_lab(data$P31) &lt;- c(&#39;masculino&#39;=1, &#39;femenino&#39;=2) 3.4.16 Ejercicio: script 13 Para cerrar esta primera sesión, vamos a abordar un ejercicio diferente. Vamos ahora a instalar (si no lo está ya) el paquete gtrendsR, y cargamos los paquetes necesarios  # Script 13 # instalar paquetes #install.packages(&quot;gtrendsR&quot;) quitar el # sino estuviera instalado library(gtrendsR) library(dplyr) library(highcharter) Obtenemos los datos de Google Trends, y los almacenamos en un dataframe, reteniendo solo los campos 1 y 2 del mismo. # manipular datos es_trends &lt;- gtrends(c(&quot;Universidad de Valencia&quot;),geo = c(&quot;ES&quot;),gprop = &quot;web&quot;,time = &quot;today 12-m&quot;) head(es_trends, 5) $interest_over_time date hits keyword geo time gprop category 1 2020-12-13 24 Universidad de Valencia ES today 12-m web 0 2 2020-12-20 15 Universidad de Valencia ES today 12-m web 0 3 2020-12-27 29 Universidad de Valencia ES today 12-m web 0 4 2021-01-03 31 Universidad de Valencia ES today 12-m web 0 5 2021-01-10 40 Universidad de Valencia ES today 12-m web 0 6 2021-01-17 34 Universidad de Valencia ES today 12-m web 0 7 2021-01-24 42 Universidad de Valencia ES today 12-m web 0 8 2021-01-31 42 Universidad de Valencia ES today 12-m web 0 9 2021-02-07 42 Universidad de Valencia ES today 12-m web 0 10 2021-02-14 21 Universidad de Valencia ES today 12-m web 0 11 2021-02-21 34 Universidad de Valencia ES today 12-m web 0 12 2021-02-28 48 Universidad de Valencia ES today 12-m web 0 13 2021-03-07 47 Universidad de Valencia ES today 12-m web 0 14 2021-03-14 28 Universidad de Valencia ES today 12-m web 0 15 2021-03-21 48 Universidad de Valencia ES today 12-m web 0 16 2021-03-28 34 Universidad de Valencia ES today 12-m web 0 17 2021-04-04 36 Universidad de Valencia ES today 12-m web 0 18 2021-04-11 37 Universidad de Valencia ES today 12-m web 0 19 2021-04-18 35 Universidad de Valencia ES today 12-m web 0 20 2021-04-25 56 Universidad de Valencia ES today 12-m web 0 21 2021-05-02 33 Universidad de Valencia ES today 12-m web 0 22 2021-05-09 68 Universidad de Valencia ES today 12-m web 0 23 2021-05-16 61 Universidad de Valencia ES today 12-m web 0 24 2021-05-23 65 Universidad de Valencia ES today 12-m web 0 25 2021-05-30 43 Universidad de Valencia ES today 12-m web 0 26 2021-06-06 63 Universidad de Valencia ES today 12-m web 0 27 2021-06-13 77 Universidad de Valencia ES today 12-m web 0 28 2021-06-20 65 Universidad de Valencia ES today 12-m web 0 29 2021-06-27 74 Universidad de Valencia ES today 12-m web 0 30 2021-07-04 70 Universidad de Valencia ES today 12-m web 0 31 2021-07-11 85 Universidad de Valencia ES today 12-m web 0 32 2021-07-18 100 Universidad de Valencia ES today 12-m web 0 33 2021-07-25 57 Universidad de Valencia ES today 12-m web 0 34 2021-08-01 44 Universidad de Valencia ES today 12-m web 0 35 2021-08-08 31 Universidad de Valencia ES today 12-m web 0 36 2021-08-15 43 Universidad de Valencia ES today 12-m web 0 37 2021-08-22 30 Universidad de Valencia ES today 12-m web 0 38 2021-08-29 48 Universidad de Valencia ES today 12-m web 0 39 2021-09-05 48 Universidad de Valencia ES today 12-m web 0 40 2021-09-12 67 Universidad de Valencia ES today 12-m web 0 41 2021-09-19 50 Universidad de Valencia ES today 12-m web 0 42 2021-09-26 57 Universidad de Valencia ES today 12-m web 0 43 2021-10-03 34 Universidad de Valencia ES today 12-m web 0 44 2021-10-10 42 Universidad de Valencia ES today 12-m web 0 45 2021-10-17 42 Universidad de Valencia ES today 12-m web 0 46 2021-10-24 40 Universidad de Valencia ES today 12-m web 0 47 2021-10-31 34 Universidad de Valencia ES today 12-m web 0 48 2021-11-07 29 Universidad de Valencia ES today 12-m web 0 49 2021-11-14 26 Universidad de Valencia ES today 12-m web 0 50 2021-11-21 19 Universidad de Valencia ES today 12-m web 0 51 2021-11-28 26 Universidad de Valencia ES today 12-m web 0 $interest_by_country NULL $interest_by_region location hits keyword geo gprop 1 Valencian Community 100 Universidad de Valencia ES web 2 Castile-La Mancha 15 Universidad de Valencia ES web 3 Aragon 14 Universidad de Valencia ES web 4 Region of Murcia 13 Universidad de Valencia ES web 5 Navarre 12 Universidad de Valencia ES web 6 Extremadura 8 Universidad de Valencia ES web 7 Balearic Islands 8 Universidad de Valencia ES web 8 Castile and León 7 Universidad de Valencia ES web 9 Andalusia 6 Universidad de Valencia ES web 10 Galicia 6 Universidad de Valencia ES web 11 Canary Islands 6 Universidad de Valencia ES web 12 La Rioja 6 Universidad de Valencia ES web 13 Community of Madrid 6 Universidad de Valencia ES web 14 Asturias 6 Universidad de Valencia ES web 15 Basque Country 5 Universidad de Valencia ES web 16 Catalonia 4 Universidad de Valencia ES web 17 Cantabria 3 Universidad de Valencia ES web 18 Ceuta NA Universidad de Valencia ES web 19 Melilla NA Universidad de Valencia ES web $interest_by_dma NULL $interest_by_city location hits keyword geo gprop 1 Valencia 100 Universidad de Valencia ES web 2 Madrid 3 Universidad de Valencia ES web df1 &lt;- es_trends$interest_over_time[, 1:2] Si deseamos pedir ayuda, # Pedir ayuda y ver `?gtrends(). Finalmente creamos el gráfico veces que han salido en las noticias (datos de Google Trends) la Universitat de València. highchart() %&gt;% hc_chart(type = &#39;line&#39;) %&gt;% hc_xAxis(categories = as.Date(df1$date)) %&gt;% hc_add_series(df1$hits, name = &#39;hits UV&#39;) %&gt;% #*** API hc_credits(enabled = TRUE,text = &#39;InvestigaOnline.com&#39;,href = &#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled = TRUE) ¿Añadimos la Politécnica y la Complutense de Madrid?. Lo hacemos de un tirón, fíjate en las diferencias. #install.packages(&quot;gtrendsR&quot;) library(gtrendsR) library(dplyr) library(highcharter) es_trends &lt;- gtrends(c(&quot;Universitat de Valencia&quot;),geo = c(&quot;ES&quot;),gprop = &quot;web&quot;,hl = &quot;es&quot;,time = &quot;today 12-m&quot;) es_trends_interest_over_time &lt;- es_trends$interest_over_time[, 1:2] df1 &lt;- es_trends_interest_over_time es_trends &lt;-gtrends(c(&quot;Universidad Politecnica de Valencia&quot;),geo = c(&quot;ES&quot;),gprop = &quot;web&quot;,hl = &quot;es&quot;,time = &quot;all&quot;) es_trends_interest_over_time &lt;- es_trends$interest_over_time[, 1:2] df2 &lt;- es_trends_interest_over_time es_trends &lt;-gtrends(c(&quot;Universidad Complutense&quot;),geo = c(&quot;ES&quot;),gprop = &quot;web&quot;,hl = &quot;es&quot;,time = &quot;all&quot;) es_trends_interest_over_time &lt;- es_trends$interest_over_time[, 1:2] df3 &lt;- es_trends_interest_over_time highchart() %&gt;% hc_chart(type = &#39;line&#39;) %&gt;% hc_xAxis(categories = as.Date(c(df1$date, df2$date, df3$date))) %&gt;% hc_add_series(df1$hits,name = &#39;hits UV&#39;,marker = list(enabled = FALSE),color = &#39;salmon&#39;) %&gt;% hc_add_series(df2$hits,name = &#39;hits UPV&#39;,marker = list(enabled = FALSE),color = &#39;cadetblue&#39;) %&gt;% hc_add_series(df3$hits,name = &#39;hits UCM&#39;,marker = list(enabled = FALSE),color = &#39;green&#39;) %&gt;% hc_credits(enabled = TRUE,text = &#39;InvestigaOnline.com&#39;,href = &#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled = TRUE) 3.5 Conclusión Cerramos esta primera parte de las sesiones R, donde hemos comenzado a trabajar con pequeños trozos de código, diferenciando entre lo que es un script de tipo R, de un script de tipo rmarkdown. Hemos hecho una amplia revisión de conceptos y no en este documento, pero sí en la sesión presencial, hemos revisado materiales de trabajo para iniciarse en el conocimiento de R. Saber hasta dónde podemos llegar. La segunda sesión, nos meterá de forma mucho más concienzuda en el análisis de tablas y gráficos y la creación de un mini-dashboard. "],["r2.html", "Parte 4 Sesión R2 4.1 Proceso de datos con tablas y cuadros 4.2 Carga de datos para la sesión 4.3 Tablas marginales 4.4 Tablas cruzadas 4.5 Conclusión 4.6 Pruebas inferenciales 4.7 Visualización gráfica", " Parte 4 Sesión R2 4.1 Proceso de datos con tablas y cuadros En esta documentación acerca de R, mostramos un conjunto de términos que serán habitualmente utilizados en los sucesivos capítulos que se presentan en este documento. estos son los más relevantes y los hemos separado en dos grupos. un grupo hace referencia a términos básicos de R y otro grupo a términos básicos del manejo de tablas o del proceso de tabulación. Cada término tiene une breve reseña, y posteriormente algunos de ellos serán más tratados en sus respectivas funcionalidades. 4.1.1 Términos básicos de proceso de datos variable, elemento de tipo vector que contiene los valores de una determinada observación, un valor en cada fila; debe entenderse en el contexto de la estructura tabular o dataframe. valores, cada una de las diferentes celdas que componen un dataframe. Una variable toma un valor en cada fila y se representa en la celda. medidas, valores de los que se pretende calcular estadísticos como la media, la desviación típica o la mediana entre otras. Suelen responder a escalas de tipo numérico (ordinal o métrico). dimensiones, valores de los que se pretende calcular frecuencias y/o porcentajes. factores, niveles, códigos, etiquetas de variable. NA, es como R representa los valores nulos o ausentes. valores perdidos, missing values, valores ausentes; tal como hemos indicado en el término NA, así es como R representa este tipo de valores. 4.1.2 Términos básicos de tabulación En nuestro trabajo vamos a crear objetos de tipo tabla; una tabla es una estructura tabular, igual que un dataframe. De hecho, con nuestro trabajo utilizando el paquete EXPSS, vamos a generar tablas que serán dataframe de tipo (clase) etable. Al ser un dataframe, podremos operar entre filas, columnas y celdas de forma lógica o aritmética utilizando funciones y comandos de R. Dejamos este glosario de términos relacionados con las tablas que utilizaremos en esta guía. título (caption), texto que se publicará sobre la tabla; pie (footer), texto que se publicará bajo la tabla; fila, cada una de las líneas de información dentro de una tabla; se suele asimilar a un nivel (código) de una variable y/o a un resultados estadístico de una variable; columna, cada una de las variables que conforman el dataframe de una tabla (estructura tabular); en un cuadro o tabla de contingencia suele equivaler a un nivel de la variable que originalmente se diseñó para ser usada en columnas (si por ejemplo SEXO, una columna sería hombre y otra mujer); celda, cada una de las unidades de información del cuadro o tabla; row_labels, primera columna donde se escriben los textos de las filas y que sirven para identificar el contenido de las mismas; etiqueta de variable, texto extra identificativo de la variable usada en filas o columnas; etiqueta de valor, texto del código identificativo de la variable usada; estadístico, medida calculada; frecuencia, tipo específico de medida calculada que significa número de veces en términos absolutos; porcentaje, tipo específico de medida calculada que significa número de veces en términos relativos; |, símbolo denominado pipe que en el paquete expss se utilizará para separar conjuntos de texto en una celda (o columna o fila); significación, prueba estadística de contraste. 4.2 Carga de datos para la sesión Procedamos a ejecutar el siguiente script para cargar los paquetes necesarios y los datos del estudio CIS 3192, barómetro sanitario. suppressMessages(library(&#39;highcharter&#39;, quietly=TRUE)) suppressMessages(library(&#39;expss&#39;, quietly = TRUE)) options(highcharter.theme = hc_theme_hcrt(tooltip = list(valueDecimals = 2))) data &lt;- suppressMessages(read_spss(&quot;https://drive.google.com/uc?export=download&amp;id=11q4pg2iWwWdV9mk5P44ejoAcj5CJEfJM&quot;)) head(data, 5) ESTU CUES CCAA PROV MUN TAMUNI CAPITAL DISTR SECCION ENTREV OLA P1 P2 P3 P401 P402 P403 P404 P501 P502 P503 P504 P6 P6A01 P6A02 P6B P6C P6D P7 P7A P801 P802 P803 P8A01 P8A02 P8A03 P8B01 P8B02 P8B03 P901 P902 P903 P904 P905 P906 P907 P908 P1001 P1002 P1003 P11 P11A01 P11A02 P11B P11C P11D P12 P12A01 P12A02 P12B P12C P12D01 P12D02 P12D P1301 P1302 P1303 P1304 P1305 P14 P14A01 P14A02 P14B P14C P1501 P1502 P1503 P1504 P1505 P1506 P16 P17 P18 P18A P18B P18C01 P18C02 P18C03 P18C04 P18C05 P18C06 P18C07 P18C08 P19 P20 P21 P21A01 P21A02 P21A03 P21A04 P21B P22 P23 P24 P2501 P2502 P2503 P2601 P2602 P2603 P2604 P27 P28 P29 P30 P30A P30AR P31 P32 P33 P34 P35 P35A P36 P37 P38 P39 P40 P41 P42 P42A P43 P44 P45 P46 P46A P46B P46C P46D P47 P47A P47B P48 P4901 P4902 P4903 P4904 P5001 P5002 P5003 P5004 P5005 P5101 P5102 P5103 P5104 P5105 P52 P53 P54 P55 I1 I2 I3 I4 I5 I6 I7 I8 I9 E101 E102 E103 E2 E3 E4 C1 C1A C2 C2A C2B C3 C4 RECUERDO ESTUDIOS OCUMAR11 RAMA09 CONDICION11 ESTATUS PESO 1 3192 1 16 1 59 5 1 0 0 0 3 9 3 6 1 1 1 1 7 7 8 8 1 2 0 1 2 3 3 1 1 2 1 2 0 1 96 96 8 7 7 7 7 6 6 6 7 3 2 3 2 96 96 0 0 0 2 96 96 0 0 NA NA NA 6 7 7 6 3 2 96 96 0 0 7 7 5 5 6 2 3 2 1 8 1 NA NA NA 1 NA NA NA NA 2 2 2 0 0 0 0 0 3 1 2 10 10 8 1 2 2 1 2 3 99 1 99 99 2 51 1 1 3 5 2 1 1 2 1 561 2 1 87 99 99 1 1 0 0 0 1 16 0 1 NA NA NA NA - - - - - - - - - - 2 2 2 2 7 NA 30 2 2 NA 12 NA 1 20 10 17 5 17 3 1 0 2 1 0 1 0 99 5 5 4 7 2 0.925 2 3192 2 16 1 59 5 1 0 0 0 3 2 2 7 1 1 1 1 7 7 7 7 1 1 0 0 2 3 1 NA 1 1 1 2 2 1 96 96 7 7 7 7 7 7 7 7 1 3 2 3 2 96 96 0 0 0 1 2 0 2 3 97 97 9997 7 7 7 7 1 2 96 96 0 0 7 7 9 7 7 1 4 8 2 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 1 1 1 10 6 4 2 9 9 2 1 3 2 1 3 3 1 37 1 1 3 13 1 2 1 1 1 215 4 0 86 7 6 1 1 0 0 0 1 16 0 3 NA NA NA NA - - - - - - - - - - 2 2 2 2 1 NA 11 NA 2 2 2 NA NA 20 10 17 5 17 1 1 0 1 0 0 1 0 3 6 2 4 1 1 0.925 3 3192 3 16 1 59 5 1 0 0 0 3 2 2 8 1 1 1 1 8 8 8 8 1 2 0 2 2 2 3 1 1 1 1 1 2 1 10 96 10 8 8 8 8 6 8 8 2 2 3 3 2 96 96 0 0 0 1 1 0 2 3 25 0 25 7 7 7 7 2 2 96 96 0 0 7 7 7 7 7 2 2 3 2 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 1 8 2 10 10 10 1 2 2 1 1 2 4 1 99 99 2 60 1 2 3 7 2 2 4 3 2 351 1 3 35 10 7 1 1 0 0 0 1 16 0 1 NA NA NA NA - - - - - - - - - - 2 2 1 1 2 NA 10 NA NA 1 NA NA NA 20 10 17 5 30 2 1 0 1 0 0 1 0 99 5 3 2 8 2 0.925 4 3192 4 16 1 59 5 1 0 0 0 3 9 2 8 1 1 1 1 9 9 9 1 1 1 0 0 1 3 2 NA 1 2 1 1 0 2 9 96 96 10 98 10 98 5 7 7 3 2 3 2 2 96 96 0 0 0 1 1 0 1 3 0 1 30 9 9 10 10 3 2 96 96 0 0 8 10 4 8 9 3 2 8 1 10 2 0 0 0 0 0 0 0 0 3 2 2 0 0 0 0 0 3 2 2 10 10 10 1 2 2 1 1 1 2 1 98 98 1 53 1 1 3 11 1 1 4 1 1 223 1 1 85 9 7 1 1 0 0 0 1 16 0 1 NA NA NA NA - - - - - - - - - - 2 2 2 1 3 NA 31 NA 2 2 10 1 NA 20 10 17 5 18 2 1 0 1 0 0 1 0 98 6 2 4 2 1 0.925 5 3192 5 16 1 59 5 1 0 0 0 3 3 2 7 1 1 1 1 9 5 8 8 1 2 0 1 2 3 4 1 1 1 1 2 2 2 96 96 96 8 8 9 9 6 8 8 4 2 3 2 2 96 96 0 0 0 1 1 0 2 3 0 4 120 5 6 8 8 4 2 96 96 0 0 5 10 7 5 98 4 8 2 1 10 2 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 1 1 2 10 8 10 2 2 2 1 2 3 1 1 3 3 2 69 3 2 3 4 2 2 4 1 2 921 1 3 81 5 5 1 1 0 0 0 1 14 0 1 NA NA NA NA - - - - - - - - - - 2 2 2 2 4 NA 13 NA NA 1 9 NA NA 20 10 17 5 19 2 1 0 1 0 0 1 0 3 3 9 4 8 5 0.925 Para descargar el cuestionario (PDF), haz clic en este enlace. Para verlo puedes probar con este otro enlace. 4.3 Tablas marginales Vamos a comenzar con un conjunto de tablas muy sencillas. En ellas representaremos los valores obtenidos del análisis de un campo extraído de nuestra fuente de datos de referencia, la tercera oleada del Barómetro Sanitario en España de 2017 del realizado y publicado por el CIS. Por ahora, trabajaremos sólo con la variable denominada P31 (sexo del entrevistado), variable medida en escala nominal, cuyas etiquetas (valores) son hombre (1) y mujer (2) y con la variable P3, escala de satisfacción (1-10) con el funcionamiento del sistema sanitario español, medida de 1 a 10. En nuestra fuente de datos tenemos 2557 casos (entrevistas realizadas). Para ello utilizaremos un script, es decir una pocas líneas de código que mostraremos en este mismo documento con un fondo gris. Lo que quede fuera de ese trozo del documento, será como este texto que estoy escribiendo. Este texto que además, puede ser formateado como si de un HTML se tratará, es lo que llamamos un archivo markdown, y como es de R, pues lo llamamos rmarkdown. Verás que también este documento tiene títulos, que se obtienen anteponiendo el símbolo # desde 1 vez hasta 6 veces y que se corresponde con las etiquetas de título de HTML. Inicialmente, comentaremos las líneas del script utilizando el también el mismo símbolo, pero no al inicio de la línea sino al final Lo que quede por detrás de él, se considera un comentario. 4.3.1 Tablas de frecuencia Este conjunto de tablas sólo trabajará que con el estadístico de cálculo de frecuencias. Comenzaremos con variables de respuesta simple, para luego avanzar a las variables de respuesta múltiple y al uso de medidas estadísticas básicas (suma, media, mediana, máximo, mínimo, etc.). 4.3.1.1 Variables de respuesta simple 4.3.1.1.1 Cálculo de frecuencias, estilo SPSS Utilizaremos en estos ejemplos de forma inicial un campo del marco de datos, P31, de respuesta simple. La primera tabla que haremos responde a un recuento de frecuencias, y es muy usada para el análisis univariante de una campo. Este comando muestra una tabla básica utilizando la función fre() que copia la salida del SPSS. Nótese que la columna de porcentaje válido y porcentaje es igual ante la inexistencia de NA (valores perdidos). fre(data$P31) Sexo de la persona entrevistada  Count   Valid percent   Percent   Responses, %   Cumulative responses, %   Hombre  1256 49.1 49.1 49.1 49.1  Mujer  1301 50.9 50.9 50.9 100.0  #Total  2557 100 100 100  &lt;NA&gt;  0 0.0 Alternativamente se puede presentar la forma que trabajaremos a lo largo de este curso, esta forma es la denominada script encadenado, donde definimos el marco de datos al inicio, y encadenamos instrucciones con el símbolo %&gt;% que irían línea a línea sucesivamente para una mejor lectura y comprensión del texto escrito; podrían perfectamente ir en una línea. Nótese que la tabla sale igual con las dos formas, pero mientras que en el primer caso se usa la nomenclatura estándar de R, y el campo se llama data$P31, es decir nombre del marco de datos en R (data) el símbolo del $ que separa y nombre del campo en el marco de datos P31 en la segunda al definir de inicio que se utilizará dataya se usa el nombre P31directamente, aunque debamos dar la orden de cálculo con el comando calculate(). data %&gt;% calculate(fre(P31)) Sexo de la persona entrevistada  Count   Valid percent   Percent   Responses, %   Cumulative responses, %   Hombre  1256 49.1 49.1 49.1 49.1  Mujer  1301 50.9 50.9 50.9 100.0  #Total  2557 100 100 100  &lt;NA&gt;  0 0.0 Veamos ahora cómo solicitaremos tablas de frecuencias, porcentajes y estadísticos simples con R. 4.3.1.1.2 Tablas de frecuencias (absolutos) La segunda tabla que vamos a hacer, ya responde a la típica presentación de una tabla de contingencia, sólo que en este casos vamos a mostrar sólo un campo y por tanto no va a haber cruce de variables. En el paquete expss, para construir un cuadro deberemos indicar al menos: un marco de datos (dataframe en nomenclatura R) referenciar la variable sobre la que se deben calcular el estadístico seleccionado (frecuencia -casos-, media, mediana, máximo, mínimo) una orden de impresión de tabla Estos elementos básicos pueden completarse con campos de columnas, campos de filas, pruebas de significación, etc. Iremos desarrollando estos conceptos a lo largo de este documento. ¡Vamos a por el cuadro! La que ahora entregamos, es la estructura básica de un script de R con el paquete expss. A lo largo del documento veremos cómo ir introduciendo mínimas variaciones a esta estructura que te permitirán descubrir un sinnúmero de posibilidades que ofrece este paquete de R. Por ejemplo, podemos modificar la etiqueta de TOTAL o indicar donde debe situarse la fila que contiene el cálculo TOTAL. Todas estas posibilidades las puedes conocer en la documentación original del package, aunque en este manual trataremos de ir desgranado las más relevantes para nuestro objetivo. Inicialmente iremos añadiendo tras el operador %&gt;% comentarios precedidos por el simbolo #. Estos comentarios irán desapareciendo a medida que avancemos en el manual, y sólo se recurrirá a ellos cuando se aporte alguna nueva funcionalidad. El dataframe tendrá el nombre que le hayas indicado en la carga. Redactamos pues nuestro script, donde identificamos el dataframe, el campo P31 del cual vamos a calcular el número de casos: data %&gt;% tab_cells(P31) %&gt;% tab_stat_cases() %&gt;% tab_pivot()  #Total   Sexo de la persona entrevistada     Hombre  1256    Mujer  1301    #Total cases  2557 Realicemos ahora una pequeña pero importante variación en el cálculo del estadístico casos -frecuencias- y utilicemos la posibilidad de ubicar donde queramos el total de casos, así como su etiqueta. Ello lo hacemos con total_row_position = \"above\", label = \"Casos\" aplicado a la función tab_stat_cases(). data %&gt;% tab_cells(P31) %&gt;% tab_stat_cases(total_row_position = &quot;above&quot;, label = &quot;Casos&quot;) %&gt;% tab_pivot()  #Total   Sexo de la persona entrevistada     #Total cases   Casos  2557    Hombre   Casos  1256    Mujer   Casos  1301 4.3.1.1.3 Tablas de frecuencias relativas Si en lugar de obtener casos (valores absolutos) queremos sacar valores porcentuales, el cambio es mínimo. Usaremos el comando tab_stat_cpct()para indicarlo. data %&gt;% tab_cells(P31) %&gt;% tab_stat_cpct(total_row_position = &quot;above&quot;, label = &quot;% casos&quot;) %&gt;% tab_pivot()  #Total   Sexo de la persona entrevistada     #Total cases   % casos  2557    Hombre   % casos  49.1    Mujer   % casos  50.9 4.3.1.1.4 Tablas de absolutos y realativos (juntos) Cuando deseamos hacer combinaciones de frecuencias y porcentajes, la filosofía de trabajo es muy parecida. En nuestro caso vamos a hacer algo muy típico. Aunque creo que resulta más sencillo leer cada estadístico en su tabla, hay ocasiones en las que la comparativa es muy necesaria y por tanto es ncesario unir los estadísticos en la misma tabla. Nótese la diferencia con el siguiente cuadro data %&gt;% tab_cells(P31) %&gt;% tab_stat_cases(total_row_position = &quot;above&quot;, label = &quot;Casos&quot;) %&gt;% tab_stat_cpct(label = &quot;% casos&quot;) %&gt;% tab_pivot(stat_position = &quot;inside_columns&quot;)  #Total   Casos   % casos   Sexo de la persona entrevistada     #Total cases  2557 2557    Hombre  1256 49.1    Mujer  1301 50.9 Nótese el efecto introducido por el modificador de posición del cálculo. También  data %&gt;% tab_cells(P31) %&gt;% tab_stat_cases(total_row_position = &quot;above&quot;, label = &quot;Casos&quot;) %&gt;% tab_stat_cpct(label = &quot;% casos&quot;) %&gt;% tab_pivot(stat_position = &quot;outside_rows&quot;)  #Total   Sexo de la persona entrevistada     #Total cases   Casos  2557    Hombre   Casos  1256.0    Mujer   Casos  1301.0    Hombre   % casos  49.1    Mujer   % casos  50.9    #Total cases   % casos  2557 O también  data %&gt;% tab_cells(P31) %&gt;% tab_stat_cases(total_row_position = &quot;below&quot;, label = &quot;Casos&quot;) %&gt;% tab_stat_cpct(label = &quot;% casos&quot;) %&gt;% tab_pivot(stat_position = &quot;inside_columns&quot;)  #Total   Casos   % casos   Sexo de la persona entrevistada     Hombre  1256 49.1    Mujer  1301 50.9    #Total cases  2557 2557 4.3.1.2 Variable de respuesta múltiple Vamos a trabajar ahora con variables multi-respuesta. SPSS divide la variable múltiple en tantas variables simples (o dicotómicas binarias) como requiera para poder representar la multi-respuesta. Por ejemplo, si tenemos una variable múltiple denominada P01, y el máximo número de respuestas (menciones) en el banco de datos es 3, al crear el dataframe se crean las variables P01_1, P01_2 y P01_3; es con estas variables con las que trabajamos. Cada una de estas variables puede tomar cualquiera de los valores codificados. Para expss, la forma de indicar que un conjunto de campos forman una multi-respuesta es muy simple anteponer mrset_f() al nombre del campo que vamos a usar. Debemos tener la precaución de que no haya variables en el banco de datos que comiencen por la misma raíz. Así, el campo de ejemplo sería mrset_f(P01_)y con eso procesaría las tres variables de forma conjunta. Alternativamente, podríamos usar también: mrset(P01_1 %to% P01_3) o también, mrset(P01_1,P01_2,P01_3) Cualquiera de ellas sería también válida, pero nótese que en estas últimas listadas, es necesario saber donde empieza y acaba la múltiple y esto puede variar sobretodo si creamos los _script_s antes de acabar el campo. Al acabar el campo, pudiera haber algún nuevo caso que tuviera más menciones que 3 y por tanto existirían también _4, _5 o, _n. Como hemos indicado, no olvides que existe otra forma de trabajar las múltiples, utilizando variables dicotómicas o binarias (así es como están en nuestro banco de datos del CIS). En este caso, serviría todo lo afirmado anterioremnte, pero en lugar de mrset_f(), usaríamos mdset_f(). 4.3.1.2.1 Tablas de frecuencias absolutas Usaremos el campo P18C para procesar su información, que se localiza en el banco de datos desde P18C01 hasta P18C08. data %&gt;% tab_cells(mdset_f(P18C)) %&gt;% tab_stat_cases(total_row_position=&quot;above&quot;, label=&quot;Casos&quot;) %&gt;% tab_pivot(stat_position=&quot;inside_columns&quot;)  #Total   Casos   #Total cases  198  La tarjeta sanitaria no funcionaba  33  El ordenador de la farmacia no funcionaba  23  Estaba fuera de plazo (era demasiado pronto o demasiado tarde)  75  No aparecían los medicamentos recetados  57  No pudo retirarlos en una comunidad autónoma distinta a la suya  17  Otro tipo de problema  48  No recuerda   N.C.  3 4.3.1.2.2 Tablas de frecuencias relativas También se pueden, como es obvio, obtener porcentajes en las tablas marginales múltiples. A diferencia de cuando la variables es simple que todos los porcentajes suman 100, en las variables múltiples cada alternativa tiene un rango de 0 a 100, desde no ser elegida una opción en ningún registro del dataframe, hasta ser elegida por todos los registros. Usaremos nuevamente el campo P18C para procesar su información, que se localiza en el banco de datos desde P18C01 hasta P18C08. data %&gt;% tab_cells(mdset_f(P18C)) %&gt;% tab_stat_cpct(total_row_position=&quot;above&quot;, label=&quot;% casos&quot;) %&gt;% tab_pivot(stat_position=&quot;inside_columns&quot;)  #Total   % casos   #Total cases  198  La tarjeta sanitaria no funcionaba  16.7  El ordenador de la farmacia no funcionaba  11.6  Estaba fuera de plazo (era demasiado pronto o demasiado tarde)  37.9  No aparecían los medicamentos recetados  28.8  No pudo retirarlos en una comunidad autónoma distinta a la suya  8.6  Otro tipo de problema  24.2  No recuerda   N.C.  1.5 Pero vamos a introducir una njueva variación. En una múltiple, también pueden calcularse los resultados en lo que se llama base respuestas, donde sí suman 100% los porcentajes nuevamente, pero recuerda que el porcentaje hace referencia a las respuestas, no a los individuos. En este caso el script modifica el estadístico solicitado. data %&gt;% tab_cells(mdset_f(P18C)) %&gt;% tab_stat_cpct_responses(total_row_position=&quot;above&quot;, label=&quot;% casos&quot;) %&gt;% tab_pivot(stat_position=&quot;inside_columns&quot;)  #Total   % casos   #Total responses  256  La tarjeta sanitaria no funcionaba  12.9  El ordenador de la farmacia no funcionaba  9.0  Estaba fuera de plazo (era demasiado pronto o demasiado tarde)  29.3  No aparecían los medicamentos recetados  22.3  No pudo retirarlos en una comunidad autónoma distinta a la suya  6.6  Otro tipo de problema  18.8  No recuerda   N.C.  1.2 4.3.1.3 Tablas combinadas Con las múltiples también funciona el posicionamiento del estadístico casos -frecuencias- cuando combinamos los mismos (frecuencia y porcentaje) y podemos realizar las mismas variantes que antes. Ubicar los cálculos dentro de las columnas  data %&gt;% tab_cells(mdset_f(P18C)) %&gt;% # o tab_cells(mdset(P18C01 %to% P18C08)) tab_stat_cases(label =&quot;Casos&quot;) %&gt;% tab_stat_cpct(label=&quot;% casos&quot;) %&gt;% tab_stat_cpct_responses(label=&quot;% respuestas&quot;) %&gt;% tab_pivot(stat_position=&quot;inside_columns&quot;)  #Total   Casos   % casos   % respuestas   La tarjeta sanitaria no funcionaba  33 16.7 12.9  El ordenador de la farmacia no funcionaba  23 11.6 9.0  Estaba fuera de plazo (era demasiado pronto o demasiado tarde)  75 37.9 29.3  No aparecían los medicamentos recetados  57 28.8 22.3  No pudo retirarlos en una comunidad autónoma distinta a la suya  17 8.6 6.6  Otro tipo de problema  48 24.2 18.8  No recuerda   N.C.  3 1.5 1.2  #Total responses  256  #Total cases  198 198 Préstese atención a las dos líneas de #Total, dado que las bases son diferentes (número de individuos y número de respuestas). Podemos ubicar los cálculos dentro de las filas  data %&gt;% tab_cells(mdset_f(P18C)) %&gt;% # o tab_cells(mdset(P18C01 %to% P18C08)) tab_stat_cases(label =&quot;Casos&quot;) %&gt;% tab_stat_cpct(label=&quot;% casos&quot;) %&gt;% tab_stat_cpct_responses(label=&quot;% respuestas&quot;) %&gt;% tab_pivot(stat_position=&quot;inside_rows&quot;)  #Total   La tarjeta sanitaria no funcionaba     Casos  33.0    % casos  16.7    % respuestas  12.9  El ordenador de la farmacia no funcionaba     Casos  23.0    % casos  11.6    % respuestas  9.0  Estaba fuera de plazo (era demasiado pronto o demasiado tarde)     Casos  75.0    % casos  37.9    % respuestas  29.3  No aparecían los medicamentos recetados     Casos  57.0    % casos  28.8    % respuestas  22.3  No pudo retirarlos en una comunidad autónoma distinta a la suya     Casos  17.0    % casos  8.6    % respuestas  6.6  Otro tipo de problema     Casos  48.0    % casos  24.2    % respuestas  18.8  No recuerda     Casos     % casos     % respuestas   N.C.     Casos  3.0    % casos  1.5    % respuestas  1.2  #Total cases     Casos  198    % casos  198  #Total responses     % respuestas  256 Podemos ubicar los cálculos fuera de las columnas (igual a la anterior inside... porque no hay campo de columna)  data %&gt;% tab_cells(mdset_f(P18C)) %&gt;% # o tab_cells(mdset(P18C01 %to% P18C08)) tab_stat_cases(label =&quot;Casos&quot;) %&gt;% tab_stat_cpct(label=&quot;% casos&quot;) %&gt;% tab_stat_cpct_responses(label=&quot;% respuestas&quot;) %&gt;% tab_pivot(stat_position=&quot;outside_columns&quot;)  #Total   Casos   % casos   % respuestas   La tarjeta sanitaria no funcionaba  33 16.7 12.9  El ordenador de la farmacia no funcionaba  23 11.6 9.0  Estaba fuera de plazo (era demasiado pronto o demasiado tarde)  75 37.9 29.3  No aparecían los medicamentos recetados  57 28.8 22.3  No pudo retirarlos en una comunidad autónoma distinta a la suya  17 8.6 6.6  Otro tipo de problema  48 24.2 18.8  No recuerda   N.C.  3 1.5 1.2  #Total responses  256  #Total cases  198 198 Podemos ubicar los cálculos fuera de las filas  nótese que la agrupación es diferente a la anterior con inside_rows data %&gt;% tab_cells(mdset_f(P18C)) %&gt;% # o tab_cells(mdset(P18C01 %to% P18C08)) tab_stat_cases(label =&quot;Casos&quot;) %&gt;% tab_stat_cpct(label=&quot;% casos&quot;) %&gt;% tab_stat_cpct_responses(label=&quot;% respuestas&quot;) %&gt;% tab_pivot(stat_position=&quot;outside_rows&quot;)  #Total   La tarjeta sanitaria no funcionaba     Casos  33.0  El ordenador de la farmacia no funcionaba     Casos  23.0  Estaba fuera de plazo (era demasiado pronto o demasiado tarde)     Casos  75.0  No aparecían los medicamentos recetados     Casos  57.0  No pudo retirarlos en una comunidad autónoma distinta a la suya     Casos  17.0  Otro tipo de problema     Casos  48.0  No recuerda     Casos   N.C.     Casos  3.0  #Total cases     Casos  198  La tarjeta sanitaria no funcionaba     % casos  16.7  El ordenador de la farmacia no funcionaba     % casos  11.6  Estaba fuera de plazo (era demasiado pronto o demasiado tarde)     % casos  37.9  No aparecían los medicamentos recetados     % casos  28.8  No pudo retirarlos en una comunidad autónoma distinta a la suya     % casos  8.6  Otro tipo de problema     % casos  24.2  No recuerda     % casos   N.C.     % casos  1.5  #Total cases     % casos  198  La tarjeta sanitaria no funcionaba     % respuestas  12.9  El ordenador de la farmacia no funcionaba     % respuestas  9.0  Estaba fuera de plazo (era demasiado pronto o demasiado tarde)     % respuestas  29.3  No aparecían los medicamentos recetados     % respuestas  22.3  No pudo retirarlos en una comunidad autónoma distinta a la suya     % respuestas  6.6  Otro tipo de problema     % respuestas  18.8  No recuerda     % respuestas   N.C.     % respuestas  1.2  #Total responses     % respuestas  256 4.3.2 Estadísticos Hasta ahora hemos trabajado sólo con casos, pero ya hemos anticipado que al igual que con los recuentos de casos o frecuencias se puede trabajar con otros estadísticos como la suma, máximo, mínimo, media, mediana, error estándar y desviación típica. Vamos a ir viendo cómo se desarrollan estos cuadros. 4.3.2.1 Estadísticos básicos Recordemos que hasta ahora no hemos cruzado la información, solo estamos trabajando con lo que se denomina medidas marginales.Nuestro primer ejemplo es un caso típico, donde queremos obtener la media (tab_stat_mean), la desviación típica (tab_stat_sd()) y la base de cálculo, es decir el número de casos con valor (tab_stat_valid_n()) para el cálculo. Así, siguiendo la misma estructra de las tablas anteriores, redactamos el siguiente script: data %&gt;% tab_cells(P3) %&gt;% tab_stat_mean() %&gt;% tab_stat_sd() %&gt;% tab_stat_valid_n() %&gt;% tab_pivot()  #Total   Escala de satisfacción (1-10) con el funcionamiento del sistema sanitario español     Mean  7.3    Std. dev.  7.2    Valid N  2557.0 No, no tienes por qué ver los nombres de los estadísticos en lengua inglesa. También aquí podemos jugar con la etiqueta (label). data %&gt;% tab_cells(P3) %&gt;% tab_stat_mean(label = &#39;media&#39;) %&gt;% tab_stat_sd(label = &#39;desviación&#39;) %&gt;% tab_stat_valid_n(label = &#39;casos&#39;) %&gt;% tab_pivot()  #Total   Escala de satisfacción (1-10) con el funcionamiento del sistema sanitario español     media  7.3    desviación  7.2    casos  2557.0 Hagamos una nueva tabla con una pequeña variación, ahora vamos a poner los estadísticos en columnas. data%&gt;% tab_cells(P3) %&gt;% tab_stat_mean(label = &#39;media&#39;) %&gt;% tab_stat_sd(label = &#39;desviación&#39;) %&gt;% tab_stat_valid_n(label = &#39;casos&#39;) %&gt;% tab_pivot(stat_position = &quot;inside_columns&quot;)  #Total   media   desviación   casos   Escala de satisfacción (1-10) con el funcionamiento del sistema sanitario español  7.3 7.2 2557 expss tiene además la posibilidad de obtener estos tres cálculos, bastante habituales por cierto, con un solo comando: tab_stat_mean_sd_n() pudiendo añadir además etiquetas separadas. data %&gt;% tab_cells(P3) %&gt;% tab_stat_mean_sd_n(labels = c(&quot;media&quot;, &quot;desviación&quot;, &quot;casos&quot;)) %&gt;% tab_pivot()  #Total   Escala de satisfacción (1-10) con el funcionamiento del sistema sanitario español     media  7.3    desviación  7.2    casos  2557.0 4.3.2.2 Otros estadísticos Además de los estadísticos más básicos, otros que podemos añadir son el máximo, el mínimo, la mediana, el error estándar y la suma. Los unimos todos. data %&gt;% tab_cells(P3) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_stat_max(label = &quot;Máximo&quot;) %&gt;% tab_stat_min(label = &quot;Mínimo&quot;) %&gt;% tab_stat_median(label = &quot;Mediana&quot;) %&gt;% tab_stat_se(label = &quot;Error estándar&quot;) %&gt;% tab_stat_sum(label = &quot;Suma&quot;) %&gt;% tab_pivot()  #Total   Escala de satisfacción (1-10) con el funcionamiento del sistema sanitario español     Media  7.3    Desviación  7.2    Máximo  99.0    Mínimo  1.0    Mediana  7.0    Error estándar  0.1    Suma  18789.0 Nótese que no se han definido ni filas, ni columnas. Es el modificador de la posición de los estadísticos (stat_position) el que habilita la posición en una fila. Del mismo modo, estos estadísticos pueden ubicarse en las columnas. data %&gt;% tab_cells(P3) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_stat_max(label = &quot;Máximo&quot;) %&gt;% tab_stat_min(label = &quot;Mínimo&quot;) %&gt;% tab_stat_median(label = &quot;Mediana&quot;) %&gt;% tab_stat_se(label = &quot;Error estándar&quot;) %&gt;% tab_stat_sum(label = &quot;Suma&quot;) %&gt;% tab_stat_cases(label = &quot;casos&quot;) %&gt;% tab_pivot(stat_position = &quot;inside_rows&quot;)  #Total   Escala de satisfacción (1-10) con el funcionamiento del sistema sanitario español     Media  7.3    Desviación  7.2    Máximo  99.0    Mínimo  1.0    Mediana  7.0    Error estándar  0.1    Suma  18789.0    1 Muy insatisfecho/a   casos  40.0    2   casos  35.0    3   casos  75.0    4   casos  111.0    5   casos  295.0    6   casos  397.0    7   casos  584.0    8   casos  623.0    9   casos  210.0    10 Muy satisfecho/a   casos  172.0    N.S.   casos  14.0    N.C.   casos  1.0    #Total cases   casos  2557 Hagamos finalmente una leve variación. Nótese que al utilizar '|'en la etiqueta del estadístico casos, hemos eliminado la columna intermedia y aparace todo como más compacto. Este será un recurso que utilizaremos en muchas ocasiones. data %&gt;% tab_cells(P3) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_stat_max(label = &quot;Máximo&quot;) %&gt;% tab_stat_min(label = &quot;Mínimo&quot;) %&gt;% tab_stat_median(label = &quot;Mediana&quot;) %&gt;% tab_stat_se(label = &quot;Error estándar&quot;) %&gt;% tab_stat_sum(label = &quot;Suma&quot;) %&gt;% tab_stat_cases(label = &quot;|&quot;) %&gt;% tab_pivot(stat_position = &quot;inside_rows&quot;)  #Total   Escala de satisfacción (1-10) con el funcionamiento del sistema sanitario español     Media  7.3    Desviación  7.2    Máximo  99.0    Mínimo  1.0    Mediana  7.0    Error estándar  0.1    Suma  18789.0    1 Muy insatisfecho/a  40.0    2  35.0    3  75.0    4  111.0    5  295.0    6  397.0    7  584.0    8  623.0    9  210.0    10 Muy satisfecho/a  172.0    N.S.  14.0    N.C.  1.0    #Total cases  2557 4.4 Tablas cruzadas A diferencia de lo visto en el anterior capítulo, en este epígrafe analizaremos como obtener cuadros resumen en los que existen variables en la cabecera, que determinan grupos de análisis y existen variables en las filas, de las cuáles queremos conocer como se distribuyen sus alternativas de respuesta entre los diferentes perfiles o grupos que determinan las variables de columna. Al igual que sucedió con las tablas marginales, mostraremos poco a poco como trabajar con variables de respuesta simple, múltiple o con medidas estadísticas. Vamos a utilizar otros campos que se localizan en la base de datos del CIS (P3, P21A01, P21A02, P21A03, P31, P33). 4.4.1 Básica con variables simples Las tablas que vamos a hacer a continuación, siempre son tablas en las que intervienen al menos dos variables. Una de las variables irá a columnas y la otra variable irá a filas. De ellas se calcularán las frecuencias absolutas o relativas y/o los estadísticos. Vamos a empezar sólo con el estadístico frecuencias, y posteriormente ya pasaremos a estadísticos como la media, suma, etc 4.4.1.1 De frecuencias, variable simple y sólo absolutos data %&gt;% tab_cells(P33) %&gt;% tab_cols(total(), P31) %&gt;% tab_stat_cases(total_row_position = &quot;above&quot;, total_label = &quot;Total&quot;) %&gt;% tab_pivot()  #Total     Sexo de la persona entrevistada     Hombre   Mujer   Estado civil de la persona entrevistada     #Total  2557   1256 1301    Casado/a  1388   677 711    Soltero/a  817   455 362    Viudo/a  190   41 149    Separado/a  57   24 33    Divorciado/a  97   55 42    N.C.  8   4 4 4.4.1.2 De frecuencias, variable simple, con porcentajes de columna Al igual que hicimos con las tablas marginales vamos a repetir esta tabla, pero en porcentaje de columna (vertical). data %&gt;% tab_cells(P33) %&gt;% tab_cols(total(), P31) %&gt;% tab_stat_cpct(total_row_position = &quot;above&quot;, total_label = &quot;Total&quot;) %&gt;% # aquí señalo los porcentajes de columna tab_pivot()  #Total     Sexo de la persona entrevistada     Hombre   Mujer   Estado civil de la persona entrevistada     #Total  2557   1256 1301    Casado/a  54.3   53.9 54.7    Soltero/a  32.0   36.2 27.8    Viudo/a  7.4   3.3 11.5    Separado/a  2.2   1.9 2.5    Divorciado/a  3.8   4.4 3.2    N.C.  0.3   0.3 0.3 4.4.1.3 De frecuencias, variable simple, con porcentajes de fila Al igual que hicimos con las tablas marginales vamos a repetir esta tabla, pero en porcentaje de fila (horizontal). data %&gt;% tab_cells(P33) %&gt;% tab_cols(total(), P31) %&gt;% tab_stat_rpct(total_row_position = &quot;above&quot;, total_label = &quot;Total&quot;) %&gt;% # aquí señalo los porcentajes de fila tab_pivot()  #Total     Sexo de la persona entrevistada     Hombre   Mujer   Estado civil de la persona entrevistada     #Total  2557   1256 1301    Casado/a  100   48.8 51.2    Soltero/a  100   55.7 44.3    Viudo/a  100   21.6 78.4    Separado/a  100   42.1 57.9    Divorciado/a  100   56.7 43.3    N.C.  100   50.0 50.0 4.4.1.4 De frecuencias, variable simple, con porcentajes total muestra Al igual que hicimos con las tablas marginales vamos a repetir esta tabla, pero en porcentaje sobre el total de la muestra. data %&gt;% tab_cells(P33) %&gt;% tab_cols(total(), P31) %&gt;% tab_stat_tpct(total_row_position = &quot;above&quot;, total_label = &quot;Total&quot;) %&gt;% # aquí señalo los porcentajes total muestra tab_pivot()  #Total     Sexo de la persona entrevistada     Hombre   Mujer   Estado civil de la persona entrevistada     #Total  2557   1256 1301    Casado/a  54.3   26.5 27.8    Soltero/a  32.0   17.8 14.2    Viudo/a  7.4   1.6 5.8    Separado/a  2.2   0.9 1.3    Divorciado/a  3.8   2.2 1.6    N.C.  0.3   0.2 0.2 4.4.1.5 Combinaciones de los anteriores Vamos ahora a hacer combinaciones entre ellos. Advierto que cada vez se dificulta más la tabla en su lectura. Como dije inicialmente, me decanto más por tablas sencillas y con un sólo dato. data %&gt;% tab_cells(P33) %&gt;% tab_cols(total(), P31) %&gt;% tab_stat_cases(label = &quot;Casos&quot;) %&gt;% tab_stat_cpct(label = &quot;% casos&quot;) %&gt;% tab_pivot(stat_position = &quot;inside_columns&quot;)  #Total     Sexo de la persona entrevistada   Casos     % casos     Hombre     Mujer       Casos   % casos     Casos   % casos   Estado civil de la persona entrevistada     Casado/a  1388   54.3   677 53.9   711 54.7    Soltero/a  817   32.0   455 36.2   362 27.8    Viudo/a  190   7.4   41 3.3   149 11.5    Separado/a  57   2.2   24 1.9   33 2.5    Divorciado/a  97   3.8   55 4.4   42 3.2    N.C.  8   0.3   4 0.3   4 0.3    #Total cases  2557   2557   1256 1256   1301 1301 Y la misma tabla pero con los estadísticos en las filas combinando frecuencia y porcentaje data %&gt;% tab_cells(P33) %&gt;% tab_cols(total(), P31) %&gt;% tab_stat_cases(label = &quot;Casos&quot;) %&gt;% tab_stat_cpct(label = &quot;% casos&quot;) %&gt;% tab_pivot(stat_position = &quot;outside_columns&quot;)  #Total     Sexo de la persona entrevistada     #Total     Sexo de la persona entrevistada   Casos     Hombre     Mujer     % casos     Hombre     Mujer     Casos     Casos       % casos     % casos   Estado civil de la persona entrevistada     Casado/a  1388   677   711   54.3   53.9   54.7    Soltero/a  817   455   362   32.0   36.2   27.8    Viudo/a  190   41   149   7.4   3.3   11.5    Separado/a  57   24   33   2.2   1.9   2.5    Divorciado/a  97   55   42   3.8   4.4   3.2    N.C.  8   4   4   0.3   0.3   0.3    #Total cases  2557   1256   1301   2557   1256   1301 Y la misma tabla pero con los estadísticos en las filas combinando frecuencia y porcentaje data %&gt;% tab_cells(P33) %&gt;% tab_cols(total(), P31) %&gt;% tab_stat_cases(label = &quot;Casos&quot;) %&gt;% tab_stat_cpct(label = &quot;% casos&quot;) %&gt;% tab_pivot(stat_position = &quot;inside_rows&quot;)    #Total     Sexo de la persona entrevistada       Hombre   Mujer   Estado civil de la persona entrevistada     Casado/a   Casos    1388.0   677.0 711.0     % casos    54.3   53.9 54.7    Soltero/a   Casos    817.0   455.0 362.0     % casos    32.0   36.2 27.8    Viudo/a   Casos    190.0   41.0 149.0     % casos    7.4   3.3 11.5    Separado/a   Casos    57.0   24.0 33.0     % casos    2.2   1.9 2.5    Divorciado/a   Casos    97.0   55.0 42.0     % casos    3.8   4.4 3.2    N.C.   Casos    8.0   4.0 4.0     % casos    0.3   0.3 0.3    #Total cases   Casos    2557   1256 1301     % casos    2557   1256 1301 Y la misma tabla pero con los estadísticos en las filas por bloque de tipo de estadístico data %&gt;% tab_cells(P33) %&gt;% tab_cols(total(), P31) %&gt;% tab_stat_cases(label = &quot;Casos&quot;) %&gt;% tab_stat_cpct(label = &quot;% casos&quot;) %&gt;% tab_pivot(stat_position = &quot;outside_rows&quot;)    #Total     Sexo de la persona entrevistada       Hombre   Mujer   Estado civil de la persona entrevistada     Casado/a   Casos    1388.0   677.0 711.0    Soltero/a   Casos    817.0   455.0 362.0    Viudo/a   Casos    190.0   41.0 149.0    Separado/a   Casos    57.0   24.0 33.0    Divorciado/a   Casos    97.0   55.0 42.0    N.C.   Casos    8.0   4.0 4.0    #Total cases   Casos    2557   1256 1301    Casado/a   % casos    54.3   53.9 54.7    Soltero/a   % casos    32.0   36.2 27.8    Viudo/a   % casos    7.4   3.3 11.5    Separado/a   % casos    2.2   1.9 2.5    Divorciado/a   % casos    3.8   4.4 3.2    N.C.   % casos    0.3   0.3 0.3    #Total cases   % casos    2557   1256 1301 4.4.2 Básica con múltiples Vamos a realizar ahora el mismo conjunto de tablas, pero en las filas, en lugar de una variable de tipo simple, vamos a utilizar una variable de tipo múltiple. Repetimos los cruces pero cambiamos las celdas donde ahora usaremos la variable P21A con la instrucción tab_cells(mdset(P21A01 %to% P21A03)). 4.4.2.1 De frecuencias, variable múltiple y sólo absolutos data %&gt;% tab_cells(mdset(P21A01 %to% P21A03)) %&gt;% tab_cols(total(), P31) %&gt;% tab_stat_cases(total_row_position = &quot;above&quot;, total_label = &quot;Total&quot;) %&gt;% tab_pivot()  #Total     Sexo de la persona entrevistada     Hombre   Mujer   #Total  415   206 209  Medicamentos que recetan por adelantado (para que no falten)  225   108 117  Envases que han quedado sin usar porque cambiaron el tratamiento  136   70 66  Medicamentos que decidió no tomar  82   42 40 4.4.2.2 De frecuencias, variable múltiple, con porcentajes de columna Al igual que hicimos con las tablas marginales vamos a repetir esta tabla, pero en porcentaje de columna (vertical). data %&gt;% tab_cells(mdset(P21A01 %to% P21A03)) %&gt;% tab_cols(total(), P31) %&gt;% tab_stat_cpct(total_row_position = &quot;above&quot;, total_label = &quot;Total&quot;) %&gt;% # aquí señalo los porcentajes de columna tab_pivot()  #Total     Sexo de la persona entrevistada     Hombre   Mujer   #Total  415   206 209  Medicamentos que recetan por adelantado (para que no falten)  54.2   52.4 56.0  Envases que han quedado sin usar porque cambiaron el tratamiento  32.8   34.0 31.6  Medicamentos que decidió no tomar  19.8   20.4 19.1 4.4.2.3 De frecuencias, variable múltiple, con porcentajes de fila Al igual que hicimos con las tablas marginales vamos a repetir esta tabla, pero en porcentaje de fila (horizontal). data %&gt;% tab_cells(mdset(P21A01 %to% P21A03)) %&gt;% tab_cols(total(), P31) %&gt;% tab_stat_rpct(total_row_position = &quot;above&quot;, total_label = &quot;Total&quot;) %&gt;% # aquí señalo los porcentajes de fila tab_pivot()  #Total     Sexo de la persona entrevistada     Hombre   Mujer   #Total  415   206 209  Medicamentos que recetan por adelantado (para que no falten)  100   48.0 52.0  Envases que han quedado sin usar porque cambiaron el tratamiento  100   51.5 48.5  Medicamentos que decidió no tomar  100   51.2 48.8 4.4.2.4 De frecuencias, variable múltiple, con porcentajes total muestra Al igual que hicimos con las tablas marginales vamos a repetir esta tabla, pero en porcentaje sobre el total de la muestra. data %&gt;% tab_cells(mdset(P21A01 %to% P21A03)) %&gt;% tab_cols(total(), P31) %&gt;% tab_stat_tpct(total_row_position = &quot;above&quot;, total_label = &quot;Total&quot;) %&gt;% # aquí señalo los porcentajes total muestra tab_pivot()  #Total     Sexo de la persona entrevistada     Hombre   Mujer   #Total  415   206 209  Medicamentos que recetan por adelantado (para que no falten)  54.2   26.0 28.2  Envases que han quedado sin usar porque cambiaron el tratamiento  32.8   16.9 15.9  Medicamentos que decidió no tomar  19.8   10.1 9.6 4.4.2.5 Combinaciones de los anteriores Vamos ahora a hacer combinaciones entre ellos. Advierto que cada vez se dificulta más la tabla en su lectura. Como dije inicialmente, me decanto más por tablas sencillas y con un sólo dato. data %&gt;% tab_cells(mdset(P21A01 %to% P21A03)) %&gt;% tab_cols(total(), P31) %&gt;% tab_stat_cases(label = &quot;Casos&quot;) %&gt;% tab_stat_cpct(label = &quot;% casos&quot;) %&gt;% tab_pivot(stat_position = &quot;inside_columns&quot;)  #Total     Sexo de la persona entrevistada   Casos     % casos     Hombre     Mujer       Casos   % casos     Casos   % casos   Medicamentos que recetan por adelantado (para que no falten)  225   54.2   108 52.4   117 56.0  Envases que han quedado sin usar porque cambiaron el tratamiento  136   32.8   70 34.0   66 31.6  Medicamentos que decidió no tomar  82   19.8   42 20.4   40 19.1  #Total cases  415   415   206 206   209 209 Y la misma tabla pero con los estadísticos en las filas combinando frecuencia y porcentaje data %&gt;% tab_cells(mdset(P21A01 %to% P21A03)) %&gt;% tab_cols(total(), P31) %&gt;% tab_stat_cases(label = &quot;Casos&quot;) %&gt;% tab_stat_cpct(label = &quot;% casos&quot;) %&gt;% tab_pivot(stat_position = &quot;outside_columns&quot;)  #Total     Sexo de la persona entrevistada     #Total     Sexo de la persona entrevistada   Casos     Hombre     Mujer     % casos     Hombre     Mujer     Casos     Casos       % casos     % casos   Medicamentos que recetan por adelantado (para que no falten)  225   108   117   54.2   52.4   56.0  Envases que han quedado sin usar porque cambiaron el tratamiento  136   70   66   32.8   34.0   31.6  Medicamentos que decidió no tomar  82   42   40   19.8   20.4   19.1  #Total cases  415   206   209   415   206   209 Y la misma tabla pero con los estadísticos en las filas combinando frecuencia y porcentaje data %&gt;% tab_cells(mdset(P21A01 %to% P21A03)) %&gt;% tab_cols(total(), P31) %&gt;% tab_stat_cases(label = &quot;Casos&quot;) %&gt;% tab_stat_cpct(label = &quot;% casos&quot;) %&gt;% tab_pivot(stat_position = &quot;inside_rows&quot;)  #Total     Sexo de la persona entrevistada     Hombre   Mujer   Medicamentos que recetan por adelantado (para que no falten)     Casos  225.0   108.0 117.0    % casos  54.2   52.4 56.0  Envases que han quedado sin usar porque cambiaron el tratamiento     Casos  136.0   70.0 66.0    % casos  32.8   34.0 31.6  Medicamentos que decidió no tomar     Casos  82.0   42.0 40.0    % casos  19.8   20.4 19.1  #Total cases     Casos  415   206 209    % casos  415   206 209 Y la misma tabla pero con los estadísticos en las filas por bloque de tipo de estadístico data %&gt;% tab_cells(mdset(P21A01 %to% P21A03)) %&gt;% tab_cols(total(), P31) %&gt;% tab_stat_cases(label = &quot;Casos&quot;) %&gt;% tab_stat_cpct(label = &quot;% casos&quot;) %&gt;% tab_pivot(stat_position = &quot;outside_rows&quot;)  #Total     Sexo de la persona entrevistada     Hombre   Mujer   Medicamentos que recetan por adelantado (para que no falten)     Casos  225.0   108.0 117.0  Envases que han quedado sin usar porque cambiaron el tratamiento     Casos  136.0   70.0 66.0  Medicamentos que decidió no tomar     Casos  82.0   42.0 40.0  #Total cases     Casos  415   206 209  Medicamentos que recetan por adelantado (para que no falten)     % casos  54.2   52.4 56.0  Envases que han quedado sin usar porque cambiaron el tratamiento     % casos  32.8   34.0 31.6  Medicamentos que decidió no tomar     % casos  19.8   20.4 19.1  #Total cases     % casos  415   206 209 Recordamos que siempre con las múltiples existe la posibilidad de calcular los porcentajes con base respuesta en lugar de con base cuestionario (individuos). Para ello debes utilizar tab_stat_cpct_responses(). 4.4.3 Básica con estadísticos Del mismo modo que antes utilizábamos la tabla cruzada para obtener los casos de intersección entre las categorías de columna y las categorías de fila, ahora procederemos a hacer lo mismo pero con categorías en columnas y cálculo de estadísticos básicos en otro. En definitiva, calcular las medidas estadísticas para cada grupo creado por la variable que general las categorías. 4.4.3.1 Cruce entre variable simple y dos estadísticos Vamos a comenzar con las más simples, dos estadísticos (media y desviación) de una variable métrica (P3) calculados para una variable (P31) que genera dos categorías (hombre y mujer). Nótese el juego a realizar con más de 2 estadísticos con la ubicación de los mismos. data %&gt;% tab_cells(P3) %&gt;% tab_cols(total(), P31) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_pivot()  #Total     Sexo de la persona entrevistada     Hombre   Mujer   Escala de satisfacción (1-10) con el funcionamiento del sistema sanitario español     Media  7.3   7.3 7.4    Desviación  7.2   6.6 7.8 Hagamos ahora su traspuesta, es decir ubiquemos en filas P31 y en columnas var_lab(data$P3)=&quot;Satisfacción&quot; data %&gt;% tab_cells(P3) %&gt;% tab_rows(total(),P31) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_pivot()  #Total   #Total     Satisfacción   Media  7.3  Sexo de la persona entrevistada     Hombre   Satisfacción   Media  7.3    Mujer   Satisfacción   Media  7.4  #Total     Satisfacción   Desviación  7.2  Sexo de la persona entrevistada     Hombre   Satisfacción   Desviación  6.6    Mujer   Satisfacción   Desviación  7.8 Recordemos que los estadísticos los podemos ir moviendo a nuestra necesidad para que se organicen de una forma u otra Dentro de las columnas  data %&gt;% tab_cells(P3) %&gt;% tab_cols(total(), P31) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_pivot(stat_position = &quot;inside_columns&quot;)  #Total     Sexo de la persona entrevistada   Media     Desviación     Hombre     Mujer       Media   Desviación     Media   Desviación   Satisfacción  7.3   7.2   7.3 6.6   7.4 7.8 Dentro de las filas  data %&gt;% tab_cells(P3) %&gt;% tab_cols(total(), P31) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_pivot(stat_position = &quot;inside_rows&quot;)  #Total     Sexo de la persona entrevistada     Hombre   Mujer   Satisfacción     Media  7.3   7.3 7.4    Desviación  7.2   6.6 7.8 Como columnas separadas o fuera de columnas  data %&gt;% tab_cells(P3) %&gt;% tab_cols(total(), P31) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_pivot(stat_position = &quot;outside_columns&quot;)  #Total     Sexo de la persona entrevistada     #Total     Sexo de la persona entrevistada   Media     Hombre     Mujer     Desviación     Hombre     Mujer     Media     Media       Desviación     Desviación   Satisfacción  7.3   7.3   7.4   7.2   6.6   7.8 Como filas separadas o fuera de filas data %&gt;% tab_cells(P3) %&gt;% tab_cols(total(), P31) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_pivot(stat_position = &quot;outside_rows&quot;)  #Total     Sexo de la persona entrevistada     Hombre   Mujer   Satisfacción     Media  7.3   7.3 7.4    Desviación  7.2   6.6 7.8 Repitamos ahora estas cuatro últimas tablas, pero en lugar de con una variable que genera grupos y de ellos se calcula la medida estadística, vamos a hacerlo con un cruce de categorías (un campo en columnas y otro en filas) y que en esos cruces, se calcule la medida estadística. Por ejemplo esta tabla me permitiría saber la media de P3 en los hombres de 18 a 25 años. data %&gt;% tab_cells(P3) %&gt;% tab_cols(total(), P31) %&gt;% tab_rows(P33) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_pivot()    #Total     Sexo de la persona entrevistada       Hombre   Mujer   Estado civil de la persona entrevistada     Casado/a   Satisfacción   Media    7.3   7.5 7.2    Soltero/a   Satisfacción   Media    7.2   6.9 7.4    Viudo/a   Satisfacción   Media    7.9   7.2 8.1    Separado/a   Satisfacción   Media    6.7   6.5 6.9    Divorciado/a   Satisfacción   Media    7.5   8.3 6.3    N.C.   Satisfacción   Media    18.2   7.5 29.0    Casado/a   Satisfacción   Desviación    6.7   7.2 6.2    Soltero/a   Satisfacción   Desviación    7.4   4.6 9.8    Viudo/a   Satisfacción   Desviación    6.9   2.3 7.7    Separado/a   Satisfacción   Desviación    2.1   2.5 1.8    Divorciado/a   Satisfacción   Desviación    9.5   12.5 2.3    N.C.   Satisfacción   Desviación    32.3   2.4 46.0 y juguemos con la posición del cálculo estadística que ahora sí arrojará cuatro configuraciones diferentes. La primera con los estadísticos fuera de las filas data %&gt;% tab_cells(P3) %&gt;% tab_cols(total(), P31) %&gt;% tab_rows(P33) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_pivot(stat_position = &quot;outside_rows&quot;) # por defecto, sin lo ponemos muestra esta opción    #Total     Sexo de la persona entrevistada       Hombre   Mujer   Estado civil de la persona entrevistada     Casado/a   Satisfacción   Media    7.3   7.5 7.2    Soltero/a   Satisfacción   Media    7.2   6.9 7.4    Viudo/a   Satisfacción   Media    7.9   7.2 8.1    Separado/a   Satisfacción   Media    6.7   6.5 6.9    Divorciado/a   Satisfacción   Media    7.5   8.3 6.3    N.C.   Satisfacción   Media    18.2   7.5 29.0    Casado/a   Satisfacción   Desviación    6.7   7.2 6.2    Soltero/a   Satisfacción   Desviación    7.4   4.6 9.8    Viudo/a   Satisfacción   Desviación    6.9   2.3 7.7    Separado/a   Satisfacción   Desviación    2.1   2.5 1.8    Divorciado/a   Satisfacción   Desviación    9.5   12.5 2.3    N.C.   Satisfacción   Desviación    32.3   2.4 46.0 Los estadísticos dentro de las filas  data %&gt;% tab_cells(P3) %&gt;% tab_cols(total(), P31) %&gt;% tab_rows(P33) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_pivot(stat_position = &quot;inside_rows&quot;)    #Total     Sexo de la persona entrevistada       Hombre   Mujer   Estado civil de la persona entrevistada     Casado/a   Satisfacción   Media    7.3   7.5 7.2     Desviación    6.7   7.2 6.2    Soltero/a   Satisfacción   Media    7.2   6.9 7.4     Desviación    7.4   4.6 9.8    Viudo/a   Satisfacción   Media    7.9   7.2 8.1     Desviación    6.9   2.3 7.7    Separado/a   Satisfacción   Media    6.7   6.5 6.9     Desviación    2.1   2.5 1.8    Divorciado/a   Satisfacción   Media    7.5   8.3 6.3     Desviación    9.5   12.5 2.3    N.C.   Satisfacción   Media    18.2   7.5 29.0     Desviación    32.3   2.4 46.0 Los estadísticos dentro de las columnas  data %&gt;% tab_cells(P3) %&gt;% tab_cols(total(), P31) %&gt;% tab_rows(P33) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_pivot(stat_position = &quot;inside_columns&quot;)    #Total     Sexo de la persona entrevistada     Media     Desviación     Hombre     Mujer         Media   Desviación     Media   Desviación   Estado civil de la persona entrevistada     Casado/a   Satisfacción    7.3   6.7   7.5 7.2   7.2 6.2    Soltero/a   Satisfacción    7.2   7.4   6.9 4.6   7.4 9.8    Viudo/a   Satisfacción    7.9   6.9   7.2 2.3   8.1 7.7    Separado/a   Satisfacción    6.7   2.1   6.5 2.5   6.9 1.8    Divorciado/a   Satisfacción    7.5   9.5   8.3 12.5   6.3 2.3    N.C.   Satisfacción    18.2   32.3   7.5 2.4   29.0 46.0 Los estadísticos fuera de las columnas  data %&gt;% tab_cells(P3) %&gt;% tab_cols(total(), P31) %&gt;% tab_rows(P33) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_pivot(stat_position = &quot;outside_columns&quot;)    #Total     Sexo de la persona entrevistada     #Total     Sexo de la persona entrevistada     Media     Hombre     Mujer     Desviación     Hombre     Mujer       Media     Media       Desviación     Desviación   Estado civil de la persona entrevistada     Casado/a   Satisfacción    7.3   7.5   7.2   6.7   7.2   6.2    Soltero/a   Satisfacción    7.2   6.9   7.4   7.4   4.6   9.8    Viudo/a   Satisfacción    7.9   7.2   8.1   6.9   2.3   7.7    Separado/a   Satisfacción    6.7   6.5   6.9   2.1   2.5   1.8    Divorciado/a   Satisfacción    7.5   8.3   6.3   9.5   12.5   2.3    N.C.   Satisfacción    18.2   7.5   29.0   32.3   2.4   46.0 ¿Hacemos lo mismo para una variable múltiple? 4.4.3.1.1 Tabulación cruzada (con cálculo estadístico) y múltiples Vamos a comenzar con las más simples, dos estadísticos (media y desviación) de una variable métrica (P3) calculados para una variable múltiple (P4_1 a P4_3) que genera categorías. Nótese el juego a realizar con más de 2 estadísticos con la ubicación de los mismos. data %&gt;% tab_cells(P3) %&gt;% tab_cols(total(), mdset(P21A01 %to% P21A03)) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_pivot()  #Total   Medicamentos que recetan por adelantado (para que no falten)   Envases que han quedado sin usar porque cambiaron el tratamiento   Medicamentos que decidió no tomar   Satisfacción     Media  7.3 7.2 6.9 6.7    Desviación  7.2 6.4 1.5 1.7 Hagamos ahora su traspuesta, es decir ubiquemos en filas P21A y en columnas P3. data %&gt;% tab_cells(P3) %&gt;% tab_rows(total(),mdset(P21A01 %to% P21A03)) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_pivot()  #Total   #Total     Satisfacción   Media  7.3  Medicamentos que recetan por adelantado (para que no falten)     Satisfacción   Media  7.2  Envases que han quedado sin usar porque cambiaron el tratamiento     Satisfacción   Media  6.9  Medicamentos que decidió no tomar     Satisfacción   Media  6.7  #Total     Satisfacción   Desviación  7.2  Medicamentos que recetan por adelantado (para que no falten)     Satisfacción   Desviación  6.4  Envases que han quedado sin usar porque cambiaron el tratamiento     Satisfacción   Desviación  1.5  Medicamentos que decidió no tomar     Satisfacción   Desviación  1.7 Recordemos que los estadísticos los podemos ir moviendo a nuestra necesidad para que se organicen de una forma u otra Dentro de columnas  data %&gt;% tab_cells(P3) %&gt;% tab_cols(total(), mdset(P21A01 %to% P21A03)) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_pivot(stat_position = &quot;inside_columns&quot;)  #Total     Medicamentos que recetan por adelantado (para que no falten)     Envases que han quedado sin usar porque cambiaron el tratamiento     Medicamentos que decidió no tomar   Media   Desviación     Media   Desviación     Media   Desviación     Media   Desviación   Satisfacción  7.3 7.2   7.2 6.4   6.9 1.5   6.7 1.7 Dentro de filas  data %&gt;% tab_cells(P3) %&gt;% tab_cols(total(), mdset(P21A01 %to% P21A03)) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_pivot(stat_position = &quot;inside_rows&quot;)  #Total   Medicamentos que recetan por adelantado (para que no falten)   Envases que han quedado sin usar porque cambiaron el tratamiento   Medicamentos que decidió no tomar   Satisfacción     Media  7.3 7.2 6.9 6.7    Desviación  7.2 6.4 1.5 1.7 Fuera de columnas  data %&gt;% tab_cells(P3) %&gt;% tab_cols(total(), mdset(P21A01 %to% P21A03)) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_pivot(stat_position = &quot;outside_columns&quot;)  #Total     Medicamentos que recetan por adelantado (para que no falten)     Envases que han quedado sin usar porque cambiaron el tratamiento     Medicamentos que decidió no tomar     #Total     Medicamentos que recetan por adelantado (para que no falten)     Envases que han quedado sin usar porque cambiaron el tratamiento     Medicamentos que decidió no tomar   Media     Media     Media     Media     Desviación     Desviación     Desviación     Desviación   Satisfacción  7.3   7.2   6.9   6.7   7.2   6.4   1.5   1.7 Fuera de filas  data %&gt;% tab_cells(P3) %&gt;% tab_cols(total(), mdset(P21A01 %to% P21A03)) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_pivot(stat_position = &quot;outside_rows&quot;)  #Total   Medicamentos que recetan por adelantado (para que no falten)   Envases que han quedado sin usar porque cambiaron el tratamiento   Medicamentos que decidió no tomar   Satisfacción     Media  7.3 7.2 6.9 6.7    Desviación  7.2 6.4 1.5 1.7 Repitamos ahora estas cuatro últimas tablas, pero en lugar de con una variable que genera grupos y de ellos se calcula la medida estadística, vamos a hacerlo con un cruce de categorías (un campo en columnas y otro en filas) y que en esos cruces, se calcule la medida estadística. Por ejemplo esta tabla me permitiría saber la media de P3 en los hombres de 18 a 25 años. data %&gt;% tab_cells(P3) %&gt;% tab_cols(total(), mdset(P21A01 %to% P21A03)) %&gt;% tab_rows(P33) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_pivot()  #Total   Medicamentos que recetan por adelantado (para que no falten)   Envases que han quedado sin usar porque cambiaron el tratamiento   Medicamentos que decidió no tomar   Estado civil de la persona entrevistada     Casado/a   Satisfacción   Media  7.3 6.7 6.7 7.0    Soltero/a   Satisfacción   Media  7.2 8.2 6.8 6.4    Viudo/a   Satisfacción   Media  7.9 7.3 7.8 5.0    Separado/a   Satisfacción   Media  6.7 7.8 5.3 5.0    Divorciado/a   Satisfacción   Media  7.5 6.4 7.1 8.7    N.C.   Satisfacción   Media  18.2    Casado/a   Satisfacción   Desviación  6.7 2.0 1.5 1.3    Soltero/a   Satisfacción   Desviación  7.4 11.4 1.4 2.0    Viudo/a   Satisfacción   Desviación  6.9 1.7 2.0    Separado/a   Satisfacción   Desviación  2.1 0.8 0.6    Divorciado/a   Satisfacción   Desviación  9.5 2.1 1.2 2.3    N.C.   Satisfacción   Desviación  32.3 y juguemos con la posición del cálculo estadística que ahora sí arrojará cuatro configuraciones diferentes. La primera con los estadísticos dentro de las filas es idéntica a la anterior (por defecto). data %&gt;% tab_cells(P3) %&gt;% tab_cols(total(), mdset(P21A01 %to% P21A03)) %&gt;% tab_rows(P33) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_pivot(stat_position = &quot;outside_rows&quot;) # por defecto, sin lo ponemos muestra esta opción  #Total   Medicamentos que recetan por adelantado (para que no falten)   Envases que han quedado sin usar porque cambiaron el tratamiento   Medicamentos que decidió no tomar   Estado civil de la persona entrevistada     Casado/a   Satisfacción   Media  7.3 6.7 6.7 7.0    Soltero/a   Satisfacción   Media  7.2 8.2 6.8 6.4    Viudo/a   Satisfacción   Media  7.9 7.3 7.8 5.0    Separado/a   Satisfacción   Media  6.7 7.8 5.3 5.0    Divorciado/a   Satisfacción   Media  7.5 6.4 7.1 8.7    N.C.   Satisfacción   Media  18.2    Casado/a   Satisfacción   Desviación  6.7 2.0 1.5 1.3    Soltero/a   Satisfacción   Desviación  7.4 11.4 1.4 2.0    Viudo/a   Satisfacción   Desviación  6.9 1.7 2.0    Separado/a   Satisfacción   Desviación  2.1 0.8 0.6    Divorciado/a   Satisfacción   Desviación  9.5 2.1 1.2 2.3    N.C.   Satisfacción   Desviación  32.3 Los estadísticos fuera de las filas  data %&gt;% tab_cells(P3) %&gt;% tab_cols(total(), mdset(P21A01 %to% P21A03)) %&gt;% tab_rows(P33) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_pivot(stat_position = &quot;inside_rows&quot;)  #Total   Medicamentos que recetan por adelantado (para que no falten)   Envases que han quedado sin usar porque cambiaron el tratamiento   Medicamentos que decidió no tomar   Estado civil de la persona entrevistada     Casado/a   Satisfacción   Media  7.3 6.7 6.7 7.0     Desviación  6.7 2.0 1.5 1.3    Soltero/a   Satisfacción   Media  7.2 8.2 6.8 6.4     Desviación  7.4 11.4 1.4 2.0    Viudo/a   Satisfacción   Media  7.9 7.3 7.8 5.0     Desviación  6.9 1.7 2.0    Separado/a   Satisfacción   Media  6.7 7.8 5.3 5.0     Desviación  2.1 0.8 0.6    Divorciado/a   Satisfacción   Media  7.5 6.4 7.1 8.7     Desviación  9.5 2.1 1.2 2.3    N.C.   Satisfacción   Media  18.2     Desviación  32.3 Los estadísticos dentro de las columnas  data %&gt;% tab_cells(P3) %&gt;% tab_cols(total(), mdset(P21A01 %to% P21A03)) %&gt;% tab_rows(P33) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_pivot(stat_position = &quot;inside_columns&quot;)    #Total     Medicamentos que recetan por adelantado (para que no falten)     Envases que han quedado sin usar porque cambiaron el tratamiento     Medicamentos que decidió no tomar     Media   Desviación     Media   Desviación     Media   Desviación     Media   Desviación   Estado civil de la persona entrevistada     Casado/a   Satisfacción    7.3 6.7   6.7 2.0   6.7 1.5   7.0 1.3    Soltero/a   Satisfacción    7.2 7.4   8.2 11.4   6.8 1.4   6.4 2.0    Viudo/a   Satisfacción    7.9 6.9   7.3 1.7   7.8 2.0   5.0    Separado/a   Satisfacción    6.7 2.1   7.8 0.8   5.3 0.6   5.0    Divorciado/a   Satisfacción    7.5 9.5   6.4 2.1   7.1 1.2   8.7 2.3    N.C.   Satisfacción    18.2 32.3       Los estadísticos fuera de las columnas  data %&gt;% tab_cells(P3) %&gt;% tab_cols(total(), mdset(P21A01 %to% P21A03)) %&gt;% tab_rows(P33) %&gt;% tab_stat_mean(label = &quot;Media&quot;) %&gt;% tab_stat_sd(label = &quot;Desviación&quot;) %&gt;% tab_pivot(stat_position = &quot;outside_columns&quot;)    #Total     Medicamentos que recetan por adelantado (para que no falten)     Envases que han quedado sin usar porque cambiaron el tratamiento     Medicamentos que decidió no tomar     #Total     Medicamentos que recetan por adelantado (para que no falten)     Envases que han quedado sin usar porque cambiaron el tratamiento     Medicamentos que decidió no tomar     Media     Media     Media     Media     Desviación     Desviación     Desviación     Desviación   Estado civil de la persona entrevistada     Casado/a   Satisfacción    7.3   6.7   6.7   7.0   6.7   2.0   1.5   1.3    Soltero/a   Satisfacción    7.2   8.2   6.8   6.4   7.4   11.4   1.4   2.0    Viudo/a   Satisfacción    7.9   7.3   7.8   5.0   6.9   1.7   2.0      Separado/a   Satisfacción    6.7   7.8   5.3   5.0   2.1   0.8   0.6      Divorciado/a   Satisfacción    7.5   6.4   7.1   8.7   9.5   2.1   1.2   2.3    N.C.   Satisfacción    18.2         32.3       Bien, como has podido observar, el resultado no difiere cuando es múltiple a cuando es simple. Igual que hemos calculado la media y la desviación lo podemos hacer con otros estadísticos: media desviación máximo mínimo mediana suma error estándar un caso especial que calcula media, desviación y nº de casos algunos otros que iremos mostrando para temas muy específicos. 4.5 Conclusión Creo que esta primera muestra de cómo procesar tablas de una única variable o cruizadas, es más que suficiente para colmar las expectativas más exigentes. Para aquellos que conozcan un poco más el funcionamiento de R, indicar que cada una de estas tablas, se puede almacenar como objeto sobre el que se puede trabajar. Este objeto es del tipo etable pero en el fondo es un objeto de tipo dataframe que por tanto puedes ser trabajado con comandos R estándar. Es de esta posibilidad de ser un dataframe de donde deriva su capacidad de integración con otros paquetes como por ejemplo highcharter Kunst (2020) que será uno de nuestros paquetes de referencia para gráficos. Para una presentación completa, véase la sesión R2, visualizacion gráfica para una presentación de gráficos a partir de dataframe o de tablas marginales / cruzadas. 4.6 Pruebas inferenciales Cuando trabajamos con tablas de contingencia es muy frecuente que sintamos la necesidad de tener que inferir acerca de la dependencia de las categorías analizadas o de las diferencias entre los grupos analizados. Siempre que nuestras variables cumplan con los requisitos que para ellas cada prueba establece (normalidad, homoscedasticidad, linealidad y en algunos casos independencia), podremos aplicar las pruebas inferenciales típicas con tablas de contingencia en la investigación básica: Chi2 en su variantes de tabla y celda; Pruebas z de contraste proporciones; Prueba t de contraste de medias. Para todas ellas expss nos da la oportunidad de hacer los cálculos desde el propio script de realización de la tabla y/o desde una instrucción posterior a la realización de la tabla. Pasemos por ello a explicar, no tanto el cometido de estas pruebas, sino el como llevarlas adelante. 4.6.1 Prueba de dependencia El contraste Chi2 de Pearson es una prueba estadística no paramétrica, que compara las frecuencias realmente obtenidas con las frecuencias esperadas que son las que corresponderían a cada celda o casilla de la tabla si su valor se ajustase a cualquier norma teórica previamente adoptada; en nuestro caso, una distribución proporcional de frecuencias normales. En definitiva, se está calculando un índice acerca de la distancia entre lo real y lo esperado Manzano Arrondo (1995). El valor numérico de esta prueba se obtiene como: fo, serán las frecuencias observadas en el experimento o muestra fe, serán las frecuencias esperadas teóricamente Las frecuencias esperadas se calculan con  fo, serán las frecuencias observadas en el experimento o muestra fe, serán las frecuencias esperadas teóricamente N, es el número de efectivos muestrales Esta prueba se suele utilizar (entre muchas otras posibilidades) para contrastar la hipótesis nula que los resultados obtenidos de una muestra no son significativos con relación a la población total, o bien como prueba de dependencia para comprobar la existencia o no de asociación entre las variables. En este caso, la prueba indica la existencia de asociación pero no la cuantifica Manzano Arrondo (1995). 4.6.1.1 De una tabla La prueba Chi2 puede hacerse a nivel de tabla, lo que muestra la relación de dependencia entre las categorías. Hagamos una primera aproximación con dos tablas de contingencia muy sencillas, pero que nos mostrarán como se indica que la relación de dependencia existe o no existe. La función tab_last_sig_cases realiza la prueba base de R denominada chisq.test. Nótese el uso de |=unvr() para utilizar la variable sin que se publiquen los texto extra de la misma. data %&gt;% tab_cols(total(), &#39;|&#39;=unvr(P31)) %&gt;% tab_cells(&#39;|&#39;=unvr(P2)) %&gt;% tab_stat_cases() %&gt;% tab_last_sig_cases() %&gt;% tab_pivot()  #Total   Hombre   Mujer   En general, el sistema sanitario funciona bastante bien  538.0  277.0  261.0   El sistema sanitario funciona bien, aunque son necesarios al  1247.0  620.0  627.0   El sistema sanitario necesita cambios fundamentales, aunque   637.0  288.0  349.0   Nuestro sistema sanitario está tan mal que necesitaríamos re  120.0  61.0  59.0   N.S.  9.0  6.0  3.0   N.C.  6.0  4.0  2.0   #Chi-squared p-value  (warn.)  #Total cases  2557.0  1256.0  1301.0  data %&gt;% tab_cols(total(), &#39;|&#39;=unvr(P31)) %&gt;% tab_cells(&#39;|&#39;=unvr(P33)) %&gt;% tab_stat_cases() %&gt;% tab_last_sig_cases() %&gt;% tab_pivot()  #Total   Hombre   Mujer   Casado/a  1388.0  677.0  711.0   Soltero/a  817.0  455.0  362.0   Viudo/a  190.0  41.0  149.0   Separado/a  57.0  24.0  33.0   Divorciado/a  97.0  55.0  42.0   N.C.  8.0  4.0  4.0   #Chi-squared p-value  &lt;0.05 (warn.)  #Total cases  2557.0  1256.0  1301.0  En la primera tabla se muestra la relación entre la variable P31 (sexo) y la P2 (valoración del sistema sanitario). Nótese que en la tabla se ha usado una línea tras el cálculo de los casos con la función tab_last_sig_cases() que indica que se debe realizar la prueba Chi2 a la relación. Esta línea provoca que en la tabla surja una nueva fila sobre el #Total con el texto #Chi-squared p-value que indica que se realiza la prueba al 5% (0,05). Si el resultado es el rechazo de la hipótesis nula de independencia se muestra un &lt;0,05 (warn.), pero si no se puede rechazar la hipótesis nula de independencia sale sólo (warn.) En la tabla no se publica el resultado de la prueba, pero podemos hacerlo siguiendo el formato estándar. table(data$P2, data$P31) Hombre Mujer En general, el sistema sanitario funciona bastante bien 277 261 El sistema sanitario funciona bien, aunque son necesarios al 620 627 El sistema sanitario necesita cambios fundamentales, aunque 288 349 Nuestro sistema sanitario está tan mal que necesitaríamos re 61 59 N.S. 6 3 N.C. 4 2 chisq.test(table(data$P2, data$P31)) Pearson&#39;s Chi-squared test data: table(data$P2, data$P31) X-squared = 7.2669, df = 5, p-value = 0.2015 table(data$P33, data$P31) Hombre Mujer Casado/a 677 711 Soltero/a 455 362 Viudo/a 41 149 Separado/a 24 33 Divorciado/a 55 42 N.C. 4 4 chisq.test(table(data$P33, data$P31)) Pearson&#39;s Chi-squared test data: table(data$P33, data$P31) X-squared = 75.203, df = 5, p-value = 8.437e-15 Donde se puede observar que para la primera relación, no se puede rechazar la hipótesis de independencia pues el valor de significación es p-value &gt; 0,05 (0.2015); para la segunda relación, sí podemos rechazar la hipótesis nula de independencia, puesto que p-value &lt; 0,05 (por tanto, existe dependencia). 4.6.1.2 De una celda de una tabla Particularmente de interés es la prueba Chi2 de celda. A diferencia de la anterior, en este caso se realiza la prueba para cada celda de la tabla en particular. La lógica de la misma sería comparar un valor de la tabla (una celda), con el resto de su fila, el resto de su columna, y el resto de la muestra. De este forma, indicamos que valores son significativos en la tabla, aquellos que cabría contemplar con un interés especial. Para obtener la tabla y la subsiguiente prueba se utilizará una nueva función denominada tab_last_sig_cell_chisq() sobre la misma estructura ya conocida de tabla. Nótese que en este caso, para la prueba se requiere utilizar los porcentajes en lugar de los casos, para que el cálculo sea el oportuno. Chi2 es una prueba muy sensible al tamaño de la muestra. data %&gt;% tab_cols(total(), &#39;|&#39;=unvr(P31)) %&gt;% tab_cells(&#39;|&#39;=unvr(P2)) %&gt;% tab_stat_cpct() %&gt;% tab_last_sig_cell_chisq() %&gt;% tab_pivot()  #Total   Hombre   Mujer   En general, el sistema sanitario funciona bastante bien  21.0  22.1   20.1    El sistema sanitario funciona bien, aunque son necesarios al  48.8  49.4   48.2    El sistema sanitario necesita cambios fundamentales, aunque   24.9  22.9 &lt; 26.8 &gt;  Nuestro sistema sanitario está tan mal que necesitaríamos re  4.7  4.9   4.5    N.S.  0.4  0.5   0.2    N.C.  0.2  0.3   0.2    #Total cases  2557  1256   1301   data %&gt;% tab_cols(total(), &#39;|&#39;=unvr(P31)) %&gt;% tab_cells(&#39;|&#39;=unvr(P33)) %&gt;% tab_stat_cpct() %&gt;% tab_last_sig_cell_chisq() %&gt;% tab_pivot()  #Total   Hombre   Mujer   Casado/a  54.3  53.9   54.7    Soltero/a  32.0  36.2 &gt; 27.8 &lt;  Viudo/a  7.4  3.3 &lt; 11.5 &gt;  Separado/a  2.2  1.9   2.5    Divorciado/a  3.8  4.4   3.2    N.C.  0.3  0.3   0.3    #Total cases  2557  1256   1301   La salida es muy clara. Con los símbolos mayor y menor, se marcan aquellas celdas que son significativamente mayores (&gt;) o menores (&lt;) que lo esperado y por tanto son las que direccionan las relaciones de dependencia que en la tabla se producen. 4.6.2 Pruebas de diferencias Un conjunto diferentes de pruebas son aquellas cuya hipótesis de partida se basa en determinar si existen diferencias entre los porcentajes (prueba z) o las medias (prueba t) de dos grupos independientes en la muestra extraídos de la misma población. Desarrollamos ambas pruebas en las líneas siguientes. 4.6.2.1 Porcentajes (prueba z) Asumiendo las hipótesis necesarias para poder trabajar con estadística paramétrica (normalidad, homoscedasticidad, linealidad y en algunos casos independencia), la función tab_last_sig_cpct realiza z-test entre columnas de porcentajes derivadas de la aplicación de tab_stat_cpct. Los resultados son calculados con la misma fórmula que con la función base de R prop.test y sin la corrección de continuidad. Obsérvese la diferencia de concepto; mientras que la prueba Chi2 de celda realiza la prueba comparando con el marginal total, la prueba z realiza esa comparación entre los grupos formados por las columnas, a los que se suele llamar perfiles. De esta forma considera la independencia de los grupos muestrales entre sí. Para utilizar esta funcionalidad el script sería el siguiente: data %&gt;% tab_cols(total(), &#39;SEXO&#39;=unvr(P31)) %&gt;% tab_cells(&#39;|&#39;=unvr(P2)) %&gt;% tab_stat_cpct() %&gt;% tab_last_sig_cpct() %&gt;% tab_pivot()  #Total     SEXO     Hombre     Mujer     A     B   En general, el sistema sanitario funciona bastante bien  21.0    22.1    20.1    El sistema sanitario funciona bien, aunque son necesarios al  48.8    49.4    48.2    El sistema sanitario necesita cambios fundamentales, aunque   24.9    22.9    26.8 A  Nuestro sistema sanitario está tan mal que necesitaríamos re  4.7    4.9    4.5    N.S.  0.4    0.5    0.2    N.C.  0.2    0.3    0.2    #Total cases  2557    1256    1301   data %&gt;% tab_cols(total(), &#39;SEXO&#39;=unvr(P31)) %&gt;% tab_cells(&#39;|&#39;=unvr(P33)) %&gt;% tab_stat_cpct() %&gt;% tab_last_sig_cpct() %&gt;% tab_pivot()  #Total     SEXO     Hombre     Mujer     A     B   Casado/a  54.3    53.9     54.7    Soltero/a  32.0    36.2 B   27.8    Viudo/a  7.4    3.3     11.5 A  Separado/a  2.2    1.9     2.5    Divorciado/a  3.8    4.4     3.2    N.C.  0.3    0.3     0.3    #Total cases  2557    1256     1301   En nuestro caso, los resultados son muy semejantes a los vistos con Chi2 de celda, porque la variable elegida para las columnas es dicotómica, es decir, con sólo dos opciones de respuesta, exhaustivas y mutuamente excluyentes. No sería así si la variable de columnas presentara más de 2 perfiles. La lectura de esta prueba es la siguiente. El porcentaje de casos en en el grupo B (mujeres) de la tabla 1, es significativamente más elevado que el de hombres, determinándose esta diferencia con una significación del 5%. En el caso de la tabla 2, el porcentaje de hombres solteros es significativamente diferente del porcentaje de mujeres solteras. Del mismo modo y a la inversa el porcentaje de mujeres viudas entrevistadas en la muestra es significativamente mayor que el de hombres. Por tanto, creemos que queda claro el funcionamiento de la prueba. Se etiquetan las columnas y se muestra la letra de la columna con la que se presentan diferencias positivas junto al valor porcentual. La prueba se realiza para cada celda, pero siempre comparando con las celdas que tiene a su derecha o izquierda en la misma fila (no con el total). 4.6.2.2 Medias (prueba t) Al igual que en el apartado anterior el objetivo es determinar si existen o no diferencias entre los grupos que se están testando, teniendo como hipótesis nula que las medias de los grupos son iguales. En nuestro ejemplo, hemos tomado la de auto clasificación ideológica (recodificando las posiciones de 1 a 10, izquierda a derecha respectivamente) creando grupos de izquierda, centro y derecha. Sobre esta tabla que calcula las medias, se aplica el estadístico tab_stat_mean_sd_n()que contiene todos los datos requeridos para el cálculo del valor t y se le indica que requerimos el test con tab_last_sig_means(). Se asume que los grupos son independientes, que existe normalidad y que las varianzas de los grupos son iguales. data$P29BIS &lt;- expss::recode(data$P29, &#39;Izquierda&#39; = 1:4 ~1, &#39;Centro&#39; = 5:6 ~2, &#39;Derecha&#39; = 7:10 ~ 3, TRUE ~NA) data %&gt;% tab_cols(total(), P29BIS) %&gt;% tab_cells(P3=na_if(P3, gt(10))) %&gt;% tab_stat_mean_sd_n() %&gt;% tab_last_sig_means() %&gt;% tab_pivot()  #Total     P29BIS     Izquierda     Centro     Derecha     A     B     C   Satisfacción     Mean  6.8    6.7    6.8    7.1 A B    Std. dev.  1.9    1.9    1.8    2.0      Unw. valid N  2542.0    770.0    750.0    348.0   Se puede observar que la salida es igual a la de la prueba Z. Se rotulan las columnas con las letras A, B  y las que sean necesarias, y posteriormente se muestra (por defecto) la letra de la columna con la que la media de la columna en la que se ubica la media presenta diferencias positivas (es mayor). Podemos por tanto observar, que en la población de la que se ha extraído la muestra, se puede afirmar que la media de satisfacción con el funcionamiento del sistema sanitario español es más alta en los individuos cuya auto clasificación ideológica es del grupo de derecha (C), que en la izquierda (A) y en el centro (B). No entramos a valorar si la distribución de grupos es la correcta o no, en cuanto al significado general. Se ha hecho una distribución acorde al significado de los números en sí mismos. Existen ocasiones en las que esta prueba, se requiere publicar para un conjunto de ítems que forman parte de una misma batería. En estos casos, no es tan interesante publicar las desviaciones y las bases, por lo que podemos formular de esta forma el script. data %&gt;% tab_cols(total(), P29BIS) %&gt;% tab_cells(P901=na_if(P901, gt(10))) %&gt;% tab_stat_mean_sd_n() %&gt;% tab_last_sig_means(keep=&#39;means&#39;) %&gt;% tab_cells(P902=na_if(P902, gt(10))) %&gt;% tab_stat_mean_sd_n() %&gt;% tab_last_sig_means(keep=&#39;means&#39;) %&gt;% tab_cells(P903=na_if(P903, gt(10))) %&gt;% tab_stat_mean_sd_n() %&gt;% tab_last_sig_means(keep=&#39;means&#39;) %&gt;% tab_cells(P904=na_if(P904, gt(10))) %&gt;% tab_stat_mean_sd_n() %&gt;% tab_last_sig_means(keep=&#39;means&#39;) %&gt;% tab_cells(P905=na_if(P905, gt(10))) %&gt;% tab_stat_mean_sd_n() %&gt;% tab_last_sig_means(keep=&#39;means&#39;) %&gt;% tab_cells(P906=na_if(P906, gt(10))) %&gt;% tab_stat_mean_sd_n() %&gt;% tab_last_sig_means(keep=&#39;means&#39;) %&gt;% tab_cells(P907=na_if(P907, gt(10))) %&gt;% tab_stat_mean_sd_n() %&gt;% tab_last_sig_means(keep=&#39;means&#39;) %&gt;% tab_pivot()  #Total     P29BIS     Izquierda     Centro     Derecha     A     B     C   Los cuidados y la atención recibida del personal médico     Mean  7.7    7.7    7.8    7.9   Los cuidados y la atención recibida del personal de enfermería     Mean  7.8    7.8    7.7    7.9   La confianza y seguridad que transmite el personal médico     Mean  7.8    7.7    7.8    8.0 A  La confianza y seguridad que transmite el personal de enfermería     Mean  7.8    7.7    7.7    8.0 A B  El tiempo dedicado por el médico o la médica a cada enfermo o enferma     Mean  7.1    6.9    7.0    7.2   El conocimiento del historial y seguimiento de los problemas de salud de cada usuario o usuaria     Mean  7.5    7.4    7.4    7.7 A B  La información recibida sobre su problema de salud     Mean  7.5    7.4    7.5    7.8 A B Se puede observar que la instrucción keep='means' lo que ha conseguido es eliminar la publicación de la desviación y la media del cuadro presentado. De este modo el resultado es más compacto y da una visión general de la batería de ítems 4.6.3 Parámetros posibles en las pruebas de significación De manera conjunta exponemos aquí diferentes parámetros que modifican el comportamiento por defecto de las cuatro pruebas anteriormente vistas. Algunos son de uso en todas ellas y otros específicos de alguna de las pruebas. sig_level, numérico; nivel de significación, por defecto es igual a 0.05. min_base, numérico; el test de significación se realizará si ambas columnas tienes bases mayores o iguales al valor determinado que por defecto es 2. delta_cpct, numérico; delta mínimo entre el porcentaje para el que marcamos diferencias significativas (en puntos porcentuales); de forma predeterminada, es igual a cero. Tenga en cuenta que, por ejemplo, para una diferencia mínima de 5 por ciento de puntos, delta_cpct debe ser igual a 5, no 0.05. delta_means, numérico; delta mínimo entre medias para las que marcamos diferencias significativas: por defecto es igual a cero. correct, lógico (TRUE o FALSE), indica si aplicar corrección de continuidad al calcular el estadístico Chi2 de prueba para tablas de 2 por 2. Solo para significance_cases y significance_cell_chisq. Para más detalles ver chisq.test. TRUE por defecto. compare_type tipo de comparación por columnas. Por defecto, es subtabla (variable por variable). otras posibilidades son \"first_column\", \"adjusted_first_column\" y \"previous_column\"; podemos realizar varios test simultáneamente. bonferroni lógico; FALSE por defecto; uso del ajuste de Bonferroni por cada fila. subtable_marks, carácter; una de las siguientes opciones: \"greater\", \"both\" or \"less\"; por defecto se marcan sólo valores cuya significación sea mayor (\"greater\") que alguna otra columna. Para significance_cell_chisq por defecto es \"both\". podemos modificar este comportamiento usando las otras alternativas. inequality_sign logical. FALSE if subtable_marks is less or greater. Should we show &gt; or &lt; before significance marks of subtable comparisons. sig_labels character vector labels for marking differences between columns of subtable. sig_labels_previous_column a character vector with two elements. Labels for marking a difference with the previous column. First mark means lower (by default it is v) and the second means greater (^). sig_labels_first_column a character vector with two elements. Labels for marking a difference with the first column of the table. First mark means lower (by default it is -) and the second means greater (+). sig_labels_chisq a character vector with two labels for marking a difference with row margin of the table. First mark means lower (by default it is &lt;) and the second means greater (&gt;). Only for significance_cell_chisq. keep, carácter. Una o más de las siguientes \"percent\", \"cases\", \"means\", \"bases\", \"sd\" o \"none\". Este argumento determina qué estadísticos permanecerán en la tabla después del marcado de significación. row_margin, carácter. Uno de los valores \"auto\" (predeterminado), \"sum_row\" o \"first_column\". Si es \"auto\", tratamos de encontrar la columna total en la subtabla por total_column_marker. Si la búsqueda falla, usamos la suma de cada fila como total de filas. Con la opción \"sum_row\" siempre sumamos cada fila para obtener margen. Tenga en cuenta que en este caso el resultado de las variables de respuesta múltiple en la cabecera puede ser incorrecta. Con la opción \"first_column\" usamos la tabla primera columna como margen de fila para todas las subtablas. En este caso, el resultado de las subtablas con bases incompletas puede ser incorrecto. Solo para significance_cell_chisq. total_marker, carácter. Total de fila marcado en la tabla. \" # \" por defecto. total_row, entero/carácter. En el caso de varios totales por subtabla, es un número o nombre de fila total para el cálculo de significación. digits, un número entero que indica cuántos dígitos después del separador decimal se mostrarán en la tabla final. na_as_zero, lógico; FALSE por defecto. ¿Deberíamos tratar a NA como cero casos? var_equal, lógico; variable que indica si se deben tratar las dos varianzas como iguales. Para más detalles ver t.test. mode, carácter; \"replace\" (default) o \"append\". En el primer caso, el resultado anterior en la secuencia del cálculo de la tabla se reemplazará con el resultado de la prueba de significación. En el segundo caso, el resultado de la prueba de significación se agregará a la secuencia del cálculo de la tabla. label, carácter; etiqueta para la estadística en tab_*. Ignorado si el modo es igual a replace. total_column_marker, carácter; marca para la columna de totales en las subtablas. # por defecto. x table (class etable): result of cro_cpct with proportions and bases for significance_cpct, result of cro_mean_sd_n with means, standard deviations and valid N for significance_means, and result of cro_cases with counts and bases for significance_cases. cases_matrix, matriz numérica con recuentos de tamaño filas*columnas. row_base, vector de números con las bases de fila. col_base, vector de números con las bases de columna. total_base, número con la base total. 4.6.3.1 Algunos ejemplos de uso de los parámetros Cambio del nivel de significación de la prueba y eliminación de las filas con las frecuencias, entre otros data %&gt;% tab_cols(total(), &#39;|&#39;=unvr(P31)) %&gt;% tab_cells(&#39;|&#39;=unvr(P33)) %&gt;% tab_stat_cases() %&gt;% tab_last_sig_cases(sig_level = 0.01, correct = TRUE, keep=&#39;bases&#39;, mode=&#39;replace&#39;, label=&#39;***&#39;) %&gt;% tab_pivot()  #Total   Hombre   Mujer   #Chi-squared p-value  &lt;0.01 (warn.)  #Total cases  2557.0  1256.0  1301.0  4.6.4 Conclusión Hasta aquí llegamos. Hemos presentado de forma muy breve y simplificada como podemos aprovechar toda la potencia de expss en nuestros script. Lo importante es practicar y practicar. No dejes de acudir a las viñetas de ayuda de Gregory Demin acerca de como usar el paquete y como generar nuevas tablas. Nosotros tan sólo hemos sentado las bases. Combinando las tablas con lenguaje R se puede llegar a conseguir casi todo. manual PDF de EXPSS material de ayuda, ejemplos uso de etiquetas en R 4.7 Visualización gráfica 4.7.1 highcharteR, introducción El paquete highcharter es un contenedor para la biblioteca Highcharts que incluye funciones de acceso directo para trazar objetos gráficos de R. Es una biblioteca de gráficos que ofrece numerosos tipos de gráficos con una sintaxis de configuración muy simple y repetitiva. Suponemos que ya estás acostumbrado a trabajar con R, por lo que no te resultará complicado seguir los pasos aquí indicados. Este documento fundamentalmente se ha dedicado a trabajar con tablas cruzadas (o mejor con los dataframe creados con esas tablas), ese elemento que tanta productividad produce y que tan claras deja las visualizaciones; sin embargo la mayoría de librerías de gráficos trabajan con dataframe, por lo que deberemos hacer una simplificación de la tabla para trabajar con ella de forma adecuada. No sería necesario, pero como digo te ayudará a ver con otros ojos la simplicidad de highcharter. Comenzaremos trabajando con la base de la librería y en el desarrollo del capítulo indicaremos como trabajar con tablas cruzadas. Debemos saber que highcharteRnos permite utilizar dos tipos diferentes de funciones que a continuación explicamos, aunque nos centramos en la primera de ellas. La segunda es una forma de acortar la primera. highchart() hchart() 4.7.1.1 highchart() Esta función crea un gráfico highchart usando un widget. El widget creado se puede representar en páginas HTML generadas a partir de rmarkdown y con características de interactividad. Si estás familiarizado con el paquete ggplot2, es una función similar a ggplot() del paquete donde se define un objeto ggplot base sobre el cual se pueden agregar más capas geométricas. De manera similar, una vez que se define la función highchart(), se pueden agregar más elementos highchart encima de ella, como si fueran capas superpuestas. 4.7.1.2 hchart() Por otro lado, hchart () es una función genérica para dibujar diferentes gráficos sobre la marcha. El gráfico resultante es un objeto highchart, por lo que puede seguir modificando con la API implícita. Si estás familiarizado con ggplot2, esta función es similar a qplot(). Comencemos nuestro viaje de visualización interactiva con los diseño más sencillos. 4.7.2 Mi primer gráfico Para trabajar con los gráficos, utilizaremos la siguiente tabla de datos, muy sencilla, propuesta por el autor del paquete, que además contiene los nombres de campo estandarizados que nos van a ayudar a de forma muy sencilla a generar nuestras visualizaciones. Lo primero que debemos saber, es que hay unos nombres de campo (por defecto) en el dataframe cuya presencia facilita enormemente el trabajo con los gráficos. Mira esta tabla de datos. En esta tabla son muy importantes los nombres de los campos, porque su existencia hace que sin apenas código, el gráfico ya visualiza de acuerdo a nuestra necesidad. x y z low high value name color from to weight 0 1.6 -34.0 -6.0 9.2 1 lemon #d35400 lemon olive 1 1 11.0 -23.0 6.7 15.3 10 nut #2980b9 lemon guava 1 2 20.4 6.8 2.8 38.0 19 olive #2ecc71 lemon fig 1 3 22.1 32.3 19.4 24.8 21 guava #f1c40f nut olive 1 4 15.4 27.7 12.1 18.7 14 fig #2c3e50 olive pear 2 5 7.4 3.2 -11.8 26.6 6 pear #7f8c8d guava pear 2 A saber  x, que contiene la secuencia de datos y, que contiene el dato que habitualmente representaremos en el eje de las Y (ordenadas) z, dimensiona el valor de y cuando se quieren usar tres dimensiones de representación (por ejemplo cuando queremos que en un scatter la burbuja sea tan grande como una tercera variable) low, valor más bajo para la categoría high, valor más alto para la categoría value, valor de la categoría name, que contiene lo nombres o textos de las categorías; suele ser lo que queremos que aparezca en el eje de las X (abscisas) color, código del color en hexadecimal que modificará el color por defecto de la serie (puede ser también el nombre del color) from, importante en gráficos especiales de tipo organización o donde hay una relación desde to, igual al anterior, importante en gráficos especiales de tipo organización o donde hay una relación hasta weight, utilizado en algunos gráficos a los que nos referiremos después. 4.7.3 Gráfico de barras Un diagrama de barras (o columnas) muestra la relación entre una variable numérica (y) y una categórica (name). Cada entidad de la variable categórica se representa como una barra. El tamaño de la barra representa su valor numérico. A veces se describe como una forma aburrida de visualizar información. Sin embargo, probablemente sea la forma más eficaz de mostrar este tipo de datos. Vamos a mostrar las dos formas de hacer este gráfico y entenderás la información que te aportábamos en la descripción anterior de las funciones posibles para hacer un gráfico. require(highcharter) # solicitamos la carga de highcharter si no lo está ya require(readr) require(dplyr) library(expss) df &lt;- suppressMessages(read_csv(&quot;https://drive.google.com/uc?export=download&amp;id=1OStFMmg5fzIpfTZnzX9Ql8sefN7se5SW&quot;, col_names=TRUE)) #df.csv, archivo con su ruta en el disco df1 &lt;- select(df, name, y, color) # seleccionamos las columnas name e y, por un motivo que más adelante explicamos highchart() %&gt;% hc_chart(type = &#39;bar&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1) ¿Por qué hemos seleccionado estos tres campos? Ya hemos hablado de la importancia del nombre de los campos en highcharter. El gráfico de barras que es un estándar, es transformado a un gráfico de barras low-high si se localizan estos nombres de campo, low y high en el dataframe de trabajo, y el dataframe original df los tenía. Por tanto si repetimos este gráfico, pero con el dataframe original con esos dos campos, veremos que variación se produce. highchart() %&gt;% hc_chart(type = &#39;bar&#39;) %&gt;% hc_xAxis(categories = df$name) %&gt;% hc_add_series(df) La barra no se traza completa sino que se traza con origen en el valor más bajo (low), y con final en el valor más alto (high). Sin embargo si acercas el ratón a una barra, verás que el valor listado se corresponde con el campo y del dataframe. Vamos a realizar unas pequeñas variaciones muy habituales en los gráficos. 4.7.3.1 Cambiar el nombre de la serie de datos La primera modificación sería añadir el nombre de la serie al gráfico  highchart() %&gt;% hc_chart(type = &#39;bar&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1, name=&#39;Fruits&#39;) Podemos observar, como en ángulo inferior derecho de la ventana del gráfico aparece la palabra fruits que hemos escrito como nombre del conjunto de datos, que en realidad es una única serie. 4.7.3.2 Añadir créditos al gráfico Añadir un pie de gráfico con créditos del creador del mismo. highchart() %&gt;% hc_chart(type = &#39;bar&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1, name=&#39;Fruits&#39;) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) Ver ángulo inferior derecho, justo debajo del nombre de la serie. Posibilidad de hacer clic y llegar hasta la URL indicada. 4.7.3.3 Añadir el valor del dato al elemento (datalabels) highchart() %&gt;% hc_chart(type = &#39;bar&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1, name=&#39;Fruits&#39;, dataLabels=list(enabled=TRUE)) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) 4.7.3.4 Guardar y exportar el gráfico En ocasiones es necesario dar la oportunidad al usuario del gráfico de poder guardarlo como imagen o guardarlo como tabla de EXCEL o fichero de texto separado por , (CSV). highchart() %&gt;% hc_chart(type = &#39;bar&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1, name=&#39;Fruits&#39;, dataLabels=list(enabled=TRUE)) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) 4.7.3.5 API de Highcharts, toda la potencia de los gráficos La pregunta que ahora nos deberíamos estar haciendo es ¿como puedo yo saber que debo usar hc_credits(), o hc_exporting() o dataLabels(list=())? Para eso tenemos lo que se llama la API de la librería de gráficos. Ahora entenderemos mejor el apartado de presentación cuando decíamos que highcharteres un wrapper de la librería Highcharts. Si visitamos el sitio web de la api de highcharts podemos ver que todas las opciones que se pueden usar en los gráficos están documentadas. Si a ello añadimos el sitio demo de esta marca podemos ver todo lo que se puede hacer. Te recomiendo la lectura del post de Danton Noriega acerca de como usar la API para saber construir nuestros gráficos en de highchart en R, en especial la parte en la que refiere a este punto que estamos hablando (Highcharts API and highcharter functions). Tras la lectura de ese post te darás cuenta de que en tus manos de analista de datos, tienes un auténtico cañón de magníficas visualizaciones. Pero vayamos poco a poco y continuemos con nuestros ejemplos de gráficos. 4.7.4 Gráfico de columna Es un gráfico idéntico al anterior, pero con la barra vertical en lugar de horizontal. Mantenemos la última vista básica con los elementos añadidos de exportación, créditos y mostrado de valores de aquí en adelante. highchart() %&gt;% hc_chart(type = &#39;column&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1, name=&#39;Fruits&#39;, dataLabels=list(enabled=TRUE)) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) Obsérvese que en el gráfico lo único que hemos hecho ha sido modificar el tipo de gráfico de bara column. Añadamos ahora perspectiva al gráfico, incluyendo la lista de opciones de 3D. highchart() %&gt;% hc_chart(type = &#39;column&#39;, options3d = list(enabled = TRUE, beta = 45, alpha = 15)) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1, name=&#39;Fruits&#39;, dataLabels=list(enabled=TRUE)) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) 4.7.4.1 Variación de columna a pirámide Y si lo presentamos en forma de pirámide  highchart() %&gt;% hc_chart(type = &#39;columnpyramid&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1, name=&#39;Fruits&#39;,showInLegend = FALSE, dataLabels = list(enabled=TRUE)) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) 4.7.4.2 Variación de columna a lollipop Y si lo presentamos en forma de lollipop, debemos variar al dataframe al completo, porque este gráfico muy parecido a la variación de rango, requiere del low-high. highchart() %&gt;% hc_chart(type = &#39;dumbbell&#39;) %&gt;% hc_xAxis(categories = df$name) %&gt;% hc_add_series(df, name=&#39;Fruits&#39;,showInLegend = FALSE, dataLabels = list(enabled=TRUE)) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) highchart() %&gt;% hc_chart(type = &#39;dumbbell&#39;, inverted=TRUE) %&gt;% hc_xAxis(categories = df$name) %&gt;% hc_add_series(df, name=&#39;Fruits&#39;,showInLegend = FALSE, dataLabels = list(enabled=TRUE)) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) 4.7.4.3 Gráficos polares Existe otra forma de visualizar el gráfico que nos va a gustar mucho, porque se ve en pocas ocasiones. highchart() %&gt;% hc_chart(type = &#39;bar&#39;, polar=TRUE) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1, name=&#39;Fruits&#39;, dataLabels=list(enabled=TRUE)) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) Nótese que se ha añadido el modificador polar=TRUE Una buena vista, espectacular pero poco efectiva. Desde el propio script, sin embargo se puede añadir una mínima opción que mejoraría esta salida. highchart() %&gt;% hc_chart(type = &#39;bar&#39;, polar=TRUE) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1, name=&#39;Fruits&#39;, dataLabels=list(enabled=TRUE)) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) %&gt;% hc_pane(endAngle=270) Esta nueva función hc_pane() hace que el círculo termine en el ángulo 270 (de 360), de forma que las etiquetas se leen mejor. Pero no es una visualización fácil, visualmente atractiva, pero difícil de leer e intepretar. 4.7.5 Diagramas de secciones 4.7.5.1 Tarta o pie chart Si hay algún gráfico tan o más famoso que el de barras o el de columnas, ese es el gráfico de tarta. df$sliced &lt;- c(0,1,0,0,1,0) #añadimos el campo sliced highchart() %&gt;% hc_title(text = &#39;Fruits pie&#39;) %&gt;% hc_subtitle(text = &#39;My favourite fruits&#39;) %&gt;% hc_chart(type = &#39;pie&#39;, polar = FALSE, inverted = FALSE) %&gt;% hc_xAxis(categories = df$name) %&gt;% hc_add_series(df,name = &quot;Fruits&quot;, showInLegend = TRUE) df &lt;- select(df, -sliced) #eliminamos el campo sliced Además de haberle añadido un título y un subtítulo este gráfico presenta un nuevo elemento fundamental: el modificador showInLegend=TRUE que nos permite mostrar una leyenda con las diferentes frutas y sus colores. Además, en el script hemos comenzado por añadir un nuevo campo a la tabla df, denominado sliced que ya puedes ver su efecto, separa del centro (desgaja) una sección de la tarta. En este caso ha sucedido para la fruta en segundo lugar (nut) y para la que está en quinto lugar (fig). 4.7.5.2 Anillo o doughnut Y si queremos convertir este gráfico en un anillo o doughnut utilizaremos el modificador innerSize='75%' en la función hc_add_series(). Este modificador traza un círculo desde el baricentro del diagrama hasta el porcentaje indicado dejando espacio central en blanco. El gráfico puede tomar diferente aspecto según ese porcentaje indicado. highchart() %&gt;% hc_title(text = &#39;Fruits pie&#39;) %&gt;% hc_subtitle(text = &#39;My favourite fruits&#39;) %&gt;% hc_chart(type = &#39;pie&#39;, polar = FALSE, inverted = FALSE) %&gt;% hc_xAxis(categories = df$name) %&gt;% hc_add_series(df,name = &quot;Fruits&quot;, showInLegend = TRUE, innerSize=&#39;75%&#39; ) o también, cambiando el radio inferior de vaciado  highchart() %&gt;% hc_title(text = &#39;Fruits pie&#39;) %&gt;% hc_subtitle(text = &#39;My favourite fruits&#39;) %&gt;% hc_chart(type = &#39;pie&#39;, polar = FALSE, inverted = FALSE) %&gt;% hc_xAxis(categories = df$name) %&gt;% hc_add_series(df,name = &quot;Fruits&quot;, showInLegend = TRUE, innerSize=&#39;33%&#39;) 4.7.5.3 Funnel Una variante para gráficos de un único campo es el funnel. 4.7.5.4 Pirámide Una nueva variante para un gráfico de una sola variable. el tipo pyramid. 4.7.6 Gráfico de línea Un nuevo pero tradicional modelo, el gráfico de línea. Vamos a aprovechar para no ser demasiado repetitivos para añadir una nueva serie de valores; recordemos la tabla de datos inicial. x y z low high value name color from to weight 0 1.6 -34.0 -6.0 9.2 1 lemon #d35400 lemon olive 1 1 11.0 -23.0 6.7 15.3 10 nut #2980b9 lemon guava 1 2 20.4 6.8 2.8 38.0 19 olive #2ecc71 lemon fig 1 3 22.1 32.3 19.4 24.8 21 guava #f1c40f nut olive 1 4 15.4 27.7 12.1 18.7 14 fig #2c3e50 olive pear 2 5 7.4 3.2 -11.8 26.6 6 pear #7f8c8d guava pear 2 Vamos a utilizar z, como si fuera una nueva serie de valores. Es decir como si quisiéramos representar en el diagrama dos conjuntos de valores. Primero lo mostramos como hasta ahora, con una sola serie df1 &lt;- select(df, name, y, z, color) # seleccionamos las columnas name, y y z highchart() %&gt;% hc_chart(type = &#39;line&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1, name=&#39;Fruits&#39;, dataLabels=list(enabled=TRUE)) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) Para ahora añadir la nueva serie. Nótese la variación en el modificador hc_add_series()donde ahora hay dos líneas, como si de dos capas se tratara. highchart() %&gt;% hc_chart(type = &#39;line&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1, name=&#39;Fruits - serie 1&#39;, dataLabels=list(enabled=TRUE)) %&gt;% hc_add_series(df1$z, name=&#39;Fruits - serie 2&#39;, dataLabels=list(enabled=TRUE)) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) Quisiera hacer notar que simplemente hemos añadido una nueva serie que se contiene en la columna denominada z de df1 (df1$z) y no hemos modificado la anterior serie que por defecto era el campo y. Creo que sería mucho más limpio y ordenado el escribir este mismo gráfico así. highchart() %&gt;% hc_chart(type = &#39;line&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1$y, name=&#39;Fruits - serie 1&#39;, dataLabels=list(enabled=TRUE)) %&gt;% hc_add_series(df1$z, name=&#39;Fruits - serie 2&#39;, dataLabels=list(enabled=TRUE)) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) De este modo, identificamos que es cada una de las series yy z, obteniendo idéntico resultado pero quedando más clara la sintaxis de cada una de las series introducidas. 4.7.6.0.1 Suavizado de la línea En muchas ocasiones es interesante suavizar la línea. Para ello highcharts tiene un modificador del tipo de gráfico denominado spline. highchart() %&gt;% hc_chart(type = &#39;spline&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1$y, name=&#39;Fruits - serie 1&#39;, dataLabels=list(enabled=TRUE)) %&gt;% hc_add_series(df1$z, name=&#39;Fruits - serie 2&#39;, dataLabels=list(enabled=TRUE)) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) Nótese el suavizado de la curva. Y ha llegado un momento de hacer algo no habitual, pero que sí puede darte ideas de futuro. highchart() %&gt;% hc_chart(type = &#39;line&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1$y, name=&#39;Fruits - serie 1&#39;, dataLabels=list(enabled=TRUE)) %&gt;% hc_add_series(df1$z, type=&#39;column&#39;, name=&#39;Fruits - serie 2&#39;, dataLabels=list(enabled=TRUE)) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) Vaya sorpresón y qué sencillo, ¿verdad? Hemos combinado línea con columna (no todas las combinaciones son posibles). Además como z tenía valores negativos, las barras negativas se muestran muy claramente. ¿Y si polarizamos este gráfico? highchart() %&gt;% hc_chart(type = &#39;line&#39;, polar=TRUE) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1$y, name=&#39;Fruits - serie 1&#39;, dataLabels=list(enabled=TRUE)) %&gt;% hc_add_series(df1$z, type=&#39;column&#39;, name=&#39;Fruits - serie 2&#39;, dataLabels=list(enabled=TRUE)) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) ¡Nada mal! aunque es posible que no combinando el tipo de representación en las series, la visualización sea más clara, en lo que se denomina gráfico spider que es muy utilizado para las baterías o tablas de ítems en nuestras encuestas. Y ya puestos, añadimos un toque de color a nuestro gráfico. Analiza tú mismo los modificadores que cambian. highchart() %&gt;% hc_chart(type = &#39;line&#39;, polar=TRUE, backgroundColor=&#39;#E2E2E2&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1$y, name=&#39;Fruits - serie 1&#39;, dataLabels=list(enabled=TRUE), color=&#39;#eb6909&#39;) %&gt;% hc_add_series(df1$z, name=&#39;Fruits - serie 2&#39;, dataLabels=list(enabled=TRUE), color=&#39;teal&#39;) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) 4.7.7 Gráficos de columnas o barras con apilamiento Volvamos la vista un poco atrás, y ahora que tenemos dos series, vamos a jugar un poco más el gráfico o más específicamente con las columnas (o barras). Vamos a realizar los apilamientos (no se pueden hacer lógicamente con los gráficos de tarta). Recuperamos nuestro gráfico de columnas, pero lo hacemos ahora con las dos series, pero ahora, para que los dos valores (y,z) sean positivos, vamos a trabajar con el campo denominado yy el campo denominado value. df1 &lt;- select(df, name, y, z, value, color) # seleccionamos las columnas name, y y value highchart() %&gt;% hc_chart(type = &#39;column&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1$y, name=&#39;Año 1900&#39;, dataLabels=list(enabled=TRUE), color=&#39;#EB6909&#39;) %&gt;% hc_add_series(df1$value, name=&#39;Año 2000&#39;, dataLabels=list(enabled=TRUE), color=&#39;#C2C2C2&#39;) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) Nótese que hemos añadido una novedad y es la asignación a la serie del color que nos gusta para ella, mediente el modificador color en la opción hc_add_series(). Procedamos con el apilamiento. highchart() %&gt;% hc_chart(type = &#39;column&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1$y, name=&#39;Año 1900&#39;, dataLabels=list(enabled=TRUE), color=&#39;#EB6909&#39;, stacking=&#39;normal&#39;) %&gt;% hc_add_series(df1$value, name=&#39;Año 2000&#39;, dataLabels=list(enabled=TRUE), color=&#39;#C2C2C2&#39;, stacking=&#39;normal&#39;) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) Nótese que en ambas series, se ha introducido el modificador stacking='normal'que ocasiona ese ajuste en las series. Podemos combinar series con apilamiento y series sin apilamiento (agrupaciones de categorías para verlas conjuntamente). highchart() %&gt;% hc_chart(type = &#39;column&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1$y, name=&#39;Año 1900&#39;, dataLabels=list(enabled=TRUE), color=&#39;#EB6909&#39;, stacking=&#39;normal&#39;) %&gt;% hc_add_series(df1$value, name=&#39;Año 2000&#39;, dataLabels=list(enabled=TRUE), color=&#39;#C2C2C2&#39;, stacking=&#39;normal&#39;) %&gt;% hc_add_series(df1$z, name=&#39;Año 2020&#39;, dataLabels=list(enabled=TRUE), color=&#39;#020202&#39;) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) Y por último, el apilamiento puede ser normal o puede ser percent donde la representación (que no el valor mostrado) se calcula en base 100. Nótese que todas las columnas son igual de altas y nótese que nuevamente z se mantiene sin apilamiento. highchart() %&gt;% hc_chart(type = &#39;column&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1$y, name=&#39;Año 1900&#39;, dataLabels=list(enabled=TRUE), color=&#39;#EB6909&#39;, stacking=&#39;percent&#39;) %&gt;% hc_add_series(df1$value, name=&#39;Año 2000&#39;, dataLabels=list(enabled=TRUE), color=&#39;#C2C2C2&#39;, stacking=&#39;percent&#39;) %&gt;% hc_add_series(df1$z, name=&#39;Año 2020&#39;, dataLabels=list(enabled=TRUE), color=&#39;#020202&#39;) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) Por último, apilemos todas  highchart() %&gt;% hc_chart(type = &#39;column&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1$y, name=&#39;Año 1900&#39;, dataLabels=list(enabled=TRUE), color=&#39;#EB6909&#39;, stacking=&#39;percent&#39;) %&gt;% hc_add_series(df1$value, name=&#39;Año 2000&#39;, dataLabels=list(enabled=TRUE), color=&#39;#C2C2C2&#39;, stacking=&#39;percent&#39;) %&gt;% hc_add_series(df1$z, name=&#39;Año 2020&#39;, dataLabels=list(enabled=TRUE), color=&#39;#020202&#39;, stacking=&#39;percent&#39;) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) Y pongamos el gráfico en estilo polar. highchart() %&gt;% hc_chart(type = &#39;column&#39;, polar=&#39;TRUE&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1$y, name=&#39;Año 1900&#39;, dataLabels=list(enabled=TRUE), color=&#39;#EB6909&#39;, stacking=&#39;percent&#39;) %&gt;% hc_add_series(df1$value, name=&#39;Año 2000&#39;, dataLabels=list(enabled=TRUE), color=&#39;#C2C2C2&#39;, stacking=&#39;percent&#39;) %&gt;% hc_add_series(df1$z, name=&#39;Año 2020&#39;, dataLabels=list(enabled=TRUE), color=&#39;#020202&#39;, stacking=&#39;percent&#39;) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) 4.7.8 Gráfico de área Volvamos a nuestras dos series (y, value) para presentar ahora una nueva visualización, el gráfico de área. Esta es una variación del gráfico de línea donde se dibujan éstas pero con la superficie bajo las líneas con el color indicado, mostrándose de esta forma. highchart() %&gt;% hc_chart(type = &#39;area&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1$y, name=&#39;Año 1900&#39;, dataLabels=list(enabled=TRUE), color=&#39;#EB6909&#39;) %&gt;% hc_add_series(df1$value, name=&#39;Año 2000&#39;, dataLabels=list(enabled=TRUE), color=&#39;#C2C2C2&#39;) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) Nótese la superposición de una y otra. Normalmente ese gráfico se usa para representar mediciones en las que una siempre está por encima de la otra (como aquí sucede), pero siempre pensando que las áreas de intersección van a combinar el color. Podemos también apilar los valores directos. highchart() %&gt;% hc_chart(type = &#39;area&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1$y, name=&#39;Año 1900&#39;, dataLabels=list(enabled=TRUE), color=&#39;#EB6909&#39;, stacking=&#39;normal&#39;) %&gt;% hc_add_series(df1$value, name=&#39;Año 2000&#39;, dataLabels=list(enabled=TRUE), color=&#39;#C2C2C2&#39;, stacking=&#39;normal&#39;) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) O mostrar las áreas con base 100. highchart() %&gt;% hc_chart(type = &#39;area&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1$y, name=&#39;Año 1900&#39;, dataLabels=list(enabled=TRUE), color=&#39;#EB6909&#39;, stacking=&#39;percent&#39;) %&gt;% hc_add_series(df1$value, name=&#39;Año 2000&#39;, dataLabels=list(enabled=TRUE), color=&#39;#C2C2C2&#39;, stacking=&#39;percent&#39;) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) 4.7.9 Gráfico de puntos o scatterplot Variación de los anteriores vamos a presentar sus dos versiones. La versión llamemos natural sería representar los puntos (igual que en el gráfico de línea) pero sin dibujar el trazo que los une. highchart() %&gt;% hc_chart(type = &#39;scatter&#39;) %&gt;% hc_xAxis(categories = df1$name) %&gt;% hc_add_series(df1$y, name=&#39;Año 1900&#39;, dataLabels=list(enabled=TRUE)) %&gt;% hc_add_series(df1$value, name=&#39;Año 2000&#39;, dataLabels=list(enabled=TRUE)) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) Sin embargo, cuando uno piensa en un scatterplot, lo que piensa es en un diagrama de dispersión o mapa cartesiano donde se presentan los puntos con sus coordenadas en x y también en y. Un diagrama de dispersión muestra la relación entre 2 variables numéricas. Para cada punto de datos, el valor de su primera variable se representa en el eje X, el segundo en el eje Y. Como no disponemos datos para un buen scatterplot, vamos a construirnos un banco de datos (aleatorio) y trabajamos con él. ##==================== construcción del dataframe set.seed(311265) # para que la aleatoriedad sea siempre la misma, fijamos su semilla de aleatorización dfextra &lt;- data.frame(mat=sample(1:100, 400, replace=TRUE), # un valor de un campo X, por ejemplo puntuación en habilidad en matemáticas bio=sample(1:100, 400, replace=TRUE), # un valor de un campo y, por ejemplo puntuación en habilidad en biología glob=sample(50:100, 400, replace=TRUE), # un valor z de peso global de adecuación al puesto grp=sample(1:3, 400, replace=TRUE) # grupo de pertenencia (tres grupos, 1, 2 y 3) ) ##================== mostramos extracto del data frame knitr::kable(head(dfextra)) # mostramos breve extracto de la tabla creada mat bio glob grp 72 80 76 3 6 49 85 3 76 47 55 2 50 42 98 2 65 77 69 2 34 8 97 3 Y vamos con el gráfico  hchart(dfextra, &#39;scatter&#39;, hcaes(x=mat, y=bio, group=grp)) Puedes observar que para este tipo de gráfico hemos optado por la forma acotada; esto es debido a que la forma de ofrecerle los datos es más simple, sin embargo podemos seguir añadiendo elementos al mismo del mismo modo que lo hacíamos con el uso de la función highchart(). La agrupación por colores es debida al modificador de grupo group=grpen la función hcaes(). Si no lo ponemos, simplemente el color sería único. hchart(dfextra, &#39;scatter&#39;, hcaes(x=mat, y=bio)) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) Una última variación al scatterplot sería convertirlo en un bubble scatterplot. Un diagrama de burbujas es un diagrama de dispersión donde se agrega una tercera dimensión: el valor de una variable numérica adicional se representa mediante el tamaño de los puntos. Necesita 3 variables numéricas como entrada: una está representada por el eje X, una por el eje Y y otra por el tamaño del punto. Más vale un imagen que mil palabras. hchart(dfextra, &#39;scatter&#39;, hcaes(x=mat, y=bio, z=glob, group = grp)) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) 4.7.10 Histograma o gráfico de densidad También en este caso vamos a recurrir a la forma simple. Un histograma solo toma como entrada una variable numérica. La variable se divide en varios cortes y el número de observaciones por corte se representa mediante la altura de la barra. Es posible representar la distribución de varias variables en el mismo eje utilizando esta técnica. Sigamos utilizando nuestro nuevo dataframe dfextra. hchart(dfextra$mat, color=&#39;teal&#39;, name=&#39;Matemáticas&#39;) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) Este gráfico puede fácilmente reconvertirse a la función de densidad. Una gráfica de densidad muestra la distribución de una variable numérica. Solo toma variables numéricas como entrada y está muy cerca de un histograma. Puede usarse exactamente en las mismas condiciones. hchart(density(dfextra$mat), color=&#39;teal&#39;, name=&#39;Matemáticas&#39;) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) 4.7.11 Gráficos indicadores Estos gráfico están caracterizados en su mayor parte por presentar un único valor numérico en una imagen muy simplificada. Su mayor exponente es el denominado gauge que estamos acostumbrados a ver en multitud de páginas web de tipo dashboard. Se caracterizan por tener datos que se proporcionan de forma externa al dataframe de donde se representa la información. Veamos algunos ejemplos. 4.7.11.1 Gauge Un gráfico de indicador (o gráfico de velocímetro) combina un gráfico de anillo y un gráfico circular en un solo gráfico. Muestra el valor deseado al que se le presupone un valor mínimo y un máximo. Es muy típico para representar por ejemplo el NPS y presentarlo con secciones tipo semáforo. En nuestro script y con afán de ir probando nuevas cosas, crearemos primero lo que se denominan las secciones del semáforo (3 o n) y luego haremos el gráfico. Representemos el campo value de nuestras frutas, comenzando por la oliva (fila 3) . Presentamos el script de forma más extendida para ir apreciando y comentando alguno de sus detalles col_stops &lt;- data.frame( q = c(0.25, 0.50, 0.75), # se establecen las secciones de valor en término porcentual c = c(&#39;#CD5C5C&#39;, &#39;#F0E68C&#39;, &#39;#3CB371&#39;), # se establecen los colores que tomará cada sección stringsAsFactors = FALSE ) stops &lt;- list_parse2(col_stops) # se crea una lista con este dataframe que hemos creado, pues highcharts lo necesita así. highchart() %&gt;% hc_chart(type = &quot;solidgauge&quot;) %&gt;% hc_pane( startAngle = -90, # determina el ángulo donde comienza endAngle = 90, # determina el ángulo donde acaba background = list( outerRadius = &#39;100%&#39;, # &quot;vaciamos&quot; el hueco del círculo que hemos dibujado innerRadius = &#39;60%&#39;, # &quot;vaciamos&quot; el hueco del círculo que hemos dibujado shape = &quot;arc&quot; ) ) %&gt;% hc_tooltip(enabled = FALSE) %&gt;% hc_yAxis( stops = stops, # le aplicamos la lista de secciones colo (semáforo) lineWidth = 0, minorTickWidth = 0, tickAmount = 2, min = 0, max = 100, labels = list(y = 25) # baja las etiquetas 0 y 100 de límites para que no sitúen sobre el gráfico ) %&gt;% hc_add_series( data = df$high[3], # le indicamos que capturamos el valor desde dataframe &#39;df&#39;, del campo &#39;high&#39;, y la fila &#39;3&#39; dataLabels = list( borderWidth = 0, useHTML = TRUE, style = list(fontSize = &quot;60px&quot;) ) ) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) Prueba si lo deseas a ir cambiando el valor de df$high[3] a cualquier valor entre 0 y 10 y observarás el cambio de color. col_stops &lt;-data.frame(q = c(0.25, 0.50, 0.75),c = c(&#39;#CD5C5C&#39;, &#39;#F0E68C&#39;, &#39;#3CB371&#39;),stringsAsFactors = FALSE) stops &lt;- list_parse2(col_stops) highchart() %&gt;% hc_chart(type = &quot;solidgauge&quot;) %&gt;% hc_pane(startAngle = -90,endAngle = 90,background = list(outerRadius = &#39;100%&#39;,innerRadius = &#39;60%&#39;,shape = &quot;arc&quot; )) %&gt;% hc_tooltip(enabled = FALSE) %&gt;% hc_yAxis(stops = stops,lineWidth = 0,minorTickWidth = 0,tickAmount = 2,min = 0,max = 100,labels = list(y = 25)) %&gt;% hc_add_series(data = 65,dataLabels = list(borderWidth = 0,useHTML = TRUE,style = list(fontSize = &quot;60px&quot;))) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) 4.7.11.2 Bullet Otra forma de representar valores unitario pero que tienen un objetivo definido y que pueden haber superado ese objetivo es el gráfico denominado bullet. vamos a imaginar que en nuestro dataframe, y es el valor alcanzado, y valuees el objetivo. bandas &lt;- list(list(from = 0, to = 10, color = &quot;#ddd&quot;),list(from = 10, to = 20, color = &quot;#bbb&quot;),list(from = 20, to = 25, color =&quot;#888&quot;)) hchart(df1, &quot;bullet&quot;, hcaes(x = name, y = y, target = value), color = &quot;teal&quot;, targetOptions=list(color=&#39;black&#39;)) %&gt;% hc_chart(inverted = TRUE) %&gt;% hc_yAxis(min = 0,max = 25, gridLineWidth = 0, plotBands = bandas) %&gt;% hc_xAxis(gridLineWidth = 15, gridLineColor = &quot;white&quot;) %&gt;% hc_plotOptions(series = list(pointPadding = 0.25, pointWidth = 15, borderWidth = 0, targetOptions = list(width = &#39;200%&#39;))) %&gt;% hc_size(height = 300)%&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) Nótese que en el gráfico la barra vertical perpendicular a cada barra horizontal, que es el target se toma de los propios datos. Es un gráfico que también se ve mucho en los dashboard, al igual que el anterior. 4.7.12 Gráfico o boxplot No lo hemos olvidado, el gráfico más típico en estadística junto con los histogramas, el denominado boxplot o diagrama de caja o diagrama de Box-Whiskers. Un diagrama de caja ofrece un buen resumen de una o varias variables numéricas. La línea que divide el cuadro en 2 partes representa la mediana de los datos. El final del cuadro muestra los cuartiles superior e inferior. Las líneas extremas muestran el valor más alto y más bajo excluyendo los valores atípicos. Nótese que es usada una función de tranformación de los datos del campo valuepara obtener los valores adecuados para el gráfico. Del mismo modo, nótese que la función de adición de las series, se ve mínimamente modificada ya que va a recibir una lista de valores por cada campos de trabajo. Usamos hc_add_series_list(). dfboxplot1 &lt;- data_to_boxplot(df, value, add_outliers=TRUE, name= &#39;value&#39;, color = &#39;teal&#39;) highchart() %&gt;% hc_chart(type=&#39;boxplot&#39;) %&gt;% hc_add_series_list(dfboxplot1) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) Añadir más series sólo implica repetir el proceso, lo que permite la compración. dfboxplot1 &lt;- data_to_boxplot(df, value, add_outliers=TRUE, name= &#39;value&#39;, color = &#39;teal&#39;) dfboxplot2 &lt;- data_to_boxplot(df, high, add_outliers=TRUE, name= &#39;high&#39;, color = &#39;red&#39;) dfboxplot3 &lt;- data_to_boxplot(df, low, add_outliers=TRUE, name= &#39;low&#39;, color = &#39;orange&#39;) highchart() %&gt;% hc_chart(type=&#39;boxplot&#39;) %&gt;% hc_add_series_list(dfboxplot1) %&gt;% hc_add_series_list(dfboxplot2) %&gt;% hc_add_series_list(dfboxplot3) %&gt;% hc_credits(enabled=TRUE, text=&#39;InvestigaOnline.com&#39;, href =&#39;https://www.investigaonline.com&#39;) %&gt;% hc_exporting(enabled=TRUE) 4.7.13 Gráfico de barras de error A menudo tenemos necesidad de incluir un gráfico denominado de barras de error. Este gráfico toma los valores de low-high (que podrían ser lo límites de confianza de un intervalo) y los representa en forma gráfica, quedando de esta forma. highchart() %&gt;% hc_chart(type = &#39;errorbar&#39;, polar = FALSE, inverted = FALSE) %&gt;% hc_xAxis(categories = df$name) %&gt;% hc_yAxis(visible = TRUE) %&gt;% hc_tooltip(outside = TRUE, enabled=TRUE) %&gt;% hc_add_series(df,name = &quot;Límites de confianza&quot;,showInLegend = FALSE, dataLabels = list(enabled=TRUE)) Si además de los límites de la medición, quisiéramos añadir el punto de valor, el resultado sería éste. highchart() %&gt;% hc_chart(type = &#39;errorbar&#39;, polar = FALSE, inverted = FALSE) %&gt;% hc_xAxis(categories = df$name) %&gt;% hc_yAxis(visible = TRUE) %&gt;% hc_tooltip(outside = TRUE, enabled=TRUE) %&gt;% hc_add_series(df,name = &quot;Límites de confianza&quot;,showInLegend = FALSE, dataLabels = list(enabled=TRUE)) %&gt;% hc_add_series(df,type = &#39;scatter&#39;, name = &quot;Valor&quot;,showInLegend = FALSE, dataLabels = list(enabled=TRUE, x=15, y=5)) Probando nuevas cosas, hemos movido la etiqueta del valor hacia la derecha (x=15) y hacia abajo (y=5). Eso hace que no se solape con el punto señalado en el gráfico. 4.7.14 Gráficos de transiciones En nuestro trabajo en mucho casos debemos a veces plantear gráficos en los que se trata de graficar relaciones de objetos con fuente y destino. Aunque nuestro banco de datos es muy simple, hemos creado campos con el nombrede weight, from y to para que nos permitan hacer este tipo de gráficos que tienen dos versiones diferentes: el diagrama de Sankey y el diagrama de rueda de dependencia. Veamos ambos. 4.7.14.1 Diagrama de Sankey El diagrama de Sankey es un tipo específico de diagrama de flujo, en el que la anchura de las linea de relación entre dos puntos (from y to) se muestra proporcional a la cantidad de flujo transferido (weight, que podría ser frecuencia de emparejamiento). highchart() %&gt;% hc_chart(type = &#39;sankey&#39;, polar = FALSE, inverted = FALSE) %&gt;% hc_xAxis(categories = df$name) %&gt;% hc_yAxis(visible = TRUE) %&gt;% hc_tooltip(outside = TRUE, enabled=TRUE) %&gt;% hc_add_series(df,name = &quot;Nombre de la serie&quot;,showInLegend = FALSE, dataLabels = list(enabled=TRUE), colorByPoint=TRUE) De esta forma se muestra que las relaciones más fuertes se producen entre aceituna y pera o entre guava y pera. 4.7.14.2 Diagrama de rueda Otra forma de ver el mismo gráfico, pero en forma circular. Las mismas necesidades de campos weight, from y to. highchart() %&gt;% hc_chart(type = &#39;dependencywheel&#39;, polar = FALSE, inverted = FALSE) %&gt;% hc_xAxis(categories = df$name) %&gt;% hc_yAxis(visible = TRUE) %&gt;% hc_tooltip(outside = TRUE, enabled=TRUE) %&gt;% hc_add_series(df,name = &quot;Nombre de la serie&quot;,showInLegend = FALSE, dataLabels = list(enabled=TRUE), colorByPoint=TRUE) 4.7.14.3 Diagrama streamgraph Un streamgraph es un tipo de gráfico de áreas apiladas. Muestra la evolución de un valor numérico (eje Y) después de otro valor numérico (eje X). Esta evolución está representada por varios grupos, todos con un color distinto. Al contrario que en un área apilada, no hay esquinas: los bordes están redondeados, lo que da esta agradable impresión de flujo. Además, las áreas generalmente se desplazan alrededor de un eje central, lo que da como resultado una forma fluida y orgánica. Usaremos los valores y, z y value para crear tres series. highchart() %&gt;% hc_chart(type = &#39;streamgraph&#39;, polar = FALSE, inverted = FALSE) %&gt;% hc_xAxis(categories = df$name) %&gt;% hc_yAxis(visible = TRUE) %&gt;% hc_tooltip(outside = TRUE, enabled=TRUE) %&gt;% hc_add_series(df$y,name = &quot;y&quot;, showInLegend = FALSE, dataLabels = list(enabled=FALSE), color=&#39;silver&#39;) %&gt;% hc_add_series(df$z,name = &quot;z&quot;, showInLegend = FALSE, dataLabels = list(enabled=FALSE), color=&#39;teal&#39;) %&gt;% hc_add_series(df$value ,name = &quot;value&quot;, showInLegend = FALSE, dataLabels = list(enabled=FALSE), color=&#39;orange&#39;) 4.7.15 Conclusión Hasta aquí llegamos. Hemos presentado de forma muy breve y simplificada como podemos aprovechar toda la potencia de highcharts en nuestros script. Lo importante es practicar y practicar. No dejes de leer el post de Danton Noriega acerca de como usar la API para saber construir los gráficos highchart en R mediante highcharteR Del mismo modo, no dejes de acudir al sitio web de Joshua Kunst, creador y mantenedor del paquete junto con otros colaboradores que permiten llevar adelante este excelente proyecto. References "],["s01.html", "Parte 5 EDA (exploratory data analysis) - Sesiones 1 y 2 5.1 Carga de paquetes 5.2 Carga de datos 5.3 Frecuencias e histogramas 5.4 Análisis de normalidad 5.5 Homogeneidad de varianzas (homoscedasticidad)", " Parte 5 EDA (exploratory data analysis) - Sesiones 1 y 2 La sesión 01 (y la 02) de esta asignatura está dedicada a realizar una introducción a los procedimientos básicos de trabajo con datos provenientes de recogidas estructuradas de datos o de investigaciones de mercado, predominantemente de encuesta. En las sesiones 01 y 02 estudiaremos entre otras pruebas: Exploración de los datos: introducción y herramientas básicas para la exploración de los datos. Herramientas de exploración: comprobación de la linealidad, normalidad y homocedasticidad Inferencia estadística paramétrica Inferencia estadística no paramétrica El siguiente documento replica todos los cálculos estadísticos de la primera sesión de la asignatura Técnicas Multivariantes en Investigación de Mercados dentro del máster oficial en Marketing e Investigación de mercados realizados con SPSS. Este documento intenta ser una guía ilustrativa y demostrativa de como se trabaja con R, magnificando todas las virtudes de este software. En esta primera sesión, particularmente acometeremos el trabajo básico de: instalar el software R instalar el software RStudio subir los datos de la asignatura obtener el cálculo de frecuencias e histogramas obtener los descriptivos analizar la normalidad estadística analizar la homogeneidad de varianza 5.1 Carga de paquetes Los paquetes aquí listados son específicos para estas siguientes sesiones. Ver la Parte R1a) para resto de paquetes cargados esenciales. #install.packages(c(&#39;car&#39;,&#39;outliers&#39;, &#39;psych&#39;, &#39;nortest&#39;, &#39;Hmisc&#39;, &#39;vcd&#39;, &#39;ca&#39;, &#39;corrplot&#39;, &#39;factoextra&#39;, &#39;FactoMineR&#39;, &#39;gplots&#39;, &#39;DT&#39;, &#39;lmtest&#39;, &#39;sjstats&#39;, &#39;igraph&#39;)) suppressMessages(library(&#39;car&#39;, quietly = TRUE)) suppressMessages(library(&#39;outliers&#39;, quietly = TRUE)) suppressMessages(library(&#39;psych&#39;, quietly = TRUE)) suppressMessages(library(&#39;nortest&#39;, quietly = TRUE)) suppressMessages(library(&#39;Hmisc&#39;, quietly = TRUE)) suppressMessages(library(&#39;vcd&#39;, quietly = TRUE)) suppressMessages(library(&#39;ca&#39;, quietly = TRUE)) suppressMessages(library(&#39;corrplot&#39;, quietly = TRUE)) suppressMessages(library(&#39;factoextra&#39;, quietly = TRUE)) suppressMessages(library(&#39;FactoMineR&#39;, quietly = TRUE)) suppressMessages(library(&#39;gplots&#39;, quietly = TRUE)) suppressMessages(library(&#39;DT&#39;, quietly = TRUE)) suppressMessages(library(&#39;lmtest&#39;, quietly = TRUE)) suppressMessages(library(&#39;sjstats&#39;, quietly = TRUE)) suppressMessages(library(&#39;igraph&#39;, quietly=TRUE)) 5.2 Carga de datos En nuestro trabajo deberemos cargar datos provenientes de fuentes como archivo texto (paquete readr), archivos xls o xlsx (paquete readr) y archivos SPSS (paquete expss). Las instrucciones serán muy simples. Para evitar repetir la carga en diferentes secciones de este capítulo, cargamos inicialmente todos los archivos. Los paquetes mencionados deberán haber sido cargados previamente. #sesiones 01 y 02 fib2 &lt;- suppressMessages(read_spss(&quot;https://download.tesigandia.com/tmim/fib_2.sav&quot;)) gssnet1 &lt;- suppressMessages(read_spss(&quot;https://download.tesigandia.com/tmim/gssnet1.sav&quot;)) hatco &lt;- suppressMessages(read_spss(&quot;https://download.tesigandia.com/tmim/hatco.sav&quot;)) gssft1 &lt;- suppressMessages(read_spss(&quot;http://download.tesigandia.com/tmim/gssft1.sav&quot;)) gssnet2 &lt;- suppressMessages(read_spss(&quot;http://download.tesigandia.com/tmim/gssnet2.sav&quot;)) endorph1 &lt;- suppressMessages(read_spss(&quot;http://download.tesigandia.com/tmim/endorph1.sav&quot;)) anxiety &lt;- suppressMessages(read_spss(&quot;http://download.tesigandia.com/tmim/anxiety.sav&quot;)) hatco &lt;- suppressMessages(read_spss(&quot;http://download.tesigandia.com/tmim/hatco.sav&quot;)) data2 &lt;- suppressMessages(read_spss(&quot;http://download.tesigandia.com/tmim/manners1.sav&quot;)) grades &lt;- suppressMessages(read_spss(&quot;http://download.tesigandia.com/tmim/grades1.sav&quot;)) bdi &lt;- suppressMessages(read_spss(&quot;http://download.tesigandia.com/tmim/bdidrogas1.sav&quot;)) 5.3 Frecuencias e histogramas Usaremos el paquete expsspara obtener todos los cálculos que tengan que ver con el manejo de la estadística básica paramétrica y relacionados con los cálculos de frecuencia. 5.3.1 Frecuencias Calculamos las frecuencias de la variable AGE obteniendo una salida similar al SPSS. Las frecuencias son la base de trabajo del investigador, cuántas veces sucede un evento. El estilo SPSS muestra diferentes columnas con el valor absoluto y el relativo, poniendo como base todos los casos del banco de datos o todos los casos válidos del banco de datos. # recuento de frecuencias fre(gssnet1$age) Age of respondent  Count   Valid percent   Percent   Responses, %   Cumulative responses, %   18  10 1.0 1.0 1.0 1.0  19  10 1.0 1.0 1.0 2.0  20  6 0.6 0.6 0.6 2.6  21  13 1.3 1.3 1.3 4.0  22  9 0.9 0.9 0.9 4.9  23  18 1.8 1.8 1.8 6.7  24  26 2.6 2.6 2.6 9.3  25  21 2.1 2.1 2.1 11.5  26  20 2.0 2.0 2.0 13.5  27  17 1.7 1.7 1.7 15.2  28  22 2.2 2.2 2.2 17.5  29  12 1.2 1.2 1.2 18.7  30  19 1.9 1.9 1.9 20.6  31  17 1.7 1.7 1.7 22.4  32  19 1.9 1.9 1.9 24.3  33  23 2.3 2.3 2.3 26.6  34  24 2.4 2.4 2.4 29.1  35  24 2.4 2.4 2.4 31.5  36  12 1.2 1.2 1.2 32.7  37  13 1.3 1.3 1.3 34.0  38  22 2.2 2.2 2.2 36.3  39  13 1.3 1.3 1.3 37.6  40  27 2.7 2.7 2.7 40.3  41  17 1.7 1.7 1.7 42.1  42  17 1.7 1.7 1.7 43.8  43  19 1.9 1.9 1.9 45.7  44  24 2.4 2.4 2.4 48.2  45  19 1.9 1.9 1.9 50.1  46  26 2.6 2.6 2.6 52.7  47  21 2.1 2.1 2.1 54.9  48  24 2.4 2.4 2.4 57.3  49  26 2.6 2.6 2.6 60.0  50  26 2.6 2.6 2.6 62.6  51  18 1.8 1.8 1.8 64.4  52  18 1.8 1.8 1.8 66.3  53  10 1.0 1.0 1.0 67.3  54  17 1.7 1.7 1.7 69.0  55  15 1.5 1.5 1.5 70.5  56  21 2.1 2.1 2.1 72.7  57  18 1.8 1.8 1.8 74.5  58  13 1.3 1.3 1.3 75.8  59  14 1.4 1.4 1.4 77.2  60  17 1.7 1.7 1.7 79.0  61  14 1.4 1.4 1.4 80.4  62  19 1.9 1.9 1.9 82.3  63  9 0.9 0.9 0.9 83.2  64  10 1.0 1.0 1.0 84.2  65  7 0.7 0.7 0.7 85.0  66  11 1.1 1.1 1.1 86.1  67  12 1.2 1.2 1.2 87.3  68  7 0.7 0.7 0.7 88.0  69  8 0.8 0.8 0.8 88.8  70  11 1.1 1.1 1.1 89.9  71  8 0.8 0.8 0.8 90.8  72  8 0.8 0.8 0.8 91.6  73  7 0.7 0.7 0.7 92.3  74  11 1.1 1.1 1.1 93.4  75  7 0.7 0.7 0.7 94.1  76  5 0.5 0.5 0.5 94.6  77  2 0.2 0.2 0.2 94.8  78  8 0.8 0.8 0.8 95.6  79  7 0.7 0.7 0.7 96.3  80  2 0.2 0.2 0.2 96.5  81  4 0.4 0.4 0.4 97.0  82  4 0.4 0.4 0.4 97.4  83  4 0.4 0.4 0.4 97.8  84  3 0.3 0.3 0.3 98.1  85  4 0.4 0.4 0.4 98.5  86  3 0.3 0.3 0.3 98.8  87  1 0.1 0.1 0.1 98.9  88  2 0.2 0.2 0.2 99.1  89  5 0.5 0.5 0.5 99.6  99  4 0.4 0.4 0.4 100.0  #Total  984 100 100 100  &lt;NA&gt;  0 0.0 Si esa misma información la intentamos conseguir en forma de tabla marginal, disponemos de la función cro_*()de crosstab que nos habilita para ello. La diferencia es que con cro_*() podemos indicar el tipo de dato deseado. Existen otras formas más completas de crear tablas de contingencia que se mostrarán más adelante con el paquete expss. # tabla cruzada cro_cases(gssnet1$region, gssnet1$usenet) #modalidad básica  Use internet ?   No   Yes   Unknown   Region of interview     Not assigned     New England  6 21    Middle Atlantic  24 102 1    E. Nor. Central  44 135 1    W. Nor. Central  25 41    South Atlantic  64 146 1    E. South Central  14 43    West South Central  37 73 2    Mountain  11 56    Pacific  30 106 1    #Total cases  255 723 6 cro_cpct(gssnet1$region, gssnet1$usenet) #modalidad básica pct  Use internet ?   No   Yes   Unknown   Region of interview     Not assigned     New England  2.4 2.9    Middle Atlantic  9.4 14.1 16.7    E. Nor. Central  17.3 18.7 16.7    W. Nor. Central  9.8 5.7    South Atlantic  25.1 20.2 16.7    E. South Central  5.5 5.9    West South Central  14.5 10.1 33.3    Mountain  4.3 7.7    Pacific  11.8 14.7 16.7    #Total cases  255 723 6 cro_rpct(gssnet1$region, gssnet1$usenet) #modalidad básica pct  Use internet ?   No   Yes   Unknown   Region of interview     Not assigned     New England  22.2 77.8    Middle Atlantic  18.9 80.3 0.8    E. Nor. Central  24.4 75.0 0.6    W. Nor. Central  37.9 62.1    South Atlantic  30.3 69.2 0.5    E. South Central  24.6 75.4    West South Central  33.0 65.2 1.8    Mountain  16.4 83.6    Pacific  21.9 77.4 0.7    #Total cases  255 723 6 cro_tpct(gssnet1$region, gssnet1$usenet) #modalidad básica pct  Use internet ?   No   Yes   Unknown   Region of interview     Not assigned     New England  0.6 2.1    Middle Atlantic  2.4 10.4 0.1    E. Nor. Central  4.5 13.7 0.1    W. Nor. Central  2.5 4.2    South Atlantic  6.5 14.8 0.1    E. South Central  1.4 4.4    West South Central  3.8 7.4 0.2    Mountain  1.1 5.7    Pacific  3.0 10.8 0.1    #Total cases  255 723 6 5.3.2 Histogramas Para no tener que repetir muchas veces el nombre del campo , gssnet1$age, lo declaramos como una variable que denominamos x; más corto y simple. Posteriormente, calculamos el histograma de frecuencias del vector (variable) x. x &lt;- gssnet1$age h &lt;- hist(x, freq = FALSE) h &lt;- curve(dnorm(x, mean(x), sd(x)), col = 1, lty = 2, lwd = 2, add=TRUE) ## Descriptivos Calculamos todos los descriptivos de forma individual, auqnue también podemos utilizar comandos de paquetes variados que hacen los mismos summary(x). la orden summary(x) usa el paquete base de R. Para una mejor organización, los guardamos en objetos y posteriormente imprimimos esos objetos en una tabla. 5.3.3 Datos descriptivos básicos # para no tener que escribir cada vez fib2$dia1, le llamamos x x &lt;- fib2$dia1 # iniciamos cálculo summary(x) Min. 1st Qu. Median Mean 3rd Qu. Max. 0.020 1.312 1.790 1.771 2.230 3.690 suma &lt;- sum(x, na.rm = TRUE) media &lt;- mean(x, na.rm = TRUE) media.recortada &lt;- mean(x, na.rm = TRUE, trim = 0.05) mediana &lt;- median(x, na.rm = TRUE) cuartiles &lt;- quantile(x, na.rm = TRUE, c(0, 0.25, 0.5, 0.75, 1)) deciles &lt;- quantile(x, na.rm = TRUE, c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1)) terciles &lt;- quantile(x, na.rm = TRUE, c(0, 0.33, 0.66, 1)) maximo &lt;- max(x, na.rm = TRUE) minimo &lt;- min(x, na.rm = TRUE) rango1 &lt;- range(x, na.rm = TRUE) rango2 &lt;- max(x, na.rm = TRUE) - min(x, na.rm = TRUE) recorrido &lt;- IQR(x, na.rm = TRUE, type = 7) desviacion &lt;- sd(x, na.rm = TRUE) varianza &lt;- var(x, na.rm = TRUE) coefvar &lt;- (sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)) * 100 int90 &lt;- t.test(x, na.rm = TRUE, conf.level = 0.9000)[[&quot;conf.int&quot;]] int95 &lt;- t.test(x, na.rm = TRUE, conf.level = 0.9545)[[&quot;conf.int&quot;]] int99 &lt;- t.test(x, na.rm = TRUE, conf.level = 0.9975)[[&quot;conf.int&quot;]] esdmd &lt;- sd(x, na.rm = TRUE) / sqrt((t.test(x, na.rm = TRUE, conf.level = 0.9545)[[&quot;parameter&quot;]][[&quot;df&quot;]])) funmoda &lt;- function(x) { t &lt;- table(x) return(as.numeric(names(t)[t == max(t)])) } moda &lt;- funmoda(x) skewness &lt;- skew(x, na.rm = TRUE) kurtosis &lt;- kurtosi(x, na.rm = TRUE) Estadístico Valor suma 1434.62 media aritmética 1.7711358 media recortada 1.7699041 mediana 1.79 cuartiles 0.02, 1.3125, 1.79, 2.23, 3.69 deciles 0.02, 0.849, 1.14, 1.42, 1.58, 1.79, 1.982, 2.17, 2.35, 2.67, 3.69 terciles 0.02, 1.47, 2.05, 3.69 máximo 3.69 mínimo 0.02 rango (1) [0.02, 3.69] rango (2) 3.67 IQR (recorrido intercuartílico) 0.9175 desviación típica 0.6935389 varianza 0.4809962 coeficiente de variación 39.1578625 intervalo de confianza al 90% 1.7310073, 1.8112643 intervalo de confianza al 95% 1.7223234, 1.8199482 intervalo de confianza al 99% 1.69723, 1.8450416 error estándar medio 0.0243835 moda 2 simetría -0.0044284 aplanamiento -0.4215941 Otras opciones de cálculo son el describedel paquete psych y también el info del paquete expss. En ambos casos, no debemos hacer los mismo de calcular individualmente, pero tampoco podemos decidir por tanto que información nos obtiene. Con info de expss. t(info(x)) [,1] Name &quot;x&quot; Class &quot;labelled,numeric&quot; Length &quot;810&quot; NotNA &quot;810&quot; NA &quot;0&quot; Distincts &quot;199&quot; Label &quot;Valoración de la higiene dia 1&quot; ValueLabels NA Min. &quot;0.02&quot; 1st Qu. &quot;1.3125&quot; Median &quot;1.79&quot; Mean &quot;1.771136&quot; 3rd Qu. &quot;2.23&quot; Max. &quot;3.69&quot; Frequency &quot;2=19, 1.47=17, 2.02=16, 1.58=15, 2.17=15, 1.5=14, 1.85=14, 1.94=14, 2.05=14, 2.23=14, Other values=658&quot; Con describe del paquete psych. Para que se vea mejor, le aplicamos la transposición de filas y columnas a la tabla por defecto t(). t(describe(x)) NULL 5.3.4 Histogramas y cajas Siempre la parte gráfica es importante. Realizamos ahora un histograma y unos gráficos de caja para conocer gráficamente la distribución de nuestra variable (campo o vector). Estos últimos los hacemos con y sin outliers, que son impresos posteriormente. Primero el histograma  # grafico de histograma hist(x, main=&quot;Histograma de frecuencias&quot;, xlab = &quot;Edad del entrevistado&quot;, ylab = &quot;Frecuencia&quot;, axes = TRUE, plot = TRUE, labels = FALSE, col = c(&quot;#eb6909&quot;), border = &quot;white&quot;) Después al gráfico de caja o Box-Whiskers con outliers  boxplot(x, varwidth = TRUE, notch = FALSE, outline = TRUE, border = TRUE, main = &quot;Diagrama de caja&quot;) Y el mismo sin outliers  boxplot(x, varwidth = TRUE, notch = FALSE, outline = FALSE, border = TRUE, main = &quot;Diagrama de caja&quot;) 5.4 Análisis de normalidad Vamos a testar ahora la normalidad de la distribución con la prueba de Kolmogorov-Smirnov. Posteriormente corregiremos el dato con la prueba de Lilliefors y calcularemos también Shapiro-Wilk. 5.4.1 Kolgomorov - Smirnov # kolgomorov-smirnov ks.test(x, pnorm, mean(x), sd(x), alternative = &quot;greater&quot;, exact = NULL) One-sample Kolmogorov-Smirnov test data: x D^+ = 0.024455, p-value = 0.3795 alternative hypothesis: the CDF of x lies above the null hypothesis 5.4.1.1 Corrección de Lilliefors Añadimos al test de la normalidad la corrección de Lilliefors. lillie.test(x) Lilliefors (Kolmogorov-Smirnov) normality test data: x D = 0.029298, p-value = 0.09694 5.4.2 Shapiro - Wilk Cuando la muestra es como máximo de tamaño 50 se puede contrastar la normalidad con la prueba de Shapiro-Wilk. shapiro.test(x) Shapiro-Wilk normality test data: x W = 0.99592, p-value = 0.03198 5.5 Homogeneidad de varianzas (homoscedasticidad) 5.5.1 Test de Levene Por último, usamos el test de Levene para testar la homogeneidad de la varianza, sobre hatco.sav; este test necesita que la variable de grupos sea no numérica (lo que en R se llama factor()), por lo que creamos un factor para ella; sólo sería necesaria la transformación a factor() si se ha leído el archivo con haven; foreign ya crea factores. Aunque en nuestro caso la lectura se hace con expss que es derivado de foreign, aplicamos la transformación. x = hatco$x1 y = factor(hatco$x8) leveneTest(x ~ y, center = mean) Levene&#39;s Test for Homogeneity of Variance (center = mean) Df F value Pr(&gt;F) group 1 0.9342 0.3362 98 leveneTest(x ~ y, data = hatco, center = mean) Levene&#39;s Test for Homogeneity of Variance (center = mean) Df F value Pr(&gt;F) group 1 0.9342 0.3362 98 leveneTest(x ~ y, data = hatco, center = median) Levene&#39;s Test for Homogeneity of Variance (center = median) Df F value Pr(&gt;F) group 1 0.993 0.3215 98 leveneTest(x ~ y,data = hatco,center = mean, trim = 0.05) Levene&#39;s Test for Homogeneity of Variance (center = mean: 0.05) Df F value Pr(&gt;F) group 1 0.9341 0.3362 98 5.5.2 Diagramas de caja Este análisis se suele complementar con gráficos de caja, histogramas y calcularemos también los ratios de varianza que recordemos no nos proporciona SPSS. Se suele acompañar de los gráficos de caja (box-whiskers) e histogramas. boxplot(x ~ y, varwidth = TRUE, notch = FALSE, outline = TRUE, border = TRUE, main = &quot;Diagrama de caja general&quot;) x1 &lt;- hatco[hatco$x8 == &quot;1&quot;, ] summary(x1$x1) Min. 1st Qu. Median Mean 3rd Qu. Max. 0.000 1.900 2.400 2.500 3.025 4.900 hist(x1$x1, breaks = seq(from=0, to=10, by=1), xlab = &quot;Rapidez de servicio (1-10&quot;, ylab = &quot;Frecuencia&quot;, axes = TRUE, plot = TRUE, labels = TRUE, col = c(&quot;#eb6909&quot;), border = &quot;white&quot;, main = &quot;Diagrama de caja -&gt; X8 = grande&quot;) x0 &lt;- hatco[hatco$x8 == &quot;0&quot;, ] summary(x0$x1) Min. 1st Qu. Median Mean 3rd Qu. Max. 2.100 3.375 4.150 4.192 5.100 6.100 hist(x0$x1, breaks = seq(from=0, to=10, by=1), xlab = &quot;texto extra de x&quot;, ylab = &quot;Frecuencia&quot;, axes = TRUE, plot = TRUE, labels = TRUE, col = c(&quot;#eb6909&quot;), border = &quot;white&quot;, main = &quot;Diagrama de caja -&gt; X8 = pequeña&quot;) 5.5.3 Ratio de varianzas Para obtener el ratio de varianzas no existe una prueba directa, pero utilizamos el cálculo para poder hacerlo. Además condicionamos el cálculo para que nos ofrezca el mejor positivo. if (var(x0$x1) &gt; var(x1$x1)) (var(x0$x1) / var(x1$x1)) -&gt; ratio.vrz if (var(x0$x1) &lt; var(x1$x1)) (var(x1$x1) / var(x0$x1)) -&gt; ratio.vrz El ratio de varianzas es: 1.0365045 "],["s02.html", "Parte 6 Inferencia - Sesiones 1 y 2 6.1 Inferencia paramétrica 6.2 Inferencia no paramétrica", " Parte 6 Inferencia - Sesiones 1 y 2 El siguiente documento muestra todos los cálculos estadísticos que entre la primera y la segunda sesión de la asignatura Técnicas multivariantes en Investigación de Mercados dentro del máster oficial en Marketing e Investigación de mercados se observan. Este documento intenta ser una guía ilustrativa y demostrativa de como se trabaja con R, magnificando todas las virtudes de este software. x &lt;- gssft1$hrs1 ## asociamos a vector para no repetir el nombre de variable 6.1 Inferencia paramétrica Pruebas inferenciales realizadas con variables que cumplen los crirerios de nromalidad y/o homoscedasticidad. 6.1.1 Test t Student para la media de una muestra test_t &lt;- t.test( x, mu = 40, ## debe ser un parámetro abierto, es el valor de control na.rm = TRUE, alternative = &quot;two.sided&quot;, ## alternativas cerradas: &quot;two.sided&quot;, &quot;less&quot;, &quot;greater&quot; paired = FALSE, var.equal = FALSE, ## alternativas TRUE / FALSE conf.level = 0.95) ## se deben dar alternativas 0.90, 0.95, 0.9545, 0.99, 0.9975 print(test_t) One Sample t-test data: x t = 14.069, df = 438, p-value &lt; 2.2e-16 alternative hypothesis: true mean is not equal to 40 95 percent confidence interval: 46.22201 48.24268 sample estimates: mean of x 47.23235 6.1.2 Test t Student para la media de una muestra en grupos independientes El test puede hacerse con varianzas iguales o diferentes, x con z, varianzas iguales / diferentes; para saber si optamos por una u otra opción hacemos el test de Levene; este test necesita que la variable de grupos sea no numérica, por lo que creamos un factor para ella. si la probabilidad es mayor que 0.05, escogemos la prueba t de varianzas iguales; si la probabilidad es menor o igual que 0.05, escogemos la prueba t de varianzas distintas; atención si el nivel de confianza es 0.95, el valor de comparación de Levene es 1-0.95=0.05 6.1.2.1 Varianzas iguales x &lt;- gssnet2$emailhrs y &lt;- gssnet2$webhrs z &lt;- gssnet2$sex z &lt;- factor(z, labels = c(&quot;hombre&quot;, &quot;mujer&quot;)) output.levene &lt;- leveneTest(x ~ z, data = gssnet2, center = mean) print(output.levene) Levene&#39;s Test for Homogeneity of Variance (center = mean) Df F value Pr(&gt;F) group 1 0.5016 0.479 982 conflevel = 0.95 ## se deben dar alternativas 0.90, 0.95, 0.9545, 0.99, 0.9975 pctrl = 1 - conflevel ## cálculo del valor de control test_true &lt;- t.test( x ~ z, ## atención al cambo, desaparace mu y cambia la forma de X que es formula x ~ z na.rm = TRUE, alternative = &quot;two.sided&quot;, ## alternativas cerradas: &quot;two.sided&quot;, &quot;less&quot;, &quot;greater&quot; paired = FALSE, var.equal = TRUE, conf.level = conflevel) print(test_true) Two Sample t-test data: x by z t = 0.20832, df = 982, p-value = 0.835 alternative hypothesis: true difference in means between group hombre and group mujer is not equal to 0 95 percent confidence interval: -0.9158859 1.1334347 sample estimates: mean in group hombre mean in group mujer 3.371057 3.262282 t1 &lt;- test_true[[&quot;statistic&quot;]][[&quot;t&quot;]] print(t1) [1] 0.2083198 df1 &lt;- test_true[[&quot;parameter&quot;]][[&quot;df&quot;]] print(df1) [1] 982 effect.size.true &lt;- sqrt((t1 ^ 2) / ((t1 ^ 2) + df1)) print(effect.size.true) [1] 0.006647606 6.1.2.2 Varianzas no iguales test_false &lt;- t.test( x ~ z, na.rm = TRUE, alternative = &quot;two.sided&quot;, paired = FALSE, var.equal = FALSE, conf.level = conflevel) print(test_false) Welch Two Sample t-test data: x by z t = 0.20682, df = 893.88, p-value = 0.8362 alternative hypothesis: true difference in means between group hombre and group mujer is not equal to 0 95 percent confidence interval: -0.9234377 1.1409865 sample estimates: mean in group hombre mean in group mujer 3.371057 3.262282 t2 &lt;- test_false[[&quot;statistic&quot;]][[&quot;t&quot;]] print(t2) [1] 0.2068209 df2 &lt;- test_false[[&quot;parameter&quot;]][[&quot;df&quot;]] print(df2) [1] 893.8837 ## calculo del efecto effect.size.false &lt;- sqrt((t2 ^ 2) / ((t2 ^ 2) + df2)) print(effect.size.false) [1] 0.00691741 6.1.3 Test t Student para la media de una muestra en grupos dependientes x &lt;- endorph1$before y &lt;- endorph1$after media &lt;- mean(x - y, na.rm = TRUE) print(media) [1] -18.73636 desviacion &lt;- sd(x - y, na.rm = TRUE) print(desviacion) [1] 8.329739 errormedia &lt;- sd(x - y, na.rm = TRUE) / (sqrt(length(x))) print(errormedia) [1] 2.511511 int_inf &lt;- media - (2 * errormedia) print(int_inf) [1] -23.75939 int_sup &lt;- media + (2 * errormedia) print(int_sup) [1] -13.71334 lillieforsx &lt;- lillie.test(x) ## kolgomorov-smirnov con la correción de lilliefors print(lillieforsx) Lilliefors (Kolmogorov-Smirnov) normality test data: x D = 0.17365, p-value = 0.4668 lillieforsy &lt;- lillie.test(y) print(lillieforsy) Lilliefors (Kolmogorov-Smirnov) normality test data: y D = 0.12988, p-value = 0.87 shapirox &lt;- shapiro.test(x) ## shapiro - wilk print(shapirox) Shapiro-Wilk normality test data: x W = 0.86876, p-value = 0.07472 shapiroy &lt;- shapiro.test(y) print(shapiroy) Shapiro-Wilk normality test data: y W = 0.96441, p-value = 0.8252 test &lt;- t.test( x, y, na.rm = TRUE, alternative = &quot;two.sided&quot;, ## alternativas cerradas: &quot;two.sided&quot;, &quot;less&quot;, &quot;greater&quot; paired = TRUE, ## nótese que aquí es TRUE porque estamos en muestras pareadas conf.level = 0.95) print(test) Paired t-test data: x and y t = -7.4602, df = 10, p-value = 2.159e-05 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: -24.33236 -13.14037 sample estimates: mean of the differences -18.73636 ## cálculo del efecto tamaño t3 &lt;- test[[&quot;statistic&quot;]][[&quot;t&quot;]] print(t3) [1] -7.460197 df3 &lt;- test[[&quot;parameter&quot;]][[&quot;df&quot;]] print(df3) [1] 10 effect_size3 &lt;- sqrt((t3 ^ 2) / ((t3 ^ 2) + df3)) print(effect_size3) [1] 0.9206995 6.1.4 Correlación paramétrica de Pearson ## correlaciones x &lt;- anxiety$horas y &lt;- anxiety$nota z &lt;- anxiety$ansiedad pearson.1 &lt;- cor.test( x, y, alternative = &quot;two.sided&quot;,## alternativas cerradas: &quot;two.sided&quot;, &quot;less&quot;, &quot;greater&quot; method = &quot;pearson&quot;,## alternativas cerradas: &quot;pearson&quot;, &quot;kendall&quot;, &quot;spearman&quot; exact = NULL, conf.level = 0.95, continuity = FALSE) print(pearson.1) Pearson&#39;s product-moment correlation data: x and y t = 4.3434, df = 101, p-value = 3.343e-05 alternative hypothesis: true correlation is not equal to 0 95 percent confidence interval: 0.2200938 0.5481602 sample estimates: cor 0.3967207 anxiety.filter &lt;- select(anxiety, horas, nota, ansiedad) ## p.coef &lt;-cor(anxiety.filter, use = &quot;complete.obs&quot;, method = &quot;pearson&quot;) ## p.cor &lt;- cor(anxiety.filter, use = &quot;pairwise.complete.obs&quot;) p.pvalue &lt;- rcorr(as.matrix(anxiety.filter), type = &quot;pearson&quot;) ## se obtiene la matriz de correlación p.pvalue[[&quot;r&quot;]] ## matriz de correlación horas nota ansiedad horas 1.0000000 0.3967207 -0.7092493 nota 0.3967207 1.0000000 -0.4409934 ansiedad -0.7092493 -0.4409934 1.0000000 p.pvalue[[&quot;n&quot;]] ## pares analizados horas nota ansiedad horas 103 103 103 nota 103 103 103 ansiedad 103 103 103 p.pvalue[[&quot;P&quot;]] ## pvalue de los coeficientes horas nota ansiedad horas NA 3.343451e-05 0.000000e+00 nota 3.343451e-05 NA 3.127873e-06 ansiedad 0.000000e+00 3.127873e-06 NA plot(anxiety.filter) ## se obtiene el gráfico de dispersión 6.1.5 Análisis de varianza de un factor (vía) Nota: la variable de grupos ha de ser factor; si no es así no funciona el análisis. hatco$x14f &lt;- factor(hatco$x14, labels = c(&quot;nueva&quot;, &quot;recompra modificada&quot;, &quot;recompra&quot;)) hatco$x13f &lt;- factor(hatco$x13, labels = c(&quot;tipo 1&quot;, &quot;tipo2&quot;)) boxplot(hatco$x10 ~ hatco$x14f, col = &quot;lightgray&quot;) boxplot(hatco$x10 ~ hatco$x13f, col = &quot;lightgray&quot;) anova1 &lt;- aov(hatco$x10 ~ hatco$x14f) print(anova1) Call: aov(formula = hatco$x10 ~ hatco$x14f) Terms: hatco$x14f Residuals Sum of Squares 39.0068 33.4591 Deg. of Freedom 2 97 Residual standard error: 0.5873152 Estimated effects may be unbalanced summary(anova1) Df Sum Sq Mean Sq F value Pr(&gt;F) hatco$x14f 2 39.01 19.503 56.54 &lt;2e-16 *** Residuals 97 33.46 0.345 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 model.tables(anova1, &quot;means&quot;) Tables of means Grand mean 4.771 hatco$x14f nueva recompra modificada recompra 3.929 5.003 5.394 rep 34.000 32.000 34.000 6.1.6 Análisis de varianza de dos factores (vías) anova2 &lt;- aov(hatco$x10 ~ hatco$x14f + hatco$x13f) print(anova2) Call: aov(formula = hatco$x10 ~ hatco$x14f + hatco$x13f) Terms: hatco$x14f hatco$x13f Residuals Sum of Squares 39.00680 0.85383 32.60527 Deg. of Freedom 2 1 96 Residual standard error: 0.5827849 Estimated effects may be unbalanced summary(anova2) Df Sum Sq Mean Sq F value Pr(&gt;F) hatco$x14f 2 39.01 19.503 57.424 &lt;2e-16 *** hatco$x13f 1 0.85 0.854 2.514 0.116 Residuals 96 32.61 0.340 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 model.tables(anova2, &quot;means&quot;) Tables of means Grand mean 4.771 hatco$x14f nueva recompra modificada recompra 3.929 5.003 5.394 rep 34.000 32.000 34.000 hatco$x13f tipo 1 tipo2 4.863 4.679 rep 50.000 50.000 6.2 Inferencia no paramétrica 6.2.1 Prueba Chi 6.2.1.1 Prueba Chi2 de una muestra El test chi2 para una muestra, compara los resultados de una distribución marginal con los resultados proporcionados de forma externa. x &lt;- c(28, 47, 80, 82, 47, 35) y &lt;- c(30, 50, 75, 75, 50, 30) chisq000 &lt;- chisq.test(x, p = y, rescale.p = TRUE) print(chisq000) Chi-squared test for given probabilities data: x X-squared = 1.9941, df = 5, p-value = 0.85 6.2.1.2 Prueba Chi2 de una tabla tabla001 &lt;- table(data2$freedman, data2$sex) print(tabla001) Male Female Don&#39;t know 28 36 No Answer 1 10 Allowing people freedom of expression/tolerate bad manners 268 232 Enforcing good manners/limit freedom of expression 195 240 chisq001 &lt;- chisq.test(tabla001, correct = FALSE) ## prueba chi2 de tabla sin corrección de continuidad de Yates (solo en 2*2) print(chisq001) Pearson&#39;s Chi-squared test data: tabla001 X-squared = 14.951, df = 3, p-value = 0.001859 chisq002 &lt;- chisq.test(tabla001, correct = TRUE) ## prueba chi2 de tabla con corrección de continuidad, como es 2*2 aplica por defecto, si no fuera 2*2 no aplica la corrección print(chisq002) Pearson&#39;s Chi-squared test data: tabla001 X-squared = 14.951, df = 3, p-value = 0.001859 6.2.1.3 Otros test derivados otros &lt;- assocstats(tabla001) print(otros) X^2 df P(&gt; X^2) Likelihood Ratio 16.138 3 0.0010623 Pearson 14.951 3 0.0018586 Phi-Coefficient : NA Contingency Coeff.: 0.121 Cramer&#39;s V : 0.122 6.2.2 Correlaciones no paramétricas 6.2.2.1 Correlación de Spearman x &lt;- grades$Estadística y &lt;- grades$Selectivo spearman.1 &lt;- cor.test( x, y, alternative = &quot;two.sided&quot;, method = &quot;spearman&quot;, exact = NULL, conf.level = 0.95, continuity = FALSE) 6.2.2.2 Correlación de Kendall tau.b.kendall.1 &lt;- cor.test( x, y, alternative = &quot;two.sided&quot;, method = &quot;kendall&quot;, exact = NULL, conf.level = 0.95, continuity = FALSE) 6.2.3 Test de diferencias de una muestra en grupos independientes Probamos la normalidad de los grupos a comparar. Probamos la normalidad de cada grupo en cada variable y una vez probado que existen problemas de normalidad en algunos de los grupos, calculamos la prueba W de Wilcoxon. 6.2.3.1 Lilliefors y Shapiro-Wilk x &lt;- bdi$sunbdi y &lt;- bdi$wedbdi z &lt;- bdi$droga bdi.filter &lt;- filter (bdi, bdi$droga == 1) es &lt;- bdi.filter$sunbdi ## alcohol domingo bdi.filter &lt;- filter (bdi, bdi$droga == 2) as &lt;- bdi.filter$sunbdi ## extasis domingo bdi.filter &lt;- filter (bdi, bdi$droga == 1) ew &lt;- bdi.filter$wedbdi ## alcohol miercoles bdi.filter &lt;- filter (bdi, bdi$droga == 2) aw &lt;- bdi.filter$wedbdi ## extasis miercoles rm(bdi.filter) lillie.sun.1 &lt;- lillie.test(es) print(lillie.sun.1) Lilliefors (Kolmogorov-Smirnov) normality test data: es D = 0.27585, p-value = 0.02986 shap.sun.1 &lt;- shapiro.test(es) print(shap.sun.1) Shapiro-Wilk normality test data: es W = 0.81064, p-value = 0.01952 lillie.sun.2 &lt;- lillie.test(as) print(lillie.sun.2) Lilliefors (Kolmogorov-Smirnov) normality test data: as D = 0.16992, p-value = 0.5687 shap.sun.2 &lt;- shapiro.test(as) print(shap.sun.2) Shapiro-Wilk normality test data: as W = 0.95947, p-value = 0.7798 lillie.wed.1 &lt;- lillie.test(ew) print(lillie.wed.1) Lilliefors (Kolmogorov-Smirnov) normality test data: ew D = 0.23469, p-value = 0.1226 shap.wed.1 &lt;- shapiro.test(ew) print(shap.wed.1) Shapiro-Wilk normality test data: ew W = 0.94114, p-value = 0.5658 lillie.wed.2 &lt;- lillie.test(aw) print(lillie.wed.2) Lilliefors (Kolmogorov-Smirnov) normality test data: aw D = 0.30502, p-value = 0.00894 shap.wed.2 &lt;- shapiro.test(aw) print(shap.wed.2) Shapiro-Wilk normality test data: aw W = 0.75347, p-value = 0.003933 6.2.3.2 Prueba W de Wilcoxon - U Mann-Withney Aunque la probabilidad no es exactamente la misma, es muy aproximada. wilcox.test.1 &lt;- wilcox.test(as, es, paired = FALSE, alternative = &quot;two.sided&quot;, mu = 0, conf.int = 0.95) print(wilcox.test.1) Wilcoxon rank sum test with continuity correction data: as and es W = 35.5, p-value = 0.2861 alternative hypothesis: true location shift is not equal to 0 95 percent confidence interval: -5.000069 1.000079 sample estimates: difference in location -1.000027 wilcox.test.2 &lt;- wilcox.test(aw, ew, paired = FALSE, alternative = &quot;two.sided&quot;, mu = 0, conf.int = 0.95) print(wilcox.test.2) Wilcoxon rank sum test with continuity correction data: aw and ew W = 4, p-value = 0.000569 alternative hypothesis: true location shift is not equal to 0 95 percent confidence interval: -28.99996 -18.00005 sample estimates: difference in location -23.50122 6.2.4 Test de diferencias de una muestra en grupos dependientes 6.2.4.1 Prueba V de Wilcoxon Atención, resultado de la prueba es suma de rangos negativos. no es el mismo resultado que SPSS el valor, pero si la probabilidad aproximada. wilcox.test.3 &lt;- wilcox.test(es, ew, paired = TRUE, alternative = &quot;two.sided&quot;, mu = 0, conf.int = 0.99) print(wilcox.test.3) Wilcoxon signed rank test with continuity correction data: es and ew V = 0, p-value = 0.01403 alternative hypothesis: true location shift is not equal to 0 95 percent confidence interval: -19.99999 -10.49998 sample estimates: (pseudo)median -15.67111 wilcox.test.4 &lt;- wilcox.test(as, aw, paired = TRUE, alternative = &quot;two.sided&quot;, mu = 0, conf.int = 0.99) print(wilcox.test.4) Wilcoxon signed rank test with continuity correction data: as and aw V = 47, p-value = 0.05248 alternative hypothesis: true location shift is not equal to 0 95 percent confidence interval: -0.4999518 10.9999380 sample estimates: (pseudo)median 7.499968 "],["s03.html", "Parte 7 Análisis de correspondencias - Sesión 03 7.1 Introducción a la técnica 7.2 Prueba Chi^2 de homogeneidad 7.3 Nuestro ejemplo 7.4 Análisis de correspondencias simple (Michael Greenacre) 7.5 Análisis de correspondencias (CA de FactoMineR)", " Parte 7 Análisis de correspondencias - Sesión 03 7.1 Introducción a la técnica El análisis de correspondencias es una técnica de interdependencia cuyo objetivo es la representación de las relaciones bidimensionales derivadas de la relación entre dos variables o de un conjunto matricial de datos ordenados. Trabaja con variables no métricas aunque el contenido medido sea métrico (frecuencias, sumas, medias), pues realmente nos importan sus categorías o niveles, siendo posible utilizar la recodificación para obtener niveles de medida con los que trabajar. Se muestra para visualizar los diferentes niveles de medidas no métricas por lo que a menudo se le conoce como el análisis de representación de tablas de contingencia trabajando con el concepto de frecuencias relativas y distancias. 7.1.1 Transformación de datos cuantitativos a cualitativos En muchos casos se hace necesario obtener la tabla de frecuencias de partida utilizando algunas estrategias de cálculo, disponiendo de esta forma adecuada los datos: Cálculos de dicotomías Clasificación en intervalos Establecimiento de condiciones de corte Nuestro objetivo será la obtención de una tabla de doble entrada; en ocasiones la fuente de datos es ya elaborada de forma ajena a nuestro trabajo, es una tabla de un periódico o libro y se debe introducir al software usado. Para hacer esto, podemos crear un fichero con tres variables: variable fila, variable columna y peso en SPSS (ver siguiente) o la lectura de de la tabla o matriz de datos en R desde fichero texto, utilizando por ejemplo el paquete readr. Este es el método por el que optamos. #lectura de datos tabla.hatco &lt;- suppressMessages(read_csv(&quot;http://download.tesigandia.com/tmim/tabla.hatco.anacor.csv&quot;)) #eliminamos la primera columna (específico de paquete `ca` con el que trabajaremos que necesita `rownames`) tabla.hatco.ca &lt;- subset(tabla.hatco, select = -1) #asignamos los nombres de fila con la propiedad rownames, pues así lo necesita el paquete `ca`. rownames(tabla.hatco.ca) = c(&quot;x1&quot;, &quot;x2&quot;, &quot;x3&quot;, &quot;x4&quot;, &quot;x5&quot;, &quot;x6&quot;, &quot;x7&quot;, &quot;x8&quot;) El análisis de correspondencias no es exigente con las propiedades estadísticas de los datos. Como ya indicamos, utiliza variables no métricas en su forma más simple (tabla de contingencia), pero sin embargo hay que ser cuidadoso respecto al sentido del análisis en función de la representación de los datos. En nuestro ejemplo pensemos que  Los poseedores de los atributos son comparables respecto a esos atributos. Confirmar que las empresas A,B, , I son efectivamente competidoras de HATCO. Que basan su diferenciación en los atributos X1 a X8. El listado de atributos debe ser exhaustivo y no dejamos ninguno relevante para la caracterización de las empresas. Comenzamos por ver la relevancia de la tabla, validar si realmente hay un cierto nivel de dependencia entre las categorías de fila y las categorías de columna. Para ello utilizamos la prueba Chi^2. 7.2 Prueba Chi^2 de homogeneidad Para disponer de un indicador del ajuste de dependencia u homogeneidad, utilizamos la prueba de Chi^2 que la vimos en anteriores análisis. Cuánto mayor es el valor de Chi^2 mayores son las discrepancias entre observado y esperado. Sin embargo, sólo somos capaces de dimensionar en valor relativo cuando vemos otros indicadores como Phi o V de Cramer, que también serían posibles si el objeto fuera tabla calculada, pero en nuestro caso es leída directa, por lo que aplicamos las transformaciones de fichero a matrix y de matriz a table. No calculamos Phi porque no es una tabla de 2*2. tabla.hatco.ca &lt;- as.table(as.matrix(tabla.hatco.ca)) crosstable_statistics(tabla.hatco.ca) # Measure of Association for Contingency Tables Chi-squared: 122.6006 Cramer&#39;s V: 0.1435 df: 63 p-value: &lt; .001*** Observations: 851 7.3 Nuestro ejemplo HATCO quiere identificar a sus principales competidores: Quiere hacerlo en función de su posición respecto a las principales variables de competencia: X1 Rapidez del servicio X2 Nivel de precios X3 Flexibilidad de precios X4 Imagen del fabricante X5 Calidad del servicio X6 Imagen de los vendedores X7 Calidad del producto X8 Tamaño de la empresa La medida que se utiliza es la asociación de la característica con el competidor. Para ello se ha utilizado una transformación de la medición original a una caracterización (0/1). En nuestro ejemplo: en la tabla de contingencia, una frecuencia de 1 implica que ese competidor se ha señalado como que dispone de la característica competitiva en la característica o atributo de fila. 7.4 Análisis de correspondencias simple (Michael Greenacre) Calculamos utilizando el paquete ca de Michael Greenacre. Sus resultados son semejantes a SPSS pero el mapa sale invertido en cuadrantes, lo que no implica distinta interpretación. 7.4.1 Resumen de resultados Obtenemos los resultados más característicos con la función ca(). Almacenamos el objeto para ir mostrando después más completos sus resultados res &lt;- ca(tabla.hatco.ca) res Principal inertias (eigenvalues): 1 2 3 4 5 6 7 Value 0.076541 0.047813 0.015291 0.002658 0.000806 0.000576 0.000381 Percentage 53.13% 33.19% 10.61% 1.84% 0.56% 0.4% 0.26% Rows: x1 x2 x3 x4 x5 x6 x7 x8 Mass 0.146886 0.144536 0.098707 0.118684 0.123384 0.124559 0.081081 0.162162 ChiDist 0.199723 0.088497 0.580707 0.400294 0.285309 0.386846 0.808039 0.139329 Inertia 0.005859 0.001132 0.033286 0.019017 0.010044 0.018640 0.052940 0.003148 Dim. 1 -0.388333 -0.219066 -0.083693 1.285544 0.383784 0.836930 -2.863462 0.153942 Dim. 2 -0.524538 0.097621 2.641197 -0.610370 -1.073949 -0.211061 -0.636902 0.524856 Columns: hatco a b c d e f g h i Mass 0.108108 0.119859 0.089307 0.079906 0.078731 0.123384 0.113984 0.103408 0.076381 0.106933 ChiDist 0.287008 0.321688 0.430028 0.569393 0.402272 0.184239 0.257577 0.532696 0.491456 0.274442 Inertia 0.008905 0.012403 0.016515 0.025906 0.012740 0.004188 0.007562 0.029344 0.018448 0.008054 Dim. 1 0.470333 1.021735 0.843200 -1.933384 -0.969935 0.449822 0.838114 -1.680687 0.392286 -0.233423 Dim. 2 -0.626124 -0.580139 1.583295 0.793574 1.189113 -0.502451 -0.446827 -1.092070 1.944341 -0.784252 Para poder representar gráficamente los datos de la tabla, se debe reducir la dimensionalidad, puesto que solo vamos a ser capaces de ver los datos en mapas de dos dimensiones, o como mucho en tres. El mapa explica en sus dos primeras dimensiones el 86,3% de la información original (suma de las dos primeras dimensiones). Podemos luego combinar para otras dimensiones, 1-3, 2-5 pero es muy poco habitual, dado que la pérdida de información (y por tanto la dificultad de explicación) es muy alta. Analicemos ahora poco a poco los elementos que componen el análisis. Algunos datos relevantes son: Llamamos perfil al vector formado por los elementos de columna y/o fila. Llamamos perfil medio al perfil total de columna y/o al perfil total de columna. Otra forma de verlo: * Las coordenadas en el mapa se calculan utilizando algunos conceptos típicos en el análisis multivariante: * La inercia total, o medida de dispersión entre los perfiles y el perfil promedio, es un indicador de la dispersión o falta de correspondencia entre un punto fila y/o columna. Se calcula como el valor de Chi-cuadrado cociente con el total de casos. La hipótesis nula es una transformación de la estándar, el perfil medio sería la homogeneidad de los perfiles (Ho en Chi-cuadrado es la independencia). Homogeneidad = Independencia. Heterogeneidad = Dependencia. 7.4.1.0.1 Valor singular res[[&quot;sv&quot;]] #extraemos el elemento llamado sv [1] 0.27666126 0.21866273 0.12365880 0.05155155 0.02838433 0.02400166 0.01951441 7.4.1.1 Análisis de las filas 7.4.1.1.1 Nombre de las filas (atributos) res[[&quot;rownames&quot;]] [1] &quot;x1&quot; &quot;x2&quot; &quot;x3&quot; &quot;x4&quot; &quot;x5&quot; &quot;x6&quot; &quot;x7&quot; &quot;x8&quot; 7.4.1.1.2 Masa de las filas (perfil) Perfiles de las filas, son los porcentajes horizontales, aunque no se llaman así porque en muchos casos las columnas y/o filas de la tabla no son realmente categorías de una misma variable (frecuencias relativas). Llamados masa, es el cálculo de los porcentajes marginales (sin contar con la otra variable), denominado en algunos casos el perfil medio o también centroide o baricentro. Es decir el peso del atributo o de la empresa en el total marginal. res[[&quot;rowmass&quot;]] [1] 0.14688602 0.14453584 0.09870740 0.11868390 0.12338425 0.12455934 0.08108108 0.16216216 7.4.1.1.3 Distancia de las filas La representación de los datos de la tabla en el mapa se hace atendiendo al cálculo de distancias. El concepto de distancia, en este caso la distancia Chi-cuadrado o cálculo de la distancia euclídea entre los vectores fila y su masa de fila. res[[&quot;rowdist&quot;]] [1] 0.19972301 0.08849696 0.58070663 0.40029405 0.28530854 0.38684579 0.80803871 0.13932907 7.4.1.1.4 Inercia de las filas La inercia de cada perfil se calcula como producto de la masa por el cuadrado de la distancia chi-cuadrado de ese perfil al promedio. La inercia mide lo lejos que se hallan los perfiles fila o columna de su perfil medio. res[[&quot;rowinertia&quot;]] [1] 0.005859178 0.001131963 0.033286129 0.019017354 0.010043597 0.018640264 0.052939991 0.003147988 7.4.1.1.5 Coordenadas de las filas Punto de ubicación en el mapa de cada punto fila. res[[&quot;rowcoord&quot;]] Dim1 Dim2 Dim3 Dim4 Dim5 Dim6 Dim7 x1 -0.38833337 -0.52453784 -0.48064888 -2.0327480 0.7993536 -0.3021486 -0.53731697 x2 -0.21906639 0.09762105 -0.05138317 0.4795627 1.3748826 0.7323587 1.78938738 x3 -0.08369285 2.64119673 -0.34019450 -0.2493870 -0.6347806 -1.2085960 0.32626826 x4 1.28554439 -0.61037038 -0.89764463 -0.4026826 -1.7762794 0.8684848 0.72333444 x5 0.38378371 -1.07394894 -0.73674199 1.3240795 0.2697071 -1.8311119 -0.28708482 x6 0.83693026 -0.21106121 2.47591880 -0.1896399 -0.1476687 -0.2958822 -0.08839279 x7 -2.86346220 -0.63690241 0.48320469 0.4465221 -1.4975360 0.2144778 0.08239776 x8 0.15394237 0.52485592 -0.23761538 0.7752912 0.3939105 1.2342381 -1.59105249 7.4.1.2 Análisis de las columnas 7.4.1.2.1 Nombre de las columnas (las marcas) res[[&quot;colnames&quot;]] [1] &quot;hatco&quot; &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; &quot;f&quot; &quot;g&quot; &quot;h&quot; &quot;i&quot; 7.4.1.2.2 Masa de las columnas (perfil) Perfiles de las columnas, son los porcentajes verticales, aunque no se llaman así porque en muchos casos las columnas y/o filas de la tabla no son realmente categorías de una misma variable (frecuencias relativas). Llamados masa, es el cálculo de los porcentajes marginales (sin contar con la otra variable), denominado en algunos casos el perfil medio o también centroide o baricentro. Es decir el peso del atributo o de la empresa en el total marginal. res[[&quot;colmass&quot;]] [1] 0.10810811 0.11985899 0.08930670 0.07990599 0.07873090 0.12338425 0.11398355 0.10340776 0.07638073 0.10693302 7.4.1.2.3 Distancia de las columnas La representación de los datos de la tabla en el mapa se hace atendiendo al cálculo de distancias. El concepto de distancia, en este caso la distancia Chi-cuadrado o cálculo de la distancia euclídea entre los vectores columna y su masa de columna. res[[&quot;coldist&quot;]] [1] 0.2870082 0.3216884 0.4300280 0.5693934 0.4022721 0.1842392 0.2575766 0.5326961 0.4914556 0.2744416 7.4.1.2.4 Inercia de las columnas La inercia de cada perfil se calcula como producto de la masa por el cuadrado de la distancia chi-cuadrado de ese perfil al promedio. La inercia mide lo lejos que se hallan los perfiles fila o columna de su perfil medio. res[[&quot;colinertia&quot;]] [1] 0.008905264 0.012403421 0.016514959 0.025906232 0.012740460 0.004188165 0.007562317 0.029343514 0.018448129 0.008054000 7.4.1.2.5 Coordenadas de las columnas Punto de ubicación en el mapa de cada punto columna. res[[&quot;colcoord&quot;]] Dim1 Dim2 Dim3 Dim4 Dim5 Dim6 Dim7 hatco 0.4703327 -0.6261240 -1.6935356 -0.29465670 1.7292066 0.4655331 0.4460250 a 1.0217346 -0.5801388 0.5338336 0.07823246 -1.1100906 1.6894406 1.1173385 b 0.8432000 1.5832948 0.7964316 -0.26209544 -0.2874627 -0.1659282 -1.3363279 c -1.9333842 0.7935744 -0.1648613 -1.59150233 0.5015929 1.0023065 -0.3955033 d -0.9699347 1.1891134 1.1762320 -0.24157388 0.3215290 0.1038722 1.4550986 e 0.4498224 -0.5024514 0.2356379 -1.01941582 -0.2256877 -2.0473172 0.9157056 f 0.8381141 -0.4468266 -0.2145714 -0.65967745 -0.3110986 0.1309981 -1.6885279 g -1.6806871 -1.0920696 -0.6758338 0.77145803 -1.5096436 -0.3224750 -0.4368324 h 0.3922857 1.9443407 -1.6117961 1.83337906 -0.3985224 -0.4838085 0.4346288 i -0.2334232 -0.7842522 1.4674729 1.62005491 1.4611537 -0.1711086 -0.5078109 7.4.2 Representación gráfica: los mapas de puntos plot(res) plot(res, lines=TRUE) plot(res, arrows=c(TRUE, TRUE)) 7.5 Análisis de correspondencias (CA de FactoMineR) Ahora hacemos el cálculo con el algoritmo CA (nótese diferencia por mayúsculas) del paquete FactoMineR. Generamos una salida de tabla en modo gráfico, donde visualmente el diámetro de la circunferencia es mayor cuanto mayor sea el valor de la celda dtmatrix &lt;- as.matrix(tabla.hatco.ca) dttable &lt;- as.table(dtmatrix) balloonplot(t(dttable),main = &quot;Empresa * Atributo&quot;,xlab = &quot;Empresa&quot;,ylab = &quot;Atributo&quot;,label = TRUE,show.margins = TRUE) 7.5.1 Resultados Calculamos el análisis de correspondencias del paquete FactoMineR. Se usa la tabla original. Gráfico básico res.ca &lt;- CA(tabla.hatco.ca, graph = TRUE) Valores propios res.ca[[&quot;eig&quot;]] eigenvalue percentage of variance cumulative percentage of variance dim 1 0.0765414510 53.1292637 53.12926 dim 2 0.0478133897 33.1884248 86.31769 dim 3 0.0152914984 10.6141972 96.93189 dim 4 0.0026575621 1.8446778 98.77656 dim 5 0.0008056703 0.5592352 99.33580 dim 6 0.0005760795 0.3998706 99.73567 dim 7 0.0003808120 0.2643308 100.00000 Masa de las columnas round(res.ca[[&quot;call&quot;]][[&quot;marge.col&quot;]], 3) hatco a b c d e f g h i 0.108 0.120 0.089 0.080 0.079 0.123 0.114 0.103 0.076 0.107 Masa de las filas round(res.ca[[&quot;call&quot;]][[&quot;marge.row&quot;]], 3) x1 x2 x3 x4 x5 x6 x7 x8 0.147 0.145 0.099 0.119 0.123 0.125 0.081 0.162 Coordenadas de las filas round(res.ca[[&quot;row&quot;]][[&quot;coord&quot;]], 3) Dim 1 Dim 2 Dim 3 Dim 4 Dim 5 x1 0.107 -0.115 0.059 -0.105 0.023 x2 0.061 0.021 0.006 0.025 0.039 x3 0.023 0.578 0.042 -0.013 -0.018 x4 -0.356 -0.133 0.111 -0.021 -0.050 x5 -0.106 -0.235 0.091 0.068 0.008 x6 -0.232 -0.046 -0.306 -0.010 -0.004 x7 0.792 -0.139 -0.060 0.023 -0.043 x8 -0.043 0.115 0.029 0.040 0.011 Contribuciones de las filas round(res.ca[[&quot;row&quot;]][[&quot;contrib&quot;]], 3) Dim 1 Dim 2 Dim 3 Dim 4 Dim 5 x1 2.215 4.041 3.393 60.694 9.386 x2 0.694 0.138 0.038 3.324 27.322 x3 0.069 68.857 1.142 0.614 3.977 x4 19.614 4.422 9.563 1.924 37.447 x5 1.817 14.231 6.697 21.632 0.898 x6 8.725 0.555 76.357 0.448 0.272 x7 66.482 3.289 1.893 1.617 18.183 x8 0.384 4.467 0.916 9.747 2.516 Calidad de las filas round(res.ca[[&quot;row&quot;]][[&quot;cos2&quot;]], 3) Dim 1 Dim 2 Dim 3 Dim 4 Dim 5 x1 0.289 0.330 0.089 0.275 0.013 x2 0.469 0.058 0.005 0.078 0.194 x3 0.002 0.989 0.005 0.000 0.001 x4 0.789 0.111 0.077 0.003 0.016 x5 0.138 0.677 0.102 0.057 0.001 x6 0.358 0.014 0.626 0.001 0.000 x7 0.961 0.030 0.005 0.001 0.003 x8 0.093 0.678 0.044 0.082 0.006 Inercia de las filas round(res.ca[[&quot;row&quot;]][[&quot;inertia&quot;]], 3) [1] 0.006 0.001 0.033 0.019 0.010 0.019 0.053 0.003 Coordenadas de las columnas round(res.ca[[&quot;col&quot;]][[&quot;coord&quot;]], 3) Dim 1 Dim 2 Dim 3 Dim 4 Dim 5 hatco -0.130 -0.137 0.209 -0.015 0.049 a -0.283 -0.127 -0.066 0.004 -0.032 b -0.233 0.346 -0.098 -0.014 -0.008 c 0.535 0.174 0.020 -0.082 0.014 d 0.268 0.260 -0.145 -0.012 0.009 e -0.124 -0.110 -0.029 -0.053 -0.006 f -0.232 -0.098 0.027 -0.034 -0.009 g 0.465 -0.239 0.084 0.040 -0.043 h -0.109 0.425 0.199 0.095 -0.011 i 0.065 -0.171 -0.181 0.084 0.041 Contribuciones de las columnas round(res.ca[[&quot;col&quot;]][[&quot;contrib&quot;]], 3) Dim 1 Dim 2 Dim 3 Dim 4 Dim 5 hatco 2.391 4.238 31.006 0.939 32.326 a 12.513 4.034 3.416 0.073 14.770 b 6.350 22.388 5.665 0.613 0.738 c 29.869 5.032 0.217 20.239 2.010 d 7.407 11.132 10.893 0.459 0.814 e 2.497 3.115 0.685 12.822 0.628 f 8.007 2.276 0.525 4.960 1.103 g 29.210 12.333 4.723 6.154 23.567 h 1.175 28.875 19.843 25.674 1.213 i 0.583 6.577 23.028 28.065 22.830 Calidad de las columnas round(res.ca[[&quot;col&quot;]][[&quot;cos2&quot;]], 3) Dim 1 Dim 2 Dim 3 Dim 4 Dim 5 hatco 0.206 0.228 0.532 0.003 0.029 a 0.772 0.156 0.042 0.000 0.010 b 0.294 0.648 0.052 0.001 0.000 c 0.882 0.093 0.001 0.021 0.001 d 0.445 0.418 0.131 0.001 0.001 e 0.456 0.356 0.025 0.081 0.001 f 0.810 0.144 0.011 0.017 0.001 g 0.762 0.201 0.025 0.006 0.006 h 0.049 0.748 0.164 0.037 0.001 i 0.055 0.390 0.437 0.093 0.023 Inercia de las columnas round(res.ca[[&quot;col&quot;]][[&quot;inertia&quot;]], 3) [1] 0.009 0.012 0.017 0.026 0.013 0.004 0.008 0.029 0.018 0.008 7.5.2 Calidad Calculamos el gráfico de las calidad de la varianza explicada por las dimensiones, descendente por representación. fviz_eig( res.ca, choice = c(&quot;variance&quot;, &quot;eigenvalue&quot;), geom = c(&quot;bar&quot;, &quot;line&quot;), barfill = &quot;grey&quot;, barcolor = &quot;grey&quot;, linecolor = &quot;red&quot;, addlabels = TRUE, hjust = 0, main = &quot;análisis de correspondencias&quot;, xlab = &quot;Dimensiones&quot;, ylab = &quot;% varianza&quot;, ggtheme = theme_minimal(), ylim = c(0, 100), repel = FALSE ) 7.5.3 Mapas de puntos Calculamos el mapa de filas y columnas en el mismo plano y los mapas conjuntos (mapa clásico y relacionados) fviz_ca_biplot( res.ca, map = &quot;symmetric&quot;, title = &quot;análisis de correspondencias: simétrico&quot;, arrow = c(TRUE, TRUE), repel = TRUE ) fviz_ca_biplot( res.ca, map = &quot;rowprincipal&quot;, title = &quot;análisis de correspondencias: fila&quot;, arrow = c(TRUE, TRUE), repel = TRUE ) fviz_ca_biplot( res.ca, map = &quot;colprincipal&quot;, title = &quot;análisis de correspondencias: columna&quot;, arrow = c(TRUE, TRUE), repel = TRUE ) fviz_ca_biplot( res.ca, map = &quot;rowgreen&quot;, title = &quot;análisis de correspondencias: puntos fila más representativos&quot;, arrow = c(TRUE, TRUE), repel = TRUE ) fviz_ca_biplot( res.ca, map = &quot;colgreen&quot;, title = &quot;análisis de correspondencias: puntos columna más representativos&quot;, arrow = c(TRUE, TRUE), repel = TRUE ) fviz_ca_biplot( res.ca, map = &quot;symbiplot&quot;, title = &quot;análisis de correspondencias: simétrico sin preservar métrica de filas y/o columnas&quot;, arrow = c(TRUE, TRUE), repel = TRUE ) fviz_ca_biplot( res.ca, map = &quot;rowgab&quot;, title = &quot;análisis de correspondencias: asimétrico filas&quot;, arrow = c(TRUE, TRUE), repel = TRUE ) fviz_ca_biplot( res.ca, map = &quot;colgab&quot;, title = &quot;análisis de correspondencias: asimétrico columnas&quot;, arrow = c(TRUE, TRUE), repel = TRUE ) 7.5.4 Otros gráficos Calculamos otros gráficos de soporte a la comprensión del análisis Mapa de filas fviz_ca_row(res.ca, repel = TRUE, col.row = &quot;blue&quot;) Mapa de columnas fviz_ca_col(res.ca, repel = TRUE, col.col = &quot;red&quot;) Calidad de puntos columna fviz_ca_row( res.ca, col.row = &quot;cos2&quot;, gradient.cols = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;, &quot;#FC4E07&quot;), repel = TRUE ) Calidad de puntos fila fviz_ca_col( res.ca, col.col = &quot;cos2&quot;, gradient.cols = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;, &quot;#FC4E07&quot;), repel = TRUE ) Creamos un mapa de correlación entre calidad filas/columnas y dimensiones corrplot(res.ca[[&quot;row&quot;]][[&quot;cos2&quot;]], is.corr = FALSE) Calidad de representación corrplot(res.ca[[&quot;col&quot;]][[&quot;cos2&quot;]], is.corr = FALSE) Calidad de filas fviz_cos2(res.ca, choice = &quot;row&quot;, axes = 1:2) Calidad de columnas fviz_cos2(res.ca, choice = &quot;col&quot;, axes = 1:2) Correlación filas en dimensiones corrplot(res.ca[[&quot;row&quot;]][[&quot;contrib&quot;]], is.corr = FALSE) Correlación columnas en dimensiones corrplot(res.ca[[&quot;col&quot;]][[&quot;contrib&quot;]], is.corr = FALSE) Contribuciones de las filas a la primera dimensión fviz_contrib(res.ca, choice = &quot;row&quot;, axes = 1, top = 10) Contribuciones de las filas a la segunda dimensión fviz_contrib(res.ca, choice = &quot;row&quot;, axes = 2, top = 10) Contribuciones de las columnas a la primera dimensión fviz_contrib(res.ca, choice = &quot;col&quot;, axes = 1, top = 10) Contribuciones de las columnas a la segunda dimensión fviz_contrib(res.ca, choice = &quot;col&quot;, axes = 2, top = 10) Contribuciones de fila con gradiente fviz_ca_row( res.ca, col.row = &quot;contrib&quot;, gradient.cols = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;, &quot;#FC4E07&quot;), repel = TRUE ) Calidad de fila con gradiente fviz_ca_row( res.ca, col.row = &quot;cos2&quot;, gradient.cols = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;, &quot;#FC4E07&quot;), repel = TRUE ) Contribuciones de columna con gradiente fviz_ca_col( res.ca, col.col = &quot;contrib&quot;, gradient.cols = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;, &quot;#FC4E07&quot;), repel = TRUE ) Calidad de columna con gradiente fviz_ca_col( res.ca, col.col = &quot;cos2&quot;, gradient.cols = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;, &quot;#FC4E07&quot;), repel = TRUE ) "],["s04.html", "Parte 8 Análisis de componentes principales - Sesión 04 8.1 Análisis de correlación 8.2 Test de esfericidad de Bartlett 8.3 Análisis de componentes principales 8.4 Resumen de resultados 8.5 Gráficos del análisis", " Parte 8 Análisis de componentes principales - Sesión 04 #sesion 04 hbat &lt;- suppressMessages(read_spss(&quot;http://download.tesigandia.com/tmim/hbat.sav&quot;)) data00 &lt;- subset(hbat, select = c(x6, x7, x8, x9, x10, x11, x12, x13, x14, x15, x16, x17, x18)) 8.1 Análisis de correlación Calculamos la correlación. Si algún valor está en el MSA está por debajo de 0.5 lo eliminamos (por orden y solo uno en cada paso) y volvemos a hacer la correlación y cálculo de Kaiser-Meyer-Olkin; solo así quedarán las mejores variables. rcorr(as.matrix(data00), type = &quot;pearson&quot;) x6 x7 x8 x9 x10 x11 x12 x13 x14 x15 x16 x17 x18 x6 1.00 -0.14 0.10 0.11 -0.05 0.48 -0.15 -0.40 0.09 0.03 0.10 -0.49 0.03 x7 -0.14 1.00 0.00 0.14 0.43 -0.05 0.79 0.23 0.05 -0.03 0.16 0.27 0.19 x8 0.10 0.00 1.00 0.10 -0.06 0.19 0.02 -0.27 0.80 -0.07 0.08 -0.19 0.03 x9 0.11 0.14 0.10 1.00 0.20 0.56 0.23 -0.13 0.14 0.06 0.76 0.39 0.87 x10 -0.05 0.43 -0.06 0.20 1.00 -0.01 0.54 0.13 0.01 0.08 0.18 0.33 0.28 x11 0.48 -0.05 0.19 0.56 -0.01 1.00 -0.06 -0.49 0.27 0.05 0.42 -0.38 0.60 x12 -0.15 0.79 0.02 0.23 0.54 -0.06 1.00 0.26 0.11 0.03 0.20 0.35 0.27 x13 -0.40 0.23 -0.27 -0.13 0.13 -0.49 0.26 1.00 -0.24 0.02 -0.11 0.47 -0.07 x14 0.09 0.05 0.80 0.14 0.01 0.27 0.11 -0.24 1.00 0.04 0.20 -0.17 0.11 x15 0.03 -0.03 -0.07 0.06 0.08 0.05 0.03 0.02 0.04 1.00 0.07 0.09 0.11 x16 0.10 0.16 0.08 0.76 0.18 0.42 0.20 -0.11 0.20 0.07 1.00 0.41 0.75 x17 -0.49 0.27 -0.19 0.39 0.33 -0.38 0.35 0.47 -0.17 0.09 0.41 1.00 0.50 x18 0.03 0.19 0.03 0.87 0.28 0.60 0.27 -0.07 0.11 0.11 0.75 0.50 1.00 n= 100 P x6 x7 x8 x9 x10 x11 x12 x13 x14 x15 x16 x17 x18 x6 0.1736 0.3441 0.2922 0.5972 0.0000 0.1316 0.0000 0.3823 0.7898 0.3017 0.0000 0.7843 x7 0.1736 0.9932 0.1642 0.0000 0.6026 0.0000 0.0216 0.6081 0.7865 0.1208 0.0065 0.0561 x8 0.3441 0.9932 0.3387 0.5343 0.0549 0.8668 0.0064 0.0000 0.4669 0.4282 0.0638 0.8016 x9 0.2922 0.1642 0.3387 0.0496 0.0000 0.0215 0.2046 0.1635 0.5572 0.0000 0.0000 0.0000 x10 0.5972 0.0000 0.5343 0.0496 0.9092 0.0000 0.1831 0.9151 0.4051 0.0665 0.0007 0.0055 x11 0.0000 0.6026 0.0549 0.0000 0.9092 0.5445 0.0000 0.0060 0.6483 0.0000 0.0001 0.0000 x12 0.1316 0.0000 0.8668 0.0215 0.0000 0.5445 0.0078 0.2873 0.7547 0.0517 0.0003 0.0063 x13 0.0000 0.0216 0.0064 0.2046 0.1831 0.0000 0.0078 0.0140 0.8191 0.2564 0.0000 0.4712 x14 0.3823 0.6081 0.0000 0.1635 0.9151 0.0060 0.2873 0.0140 0.7281 0.0494 0.0904 0.2786 x15 0.7898 0.7865 0.4669 0.5572 0.4051 0.6483 0.7547 0.8191 0.7281 0.4980 0.3516 0.2950 x16 0.3017 0.1208 0.4282 0.0000 0.0665 0.0000 0.0517 0.2564 0.0494 0.4980 0.0000 0.0000 x17 0.0000 0.0065 0.0638 0.0000 0.0007 0.0001 0.0003 0.0000 0.0904 0.3516 0.0000 0.0000 x18 0.7843 0.0561 0.8016 0.0000 0.0055 0.0000 0.0063 0.4712 0.2786 0.2950 0.0000 0.0000 Calculamos Kaiser - Meyer - Olkin y MSA KMO(data00) Kaiser-Meyer-Olkin factor adequacy Call: KMO(r = data00) Overall MSA = 0.61 MSA for each item = x6 x7 x8 x9 x10 x11 x12 x13 x14 x15 x16 x17 x18 0.87 0.62 0.53 0.89 0.81 0.45 0.59 0.88 0.53 0.31 0.86 0.44 0.53 Quitamos X15, dado que su MSA es 0.31, y es el peor de todos los coeeficientes, estando por debajo de 0.5. data01 &lt;- subset(hbat, select = c(x6, x7, x8, x9, x10, x11, x12, x13, x14, x16, x17, x18)) rcorr(as.matrix(data01), type = &quot;pearson&quot;) x6 x7 x8 x9 x10 x11 x12 x13 x14 x16 x17 x18 x6 1.00 -0.14 0.10 0.11 -0.05 0.48 -0.15 -0.40 0.09 0.10 -0.49 0.03 x7 -0.14 1.00 0.00 0.14 0.43 -0.05 0.79 0.23 0.05 0.16 0.27 0.19 x8 0.10 0.00 1.00 0.10 -0.06 0.19 0.02 -0.27 0.80 0.08 -0.19 0.03 x9 0.11 0.14 0.10 1.00 0.20 0.56 0.23 -0.13 0.14 0.76 0.39 0.87 x10 -0.05 0.43 -0.06 0.20 1.00 -0.01 0.54 0.13 0.01 0.18 0.33 0.28 x11 0.48 -0.05 0.19 0.56 -0.01 1.00 -0.06 -0.49 0.27 0.42 -0.38 0.60 x12 -0.15 0.79 0.02 0.23 0.54 -0.06 1.00 0.26 0.11 0.20 0.35 0.27 x13 -0.40 0.23 -0.27 -0.13 0.13 -0.49 0.26 1.00 -0.24 -0.11 0.47 -0.07 x14 0.09 0.05 0.80 0.14 0.01 0.27 0.11 -0.24 1.00 0.20 -0.17 0.11 x16 0.10 0.16 0.08 0.76 0.18 0.42 0.20 -0.11 0.20 1.00 0.41 0.75 x17 -0.49 0.27 -0.19 0.39 0.33 -0.38 0.35 0.47 -0.17 0.41 1.00 0.50 x18 0.03 0.19 0.03 0.87 0.28 0.60 0.27 -0.07 0.11 0.75 0.50 1.00 n= 100 P x6 x7 x8 x9 x10 x11 x12 x13 x14 x16 x17 x18 x6 0.1736 0.3441 0.2922 0.5972 0.0000 0.1316 0.0000 0.3823 0.3017 0.0000 0.7843 x7 0.1736 0.9932 0.1642 0.0000 0.6026 0.0000 0.0216 0.6081 0.1208 0.0065 0.0561 x8 0.3441 0.9932 0.3387 0.5343 0.0549 0.8668 0.0064 0.0000 0.4282 0.0638 0.8016 x9 0.2922 0.1642 0.3387 0.0496 0.0000 0.0215 0.2046 0.1635 0.0000 0.0000 0.0000 x10 0.5972 0.0000 0.5343 0.0496 0.9092 0.0000 0.1831 0.9151 0.0665 0.0007 0.0055 x11 0.0000 0.6026 0.0549 0.0000 0.9092 0.5445 0.0000 0.0060 0.0000 0.0001 0.0000 x12 0.1316 0.0000 0.8668 0.0215 0.0000 0.5445 0.0078 0.2873 0.0517 0.0003 0.0063 x13 0.0000 0.0216 0.0064 0.2046 0.1831 0.0000 0.0078 0.0140 0.2564 0.0000 0.4712 x14 0.3823 0.6081 0.0000 0.1635 0.9151 0.0060 0.2873 0.0140 0.0494 0.0904 0.2786 x16 0.3017 0.1208 0.4282 0.0000 0.0665 0.0000 0.0517 0.2564 0.0494 0.0000 0.0000 x17 0.0000 0.0065 0.0638 0.0000 0.0007 0.0001 0.0003 0.0000 0.0904 0.0000 0.0000 x18 0.7843 0.0561 0.8016 0.0000 0.0055 0.0000 0.0063 0.4712 0.2786 0.0000 0.0000 Calculamos Kaiser - Meyer - Olkin y MSA KMO(data01) Kaiser-Meyer-Olkin factor adequacy Call: KMO(r = data01) Overall MSA = 0.61 MSA for each item = x6 x7 x8 x9 x10 x11 x12 x13 x14 x16 x17 x18 0.88 0.62 0.53 0.89 0.80 0.45 0.59 0.88 0.53 0.86 0.44 0.53 Quitamos X17, dado que su MSA es 0.44, y es el peor de todos los coeeficientes, estando por debajo de 0.5. data02 &lt;- subset(hbat, select = c(x6, x7, x8, x9, x10, x11, x12, x13, x14, x16, x18)) rcorr(as.matrix(data02), type = &quot;pearson&quot;) x6 x7 x8 x9 x10 x11 x12 x13 x14 x16 x18 x6 1.00 -0.14 0.10 0.11 -0.05 0.48 -0.15 -0.40 0.09 0.10 0.03 x7 -0.14 1.00 0.00 0.14 0.43 -0.05 0.79 0.23 0.05 0.16 0.19 x8 0.10 0.00 1.00 0.10 -0.06 0.19 0.02 -0.27 0.80 0.08 0.03 x9 0.11 0.14 0.10 1.00 0.20 0.56 0.23 -0.13 0.14 0.76 0.87 x10 -0.05 0.43 -0.06 0.20 1.00 -0.01 0.54 0.13 0.01 0.18 0.28 x11 0.48 -0.05 0.19 0.56 -0.01 1.00 -0.06 -0.49 0.27 0.42 0.60 x12 -0.15 0.79 0.02 0.23 0.54 -0.06 1.00 0.26 0.11 0.20 0.27 x13 -0.40 0.23 -0.27 -0.13 0.13 -0.49 0.26 1.00 -0.24 -0.11 -0.07 x14 0.09 0.05 0.80 0.14 0.01 0.27 0.11 -0.24 1.00 0.20 0.11 x16 0.10 0.16 0.08 0.76 0.18 0.42 0.20 -0.11 0.20 1.00 0.75 x18 0.03 0.19 0.03 0.87 0.28 0.60 0.27 -0.07 0.11 0.75 1.00 n= 100 P x6 x7 x8 x9 x10 x11 x12 x13 x14 x16 x18 x6 0.1736 0.3441 0.2922 0.5972 0.0000 0.1316 0.0000 0.3823 0.3017 0.7843 x7 0.1736 0.9932 0.1642 0.0000 0.6026 0.0000 0.0216 0.6081 0.1208 0.0561 x8 0.3441 0.9932 0.3387 0.5343 0.0549 0.8668 0.0064 0.0000 0.4282 0.8016 x9 0.2922 0.1642 0.3387 0.0496 0.0000 0.0215 0.2046 0.1635 0.0000 0.0000 x10 0.5972 0.0000 0.5343 0.0496 0.9092 0.0000 0.1831 0.9151 0.0665 0.0055 x11 0.0000 0.6026 0.0549 0.0000 0.9092 0.5445 0.0000 0.0060 0.0000 0.0000 x12 0.1316 0.0000 0.8668 0.0215 0.0000 0.5445 0.0078 0.2873 0.0517 0.0063 x13 0.0000 0.0216 0.0064 0.2046 0.1831 0.0000 0.0078 0.0140 0.2564 0.4712 x14 0.3823 0.6081 0.0000 0.1635 0.9151 0.0060 0.2873 0.0140 0.0494 0.2786 x16 0.3017 0.1208 0.4282 0.0000 0.0665 0.0000 0.0517 0.2564 0.0494 0.0000 x18 0.7843 0.0561 0.8016 0.0000 0.0055 0.0000 0.0063 0.4712 0.2786 0.0000 Calculamos Kaiser - Meyer - Olkin y MSA KMO(data02) Kaiser-Meyer-Olkin factor adequacy Call: KMO(r = data02) Overall MSA = 0.65 MSA for each item = x6 x7 x8 x9 x10 x11 x12 x13 x14 x16 x18 0.51 0.63 0.52 0.79 0.78 0.62 0.62 0.75 0.51 0.76 0.67 X11 que tenía un MSA de 0.45 y era candidato, ahora supera el 0.5 de MSA. Decidimos seguir con los siguientes pasos. Calculamos el test de esfericidad de Bartlett, donde la Ho es la igualdad de la matriz de correlaciones a la matriz identidad, es decir la ausencia de correlación entre las variables que conforman la estructura a analizar. Analizamos el test de esfericidad de Bartlett. 8.2 Test de esfericidad de Bartlett bartlett.test(data02) Bartlett test of homogeneity of variances data: data02 Bartlett&#39;s K-squared = 146.4, df = 10, p-value &lt; 2.2e-16 Dado que es correcto y rechazamos la hipótesis nula, continuamos con el análisis de componentes. 8.3 Análisis de componentes principales output &lt;- principal(data02, nfactors=4, rotate=&quot;varimax&quot;) output Principal Components Analysis Call: principal(r = data02, nfactors = 4, rotate = &quot;varimax&quot;) Standardized loadings (pattern matrix) based upon correlation matrix RC1 RC2 RC3 RC4 h2 u2 com x6 0.00 -0.01 -0.03 0.88 0.77 0.232 1.0 x7 0.06 0.87 0.05 -0.12 0.78 0.223 1.1 x8 0.02 -0.02 0.94 0.10 0.89 0.107 1.0 x9 0.93 0.12 0.05 0.09 0.88 0.119 1.1 x10 0.14 0.74 -0.08 0.01 0.58 0.424 1.1 x11 0.59 -0.06 0.15 0.64 0.79 0.213 2.1 x12 0.13 0.90 0.08 -0.16 0.86 0.141 1.1 x13 -0.09 0.23 -0.25 -0.72 0.64 0.359 1.5 x14 0.11 0.05 0.93 0.10 0.89 0.108 1.1 x16 0.86 0.11 0.08 0.04 0.77 0.234 1.1 x18 0.94 0.18 0.00 0.05 0.91 0.086 1.1 RC1 RC2 RC3 RC4 SS loadings 2.89 2.23 1.86 1.77 Proportion Var 0.26 0.20 0.17 0.16 Cumulative Var 0.26 0.47 0.63 0.80 Proportion Explained 0.33 0.26 0.21 0.20 Cumulative Proportion 0.33 0.59 0.80 1.00 Mean item complexity = 1.2 Test of the hypothesis that 4 components are sufficient. The root mean square of the residuals (RMSR) is 0.06 with the empirical chi square 39.02 with prob &lt; 0.0018 Fit based upon off diagonal values = 0.97 Analizamos las comunalidades continuando con la adecuación de los datos al análisis, vemos que tenemos que eliminar X11pues mantiene cargas cruzadas superiores a 0.5 en dos componentes (0.59 en RC1 y 0.64 en RC4). Eliminamos esa variable del set de datos, y volvemos a lanzar las pruebas preliminares al análisis de componentes principales. data03 &lt;- subset(hbat, select = c(x6, x7, x8, x9, x10, x12, x13, x14, x16, x18)) rcorr(as.matrix(data03), type = &quot;pearson&quot;) x6 x7 x8 x9 x10 x12 x13 x14 x16 x18 x6 1.00 -0.14 0.10 0.11 -0.05 -0.15 -0.40 0.09 0.10 0.03 x7 -0.14 1.00 0.00 0.14 0.43 0.79 0.23 0.05 0.16 0.19 x8 0.10 0.00 1.00 0.10 -0.06 0.02 -0.27 0.80 0.08 0.03 x9 0.11 0.14 0.10 1.00 0.20 0.23 -0.13 0.14 0.76 0.87 x10 -0.05 0.43 -0.06 0.20 1.00 0.54 0.13 0.01 0.18 0.28 x12 -0.15 0.79 0.02 0.23 0.54 1.00 0.26 0.11 0.20 0.27 x13 -0.40 0.23 -0.27 -0.13 0.13 0.26 1.00 -0.24 -0.11 -0.07 x14 0.09 0.05 0.80 0.14 0.01 0.11 -0.24 1.00 0.20 0.11 x16 0.10 0.16 0.08 0.76 0.18 0.20 -0.11 0.20 1.00 0.75 x18 0.03 0.19 0.03 0.87 0.28 0.27 -0.07 0.11 0.75 1.00 n= 100 P x6 x7 x8 x9 x10 x12 x13 x14 x16 x18 x6 0.1736 0.3441 0.2922 0.5972 0.1316 0.0000 0.3823 0.3017 0.7843 x7 0.1736 0.9932 0.1642 0.0000 0.0000 0.0216 0.6081 0.1208 0.0561 x8 0.3441 0.9932 0.3387 0.5343 0.8668 0.0064 0.0000 0.4282 0.8016 x9 0.2922 0.1642 0.3387 0.0496 0.0215 0.2046 0.1635 0.0000 0.0000 x10 0.5972 0.0000 0.5343 0.0496 0.0000 0.1831 0.9151 0.0665 0.0055 x12 0.1316 0.0000 0.8668 0.0215 0.0000 0.0078 0.2873 0.0517 0.0063 x13 0.0000 0.0216 0.0064 0.2046 0.1831 0.0078 0.0140 0.2564 0.4712 x14 0.3823 0.6081 0.0000 0.1635 0.9151 0.2873 0.0140 0.0494 0.2786 x16 0.3017 0.1208 0.4282 0.0000 0.0665 0.0517 0.2564 0.0494 0.0000 x18 0.7843 0.0561 0.8016 0.0000 0.0055 0.0063 0.4712 0.2786 0.0000 Analizamos Kaiser - Meyer - Olkin y MSA KMO(data03) Kaiser-Meyer-Olkin factor adequacy Call: KMO(r = data03) Overall MSA = 0.67 MSA for each item = x6 x7 x8 x9 x10 x12 x13 x14 x16 x18 0.61 0.64 0.52 0.69 0.81 0.63 0.74 0.53 0.83 0.72 Consiguiendo de nuevo valores válidos en este caso para continuar con el proceso, donde volvemos a recalcular Bartlett. bartlett.test(data03) Bartlett test of homogeneity of variances data: data03 Bartlett&#39;s K-squared = 142.71, df = 9, p-value &lt; 2.2e-16 Es óptimo y analizamos el resultado de componentes  KMO(data03) Kaiser-Meyer-Olkin factor adequacy Call: KMO(r = data03) Overall MSA = 0.67 MSA for each item = x6 x7 x8 x9 x10 x12 x13 x14 x16 x18 0.61 0.64 0.52 0.69 0.81 0.63 0.74 0.53 0.83 0.72 8.4 Resumen de resultados 8.4.1 Rotación Varimax (ACP, psych) output &lt;- principal(data03, nfactors=4, rotate=&quot;varimax&quot;) output Principal Components Analysis Call: principal(r = data03, nfactors = 4, rotate = &quot;varimax&quot;) Standardized loadings (pattern matrix) based upon correlation matrix RC1 RC2 RC3 RC4 h2 u2 com x6 0.03 -0.01 -0.02 0.89 0.80 0.20 1.0 x7 0.06 0.87 0.05 -0.14 0.78 0.22 1.1 x8 0.02 -0.02 0.94 0.10 0.89 0.11 1.0 x9 0.93 0.10 0.06 0.08 0.89 0.11 1.0 x10 0.16 0.74 -0.08 0.04 0.58 0.42 1.1 x12 0.14 0.90 0.08 -0.17 0.86 0.14 1.1 x13 -0.10 0.23 -0.26 -0.73 0.66 0.34 1.5 x14 0.10 0.05 0.93 0.08 0.89 0.11 1.0 x16 0.89 0.10 0.09 0.07 0.81 0.19 1.1 x18 0.93 0.17 0.00 0.01 0.89 0.11 1.1 RC1 RC2 RC3 RC4 SS loadings 2.59 2.22 1.85 1.41 Proportion Var 0.26 0.22 0.18 0.14 Cumulative Var 0.26 0.48 0.67 0.81 Proportion Explained 0.32 0.28 0.23 0.17 Cumulative Proportion 0.32 0.60 0.83 1.00 Mean item complexity = 1.1 Test of the hypothesis that 4 components are sufficient. The root mean square of the residuals (RMSR) is 0.06 with the empirical chi square 35.71 with prob &lt; 0.00019 Fit based upon off diagonal values = 0.96 La salida de la función print.psych muestra las cargas de los componentes (de la matriz del modelo), la h2 (comunalidades) la u2 (las singularidades [1-h2]) y la complejidad de las cargas de los componentes para esa variable (índice de Hoffman) 8.5 Gráficos del análisis biplot.psych(output) plot(output) cor.plot(output, numbers=TRUE) fa.diagram(output) "],["s05.html", "Parte 9 Análisis de cluster - Sesión 05 9.1 Cálculo de distancias 9.2 Clúster jerárquico 9.3 Clúster K-medias", " Parte 9 Análisis de cluster - Sesión 05 Cargamos los paquetes necesarios y los datos del archivo hatco.sav options(scipen=9,width=80) data &lt;- read_spss(&quot;http://download.tesigandia.com/tmim/hatco.sav&quot;) No retenemos todo el archivo, sino que hacemos un subfichero con las 7 variables de trabajo y el identificador del registro. #selecciono las variables con las que voy a trabajar data01 &lt;- subset(data, select = c(id, x1,x2,x3,x4,x5,x6,x7)) Recordemos que si las variables estuvieran medidas en distinta escala, deberíamos estandarizar. No es el caso. # si fuera necesario debería estandarizar, si todas miden igual no sería necesario # data01&lt;- scale(data01, center= TRUE, scale=TRUE) mh &lt;- round(mahalanobis(data01[,-1], colMeans(data01[,-1]), cov(data01[,-1])),5) pmh &lt;- round(pchisq(mh, df=7, lower.tail=FALSE),5) data01 &lt;- cbind(data01, mh,pmh) dim(data01) [1] 100 10 data01 &lt;- subset(data01, pmh&gt;0.001) dim(data01) [1] 98 10 datatable(data01) data01 &lt;- data01[,c(-9,-10)] 9.1 Cálculo de distancias Calculamos las distancias, euclídeas. #calculo las distancias (package stats) dist01 &lt;- dist(data01[,-1]) 9.2 Clúster jerárquico 9.2.1 Cálculo Realizamos el cluster jerárquico y listamos sus resultados. Nótese en la agenda de casos, que un número negativo significa referencia al caso original, mientras que un número positivo indica una referencia un grupo creado en el paso idncado por el número #calculo los grupos method -&gt; the agglomeration method to be used. This should be (an unambiguous abbreviation of) one of &quot;ward.D&quot;, &quot;ward.D2&quot;, &quot;single&quot;, &quot;complete&quot;, &quot;average&quot; (= UPGMA), &quot;mcquitty&quot; (= WPGMA), &quot;median&quot; (= WPGMC) or &quot;centroid&quot; (= UPGMC). clusters &lt;- hclust(dist01, method = &quot;complete&quot;) clusters[[&quot;method&quot;]] [1] &quot;complete&quot; clusters[[&quot;call&quot;]] hclust(d = dist01, method = &quot;complete&quot;) clusters[[&quot;dist.method&quot;]] [1] &quot;euclidean&quot; clusters[[&quot;merge&quot;]] [,1] [,2] [1,] -14 -15 [2,] -6 -7 [3,] -86 -91 [4,] -4 -5 [5,] -49 -54 [6,] -69 -72 [7,] -92 -93 [8,] -45 -52 [9,] -51 -58 [10,] -53 -55 [11,] -67 -70 [12,] -83 -89 [13,] -25 -28 [14,] -8 -9 [15,] -84 -88 [16,] -65 -68 [17,] -12 -13 [18,] -77 -87 [19,] -57 -64 [20,] -43 -50 [21,] -42 -56 [22,] -36 -46 [23,] -26 -30 [24,] -71 -74 [25,] -29 -47 [26,] -18 -31 [27,] -95 -96 [28,] -35 -37 [29,] -19 -22 [30,] -21 -24 [31,] -27 -33 [32,] -39 -48 [33,] -66 -82 [34,] -44 -59 [35,] -17 -32 [36,] -78 -79 [37,] -73 -81 [38,] -20 -23 [39,] -16 6 [40,] 7 27 [41,] -76 -90 [42,] -75 -85 [43,] -2 -3 [44,] -97 -98 [45,] -61 36 [46,] -41 -62 [47,] -38 -80 [48,] -1 -11 [49,] 16 17 [50,] -34 45 [51,] -63 15 [52,] 1 5 [53,] -40 41 [54,] 20 30 [55,] 3 25 [56,] 9 49 [57,] 42 47 [58,] -60 34 [59,] -94 22 [60,] 10 11 [61,] 32 40 [62,] 18 21 [63,] 37 60 [64,] 44 51 [65,] 35 46 [66,] 29 50 [67,] 33 58 [68,] 12 24 [69,] 8 23 [70,] 14 48 [71,] 39 52 [72,] 28 62 [73,] 13 56 [74,] 19 57 [75,] 4 54 [76,] 59 66 [77,] 64 68 [78,] 31 61 [79,] 67 71 [80,] 55 74 [81,] -10 26 [82,] 63 73 [83,] 70 80 [84,] 53 69 [85,] 38 82 [86,] 65 72 [87,] 75 77 [88,] 76 81 [89,] 84 87 [90,] 78 86 [91,] 43 88 [92,] 85 89 [93,] 83 90 [94,] 2 79 [95,] 91 93 [96,] 92 94 [97,] 95 96 clusters[[&quot;height&quot;]] [1] 0.0000000 0.1000000 0.1000000 0.1414214 0.2000000 0.2449490 0.2645751 [8] 0.2645751 0.2645751 0.2645751 0.3162278 0.3162278 0.3162278 0.3162278 [15] 0.3605551 0.4000000 0.4358899 0.4358899 0.4358899 0.4690416 0.4690416 [22] 0.4690416 0.4924429 0.5000000 0.5291503 0.5291503 0.5291503 0.5291503 [29] 0.5291503 0.5291503 0.6164414 0.6557439 0.6557439 0.7280110 0.7615773 [36] 0.8185353 0.8366600 0.9165151 0.9539392 0.9848858 1.0198039 1.0246951 [43] 1.0246951 1.0344080 1.0488088 1.1489125 1.2884099 1.2961481 1.3601471 [50] 1.4899664 1.5652476 1.5968719 1.6278821 1.6703293 1.7804494 1.8055470 [57] 1.8627936 1.8627936 1.8947295 1.9078784 1.9949937 1.9974984 2.0976177 [64] 2.1447611 2.1725561 2.2338308 2.2383029 2.2737634 2.3643181 2.3916521 [71] 2.4269322 2.4331050 2.4617067 2.4698178 2.6532998 2.8548205 2.9000000 [78] 3.1016125 3.1096624 3.1968735 3.3630343 3.3941125 3.4292856 3.6000000 [85] 3.9076847 3.9230090 4.0435133 4.0472213 4.3335897 4.6957428 4.9061186 [92] 5.0892043 5.4899909 5.9665736 7.1554175 7.3464277 8.8960665 clusters[[&quot;order&quot;]] [1] 2 3 94 36 46 19 22 34 61 78 79 10 18 31 8 9 1 11 86 91 29 47 57 64 75 [26] 85 38 80 27 33 39 48 92 93 95 96 17 32 41 62 35 37 77 87 42 56 20 23 73 81 [51] 53 55 67 70 25 28 51 58 65 68 12 13 40 76 90 45 52 26 30 4 5 43 50 21 24 [76] 97 98 63 84 88 83 89 71 74 6 7 66 82 60 44 59 16 69 72 14 15 49 54 plot(clusters) 9.2.2 Creación de variables de grupo 9.2.2.1 Solución de 5 grupos Retenemos una variable con la pertenencia a cada grupo (5). clusterCut.05 &lt;- cutree(clusters, 5) clusterCut.05 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 1 2 2 3 3 4 4 1 1 2 1 3 3 5 5 5 1 2 2 3 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 3 2 3 3 3 3 1 3 1 3 2 1 1 2 1 2 1 1 1 3 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 1 1 3 5 3 2 1 1 5 3 3 3 3 5 3 1 1 3 5 5 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 2 1 3 1 3 5 3 3 5 3 3 5 3 3 1 3 1 2 2 1 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 3 5 3 3 1 1 1 3 3 3 1 1 1 2 1 1 3 3 9.2.2.2 Solución de 4 grupos Retenemos una variable con la pertenencia a cada grupo (4). clusterCut.04 &lt;- cutree(clusters, 4) clusterCut.04 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 1 2 2 3 3 4 4 1 1 2 1 3 3 4 4 4 1 2 2 3 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 3 2 3 3 3 3 1 3 1 3 2 1 1 2 1 2 1 1 1 3 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 1 1 3 4 3 2 1 1 4 3 3 3 3 4 3 1 1 3 4 4 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 2 1 3 1 3 4 3 3 4 3 3 4 3 3 1 3 1 2 2 1 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 3 4 3 3 1 1 1 3 3 3 1 1 1 2 1 1 3 3 9.2.2.3 Solución de 3 grupos Retenemos una variable con la pertenencia a cada grupo (3). clusterCut.03 &lt;- cutree(clusters, 3) clusterCut.03 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 1 1 1 2 2 3 3 1 1 1 1 2 2 3 3 3 1 1 1 2 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 2 1 2 2 2 2 1 2 1 2 1 1 1 1 1 1 1 1 1 2 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 1 1 2 3 2 1 1 1 3 2 2 2 2 3 2 1 1 2 3 3 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 1 1 2 1 2 3 2 2 3 2 2 3 2 2 1 2 1 1 1 1 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 2 3 2 2 1 1 1 2 2 2 1 1 1 1 1 1 2 2 9.2.2.4 Solución de 2 grupos Retenemos una variable con la pertenencia a cada grupo (2). clusterCut.02 &lt;- cutree(clusters, 2) clusterCut.02 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 1 1 1 2 2 2 2 1 1 1 1 2 2 2 2 2 1 1 1 2 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 2 1 2 2 2 2 1 2 1 2 1 1 1 1 1 1 1 1 1 2 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 1 1 2 2 2 1 1 1 2 2 2 2 2 2 2 1 1 2 2 2 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 1 1 2 1 2 2 2 2 2 2 2 2 2 2 1 2 1 1 1 1 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 2 2 2 2 1 1 1 2 2 2 1 1 1 1 1 1 2 2 Procedemos a unir las variables con el fichero original. data02 &lt;- cbind(id=data01[,1],clusterCut.02,clusterCut.03,clusterCut.04,clusterCut.05) 9.3 Clúster K-medias 9.3.1 Cálculo Hacemos el análisis K-means para 5, 4 3 y 2 grupos. Listamos secuencialmente sus resúmenes. #cluster kmeans set.seed(31121965) kclusterCut.05 &lt;- kmeans(data01[,-1], 5, nstart = 10) kclusterCut.05 K-means clustering with 5 clusters of sizes 31, 14, 19, 16, 18 Cluster means: x1 x2 x3 x4 x5 x6 x7 1 4.125806 1.687097 8.638710 4.525806 2.922581 2.091935 5.264516 2 3.614286 4.128571 5.950000 6.064286 3.842857 3.164286 7.950000 3 4.884211 1.510526 9.368421 5.810526 3.178947 3.300000 7.000000 4 2.300000 3.625000 7.843750 5.562500 2.956250 2.675000 7.881250 5 2.011111 2.133333 6.544444 5.266667 2.038889 2.672222 8.483333 Clustering vector: 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 5 2 2 1 1 3 3 5 5 2 5 1 1 3 3 3 4 4 2 3 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 1 2 3 1 1 1 2 1 5 1 4 4 2 2 5 2 5 5 4 1 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 4 5 1 3 1 2 5 4 3 1 1 1 1 3 1 5 5 1 3 3 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 2 4 3 5 1 3 1 1 3 1 1 3 1 1 5 1 4 2 2 5 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 1 3 4 3 5 5 4 3 4 1 5 4 4 2 4 4 1 1 Within cluster sum of squares by cluster: [1] 130.54274 54.23429 73.35368 51.28063 60.38611 (between_SS / total_SS = 61.6 %) Available components: [1] &quot;cluster&quot; &quot;centers&quot; &quot;totss&quot; &quot;withinss&quot; &quot;tot.withinss&quot; [6] &quot;betweenss&quot; &quot;size&quot; &quot;iter&quot; &quot;ifault&quot; set.seed(31121965) kclusterCut.04 &lt;- kmeans(data01[,-1], 4, nstart = 10) kclusterCut.04 K-means clustering with 4 clusters of sizes 31, 19, 19, 29 Cluster means: x1 x2 x3 x4 x5 x6 x7 1 4.125806 1.687097 8.638710 4.525806 2.922581 2.091935 5.264516 2 3.415789 3.989474 6.578947 6.210526 3.684211 3.200000 8.026316 3 4.884211 1.510526 9.368421 5.810526 3.178947 3.300000 7.000000 4 2.024138 2.703448 6.951724 5.196552 2.337931 2.565517 8.193103 Clustering vector: 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 4 2 2 1 1 3 3 4 4 2 4 1 1 3 3 3 2 2 2 3 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 1 2 3 1 1 1 2 1 4 1 2 4 2 2 4 2 4 4 4 1 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 4 4 1 3 1 2 4 4 3 1 1 1 1 3 1 4 4 1 3 3 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 2 4 3 4 1 3 1 1 3 1 1 3 1 1 4 1 2 2 2 4 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 1 3 4 3 4 4 2 3 4 1 4 4 4 2 4 4 1 1 Within cluster sum of squares by cluster: [1] 130.54274 92.03474 73.35368 116.63724 (between_SS / total_SS = 57.2 %) Available components: [1] &quot;cluster&quot; &quot;centers&quot; &quot;totss&quot; &quot;withinss&quot; &quot;tot.withinss&quot; [6] &quot;betweenss&quot; &quot;size&quot; &quot;iter&quot; &quot;ifault&quot; set.seed(31121965) kclusterCut.03 &lt;- kmeans(data01[,-1], 3, nstart = 10) kclusterCut.03 K-means clustering with 3 clusters of sizes 31, 19, 48 Cluster means: x1 x2 x3 x4 x5 x6 x7 1 4.125806 1.687097 8.638710 4.525806 2.922581 2.091935 5.264516 2 4.884211 1.510526 9.368421 5.810526 3.178947 3.300000 7.000000 3 2.575000 3.212500 6.804167 5.597917 2.870833 2.816667 8.127083 Clustering vector: 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 3 3 3 1 1 2 2 3 3 3 3 1 1 2 2 2 3 3 3 2 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 1 3 2 1 1 1 3 1 3 1 3 3 3 3 3 3 3 3 3 1 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 3 3 1 2 1 3 3 3 2 1 1 1 1 2 1 3 3 1 2 2 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 3 3 2 3 1 2 1 1 2 1 1 2 1 1 3 1 3 3 3 3 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 1 2 3 2 3 3 3 2 3 1 3 3 3 3 3 3 1 1 Within cluster sum of squares by cluster: [1] 130.54274 73.35368 289.03208 (between_SS / total_SS = 48.8 %) Available components: [1] &quot;cluster&quot; &quot;centers&quot; &quot;totss&quot; &quot;withinss&quot; &quot;tot.withinss&quot; [6] &quot;betweenss&quot; &quot;size&quot; &quot;iter&quot; &quot;ifault&quot; set.seed(31121965) kclusterCut.02 &lt;- kmeans(data01[,-1], 2, nstart = 10) kclusterCut.02 K-means clustering with 2 clusters of sizes 50, 48 Cluster means: x1 x2 x3 x4 x5 x6 x7 1 4.414 1.6200 8.916000 5.014000 3.020000 2.551000 5.924000 2 2.575 3.2125 6.804167 5.597917 2.870833 2.816667 8.127083 Clustering vector: 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 2 2 2 1 1 1 1 2 2 2 2 1 1 1 1 1 2 2 2 1 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 1 2 1 1 1 1 2 1 2 1 2 2 2 2 2 2 2 2 2 1 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 2 2 1 1 1 2 2 2 1 1 1 1 1 1 1 2 2 1 1 1 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 2 2 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 1 1 2 1 2 2 2 1 2 1 2 2 2 2 2 2 1 1 Within cluster sum of squares by cluster: [1] 290.2013 289.0321 (between_SS / total_SS = 39.8 %) Available components: [1] &quot;cluster&quot; &quot;centers&quot; &quot;totss&quot; &quot;withinss&quot; &quot;tot.withinss&quot; [6] &quot;betweenss&quot; &quot;size&quot; &quot;iter&quot; &quot;ifault&quot; 9.3.2 Creación de las variables de grupo g2 &lt;- kclusterCut.02[[&quot;cluster&quot;]] g3 &lt;- kclusterCut.03[[&quot;cluster&quot;]] g4 &lt;- kclusterCut.04[[&quot;cluster&quot;]] g5 &lt;- kclusterCut.05[[&quot;cluster&quot;]] Procedemos a unir las variables de pertenencia del K-means con el fichero original. data03 &lt;- cbind(id=data01[,1], g2, g3, g4, g5) data &lt;- merge(data, data02, by = &quot;id&quot;) data &lt;- merge(data, data03, by = &quot;id&quot;) El fichero resultante tras la adición de las variables es: datatable(data) 9.3.3 Perfil de los grupos, contrastes inferenciales Perfilamos los grupos con otros datos del banco de datos. Hacemos la prueba Chisq para los datos nominales y la prueba T para los métricos. data = apply_labels(data, g5 = &quot;Grupo&quot; ) data %&gt;% tab_cells(x8,x11,x12,x13,x14) %&gt;% tab_cols(g5) %&gt;% tab_stat_cases() %&gt;% tab_last_sig_cases() %&gt;% tab_pivot()  Grupo   1   2   3   4   5   tamaño de la empresa     0  29.0  4.0  19.0  6.0     1  2.0  10.0  10.0  18.0     #Chi-squared p-value  &lt;0.05     #Total cases  31.0  14.0  19.0  16.0  18.0   especificación de las compras     0  2.0  10.0  10.0  18.0     1  29.0  4.0  19.0  6.0     #Chi-squared p-value  &lt;0.05     #Total cases  31.0  14.0  19.0  16.0  18.0   estructura     0  29.0  19.0     1  2.0  14.0  16.0  18.0     #Chi-squared p-value  &lt;0.05     #Total cases  31.0  14.0  19.0  16.0  18.0   tipo de industria     0  21.0  6.0  5.0  8.0  8.0     1  10.0  8.0  14.0  8.0  10.0     #Chi-squared p-value     #Total cases  31.0  14.0  19.0  16.0  18.0   situacion de compra     1  6.0  2.0  2.0  4.0  18.0     2  8.0  12.0  2.0  10.0     3  17.0  15.0  2.0     #Chi-squared p-value  &lt;0.05 (warn.)    #Total cases  31.0  14.0  19.0  16.0  18.0  data %&gt;% tab_cells(x9,x10) %&gt;% tab_cols(g5) %&gt;% tab_stat_mean_sd_n() %&gt;% tab_last_sig_means() %&gt;% tab_pivot()  Grupo   1     2     3     4     5   A     B     C     D     E   nivel de uso     Mean  46.9 E   46.5 E   54.2 A B D E   46.7 E   36.3     Std. dev.  8.8     6.5     7.0     6.1     5.3     Unw. valid N  31.0     14.0     19.0     16.0     18.0   nivel de satisfacción     Mean  4.9 E   4.9 E   5.6 A B D E   4.6 E   3.7     Std. dev.  0.7     0.8     0.6     0.6     0.3     Unw. valid N  31.0     14.0     19.0     16.0     18.0  data = apply_labels(data, g4 = &quot;Grupo&quot; ) data %&gt;% tab_cells(x8,x11,x12,x13,x14) %&gt;% tab_cols(g4) %&gt;% tab_stat_cases() %&gt;% tab_last_sig_cases() %&gt;% tab_pivot()  Grupo   1   2   3   4   tamaño de la empresa     0  29.0  8.0  19.0  2.0     1  2.0  11.0  27.0     #Chi-squared p-value  &lt;0.05     #Total cases  31.0  19.0  19.0  29.0   especificación de las compras     0  2.0  11.0  27.0     1  29.0  8.0  19.0  2.0     #Chi-squared p-value  &lt;0.05     #Total cases  31.0  19.0  19.0  29.0   estructura     0  29.0  19.0     1  2.0  19.0  29.0     #Chi-squared p-value  &lt;0.05     #Total cases  31.0  19.0  19.0  29.0   tipo de industria     0  21.0  8.0  5.0  14.0     1  10.0  11.0  14.0  15.0     #Chi-squared p-value  &lt;0.05     #Total cases  31.0  19.0  19.0  29.0   situacion de compra     1  6.0  2.0  2.0  22.0     2  8.0  15.0  2.0  7.0     3  17.0  2.0  15.0     #Chi-squared p-value  &lt;0.05     #Total cases  31.0  19.0  19.0  29.0  data %&gt;% tab_cells(x9,x10) %&gt;% tab_cols(g4) %&gt;% tab_stat_mean_sd_n() %&gt;% tab_last_sig_means() %&gt;% tab_pivot()  Grupo   1     2     3     4   A     B     C     D   nivel de uso     Mean  46.9 D   47.8 D   54.2 A B D   39.4     Std. dev.  8.8     6.2     7.0     6.8     Unw. valid N  31.0     19.0     19.0     29.0   nivel de satisfacción     Mean  4.9 D   4.9 D   5.6 A B D   4.0     Std. dev.  0.7     0.7     0.6     0.6     Unw. valid N  31.0     19.0     19.0     29.0  data = apply_labels(data, g3 = &quot;Grupo&quot; ) data %&gt;% tab_cells(x8,x11,x12,x13,x14) %&gt;% tab_cols(g3) %&gt;% tab_stat_cases() %&gt;% tab_last_sig_cases() %&gt;% tab_pivot()  Grupo   1   2   3   tamaño de la empresa     0  29.0  19.0  10.0     1  2.0  38.0     #Chi-squared p-value  &lt;0.05     #Total cases  31.0  19.0  48.0   especificación de las compras     0  2.0  38.0     1  29.0  19.0  10.0     #Chi-squared p-value  &lt;0.05     #Total cases  31.0  19.0  48.0   estructura     0  29.0  19.0     1  2.0  48.0     #Chi-squared p-value  &lt;0.05     #Total cases  31.0  19.0  48.0   tipo de industria     0  21.0  5.0  22.0     1  10.0  14.0  26.0     #Chi-squared p-value  &lt;0.05     #Total cases  31.0  19.0  48.0   situacion de compra     1  6.0  2.0  24.0     2  8.0  2.0  22.0     3  17.0  15.0  2.0     #Chi-squared p-value  &lt;0.05     #Total cases  31.0  19.0  48.0  data %&gt;% tab_cells(x9,x10) %&gt;% tab_cols(g3) %&gt;% tab_stat_mean_sd_n() %&gt;% tab_last_sig_means() %&gt;% tab_pivot()  Grupo   1     2     3   A     B     C   nivel de uso     Mean  46.9 C   54.2 A C   42.7     Std. dev.  8.8     7.0     7.7     Unw. valid N  31.0     19.0     48.0   nivel de satisfacción     Mean  4.9 C   5.6 A C   4.4     Std. dev.  0.7     0.6     0.8     Unw. valid N  31.0     19.0     48.0  data = apply_labels(data, g2 = &quot;Grupo&quot; ) data %&gt;% tab_cells(x8,x11,x12,x13,x14) %&gt;% tab_cols(g2) %&gt;% tab_stat_cases() %&gt;% tab_last_sig_cases() %&gt;% tab_pivot()  Grupo   1   2   tamaño de la empresa     0  48.0  10.0     1  2.0  38.0     #Chi-squared p-value  &lt;0.05     #Total cases  50.0  48.0   especificación de las compras     0  2.0  38.0     1  48.0  10.0     #Chi-squared p-value  &lt;0.05     #Total cases  50.0  48.0   estructura     0  48.0     1  2.0  48.0     #Chi-squared p-value  &lt;0.05     #Total cases  50.0  48.0   tipo de industria     0  26.0  22.0     1  24.0  26.0     #Chi-squared p-value     #Total cases  50.0  48.0   situacion de compra     1  8.0  24.0     2  10.0  22.0     3  32.0  2.0     #Chi-squared p-value  &lt;0.05     #Total cases  50.0  48.0  data %&gt;% tab_cells(x9,x10) %&gt;% tab_cols(g2) %&gt;% tab_stat_mean_sd_n() %&gt;% tab_last_sig_means() %&gt;% tab_pivot()  Grupo   1     2   A     B   nivel de uso     Mean  49.7 B   42.7     Std. dev.  8.9     7.7     Unw. valid N  50.0     48.0   nivel de satisfacción     Mean  5.2 B   4.4     Std. dev.  0.7     0.8     Unw. valid N  50.0     48.0  "],["s06.html", "Parte 10 Análisis de regresión múltiple - Sesión 06 10.1 Análisis de correlación 10.2 Modelo de regresión 10.3 Distancia de De Cook 10.4 Fiabilidad del modelo", " Parte 10 Análisis de regresión múltiple - Sesión 06 Cargamos los paquetes necesarios y los datos del archivo institutoschicago.sav data &lt;- read_spss(&quot;http://download.tesigandia.com/tmim/institutoschicago.sav&quot;) 10.1 Análisis de correlación Calculamos la matriz de correlaciones para validar la linealidad d ela relación entre la variable dependiente y cualquiera de las independientes rcorr(as.matrix(subset(data, select = c(selectivo, asistencia, rentabaja, extranjero, tamclase)))) selectivo asistencia rentabaja extranjero tamclase selectivo 1.00 0.72 -0.71 -0.14 0.50 asistencia 0.72 1.00 -0.52 -0.01 0.59 rentabaja -0.71 -0.52 1.00 0.10 -0.43 extranjero -0.14 -0.01 0.10 1.00 0.07 tamclase 0.50 0.59 -0.43 0.07 1.00 n selectivo asistencia rentabaja extranjero tamclase selectivo 81 80 81 81 81 asistencia 80 81 81 81 81 rentabaja 81 81 82 82 82 extranjero 81 81 82 82 82 tamclase 81 81 82 82 82 P selectivo asistencia rentabaja extranjero tamclase selectivo 0.0000 0.0000 0.2062 0.0000 asistencia 0.0000 0.0000 0.9601 0.0000 rentabaja 0.0000 0.0000 0.3555 0.0000 extranjero 0.2062 0.9601 0.3555 0.5222 tamclase 0.0000 0.0000 0.0000 0.5222 pairs(subset(data, select = c(selectivo, asistencia, rentabaja, extranjero, tamclase))) 10.2 Modelo de regresión Mostramos el modelo de regresión lineal múltiple. modelo1 &lt;- lm(selectivo ~ asistencia + rentabaja + extranjero + tamclase, data = data) summary(modelo1) Call: lm(formula = selectivo ~ asistencia + rentabaja + extranjero + tamclase, data = data) Residuals: Porcentaje de aprobados en selectivo Min 1Q Median 3Q Max -34.845 -6.649 -1.301 6.234 52.897 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -110.5677 37.5578 -2.944 0.00431 ** asistencia 2.2045 0.4106 5.370 0.000000851 *** rentabaja -0.6517 0.1136 -5.739 0.000000190 *** extranjero -0.2593 0.2300 -1.127 0.26316 tamclase 0.2119 0.4162 0.509 0.61222 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 12.86 on 75 degrees of freedom (2 observations deleted due to missingness) Multiple R-squared: 0.6839, Adjusted R-squared: 0.6671 F-statistic: 40.57 on 4 and 75 DF, p-value: &lt; 2.2e-16 10.3 Distancia de De Cook Se comprueba la existencia de outliers con el cálculo distancias. de.cook &lt;- cooks.distance(modelo1) summary(de.cook) Min. 1st Qu. Median Mean 3rd Qu. Max. 0.00000043 0.00065550 0.00364650 0.01192072 0.01133593 0.09615295 10.4 Fiabilidad del modelo Para que este modelo sea fiable debemos realizar un ANALISIS DE RESIDUOS 10.4.1 1: Los errores deben seguir una distribución normal residuos &lt;- rstandard(modelo1) # residuos estándares del modelo ajustado (completo) hist(residuos) # histograma de los residuos estandarizados boxplot(residuos) # diagrama de cajas de los residuos estandarizados qqnorm(residuos) # gráfico de cuantiles de los residuos estandarizados residuosest &lt;- rstudent(modelo1) # residuos estándares del modelo ajustado (completo) hist(residuosest) # histograma de los residuos estandarizados boxplot(residuosest) # diagrama de cajas de los residuos estandarizados qqnorm(residuosest) # gráfico de cuantiles de los residuos estandarizados 10.4.2 2: La varianza de los errores es constante. Se hace el test de Goldfeld y Quandt. gqtest(selectivo ~ asistencia + rentabaja + extranjero + tamclase, data = data) Goldfeld-Quandt test data: selectivo ~ asistencia + rentabaja + extranjero + tamclase GQ = 0.051197, df1 = 35, df2 = 35, p-value = 1 alternative hypothesis: variance increases from segment 1 to 2 plot(fitted.values(modelo1),rstandard(modelo1), xlab=&quot;Valores ajustados&quot;, ylab=&quot;Residuos estandarizados&quot;) abline(h=0) # dibuja la recta en cero plot(fitted.values(modelo1),rstudent(modelo1), xlab=&quot;Valores ajustados&quot;, ylab=&quot;Residuos estudentizados&quot;) abline(h=0) # dibuja la recta en cero 10.4.3 3: La independencia de los errores plot(modelo1[[&quot;model&quot;]][[&quot;asistencia&quot;]], rstandard(modelo1), xlab = &quot;Asistencia a clase&quot;, ylab = &quot;Residuos estandarizados&quot;) plot(modelo1[[&quot;model&quot;]][[&quot;rentabaja&quot;]], rstandard(modelo1), xlab = &quot;Renta baja&quot;, ylab = &quot;Residuos estandarizados&quot;) plot(modelo1[[&quot;model&quot;]][[&quot;extranjero&quot;]], rstandard(modelo1), xlab = &quot;Número de extranjeros&quot;, ylab = &quot;Residuos estandarizados&quot;) plot(modelo1[[&quot;model&quot;]][[&quot;tamclase&quot;]], rstandard(modelo1), xlab = &quot;Tamaño medio de la clase&quot;, ylab = &quot;Residuos estandarizados&quot;) plot(modelo1[[&quot;model&quot;]][[&quot;asistencia&quot;]], rstudent(modelo1), xlab = &quot;Asistencia a clase&quot;, ylab = &quot;Residuos estudentizados&quot;) plot(modelo1[[&quot;model&quot;]][[&quot;rentabaja&quot;]], rstudent(modelo1), xlab = &quot;Renta baja&quot;, ylab = &quot;Residuos estudentizados&quot;) plot(modelo1[[&quot;model&quot;]][[&quot;extranjero&quot;]], rstudent(modelo1), xlab = &quot;Número de extranjeros&quot;, ylab = &quot;Residuos estudentizados&quot;) plot(modelo1[[&quot;model&quot;]][[&quot;tamclase&quot;]], rstudent(modelo1), xlab = &quot;Tamaño medio de la clase&quot;, ylab = &quot;Residuos estudentizados&quot;) 10.4.4 4: No auto correlación de los términos de error. dwtest(selectivo ~ asistencia + rentabaja + extranjero + tamclase, data = data) Durbin-Watson test data: selectivo ~ asistencia + rentabaja + extranjero + tamclase DW = 1.6611, p-value = 0.05996 alternative hypothesis: true autocorrelation is greater than 0 "],["conclusion.html", "Parte 11 Conclusión", " Parte 11 Conclusión "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
